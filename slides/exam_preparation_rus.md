# Машинное обучение и статистика: 24 основных вопроса
## Подробное руководство по подготовке к экзамену с формулами и ссылками

## В1 — Закон больших чисел vs Центральная предельная теорема

### Краткий ответ
**ЗБЧ** говорит нам, КУДА стремится выборочное среднее (→ среднее генеральной совокупности).
**ЦПТ** говорит нам, КАК оно туда стремится (→ Нормальное распределение).

### Закон больших чисел (ЗБЧ)

**Что утверждает:** Выборочное среднее сходится к математическому ожиданию при n → ∞

$$\bar{X}_n \to \mathbb{E}[X] \quad \text{при } n \to \infty$$

**Необходимые условия:**
- Независимость
- Одинаковое распределение
- Конечное математическое ожидание

**Интуиция:** Подбросить монету 1 000 000 раз → доля орлов ≈ 0.5

**Две версии:**
- **Слабый закон:** Сходимость по вероятности
- **Сильный закон:** Сходимость почти наверное (более сильная гарантия)

**Ключевой момент:** ЗБЧ говорит, что среднее **стабилизируется**, но не описывает его распределение.

### Центральная предельная теорема (ЦПТ)

**Что утверждает:** Сумма (или масштабированное среднее) независимых одинаково распределенных случайных величин → Нормальное распределение

$$\frac{\sum X_i - n\mathbb{E}[X]}{\sqrt{n\text{Var}(X)}} \xrightarrow{d} N(0,1)$$

**Интуиция:** Даже если распределение X асимметрично/дискретно, сумма многих X выглядит как колоколообразная кривая.

**Требования:**
- Независимые наблюдения
- Одинаково распределенные
- **Конечная дисперсия** (исключает распределение Коши)
- n ≥ 30 (практическое правило)

Ключевые различия


| Аспект | ЗБЧ | ЦПТ |
|--------|-----|-----|
| **О чем** | Сходимость среднего | Форма распределения |
| **Сходится к** | Константе (μ) | Нормальному распределению N(0,1) |
| **Требует дисперсию** | Нет (слабый закон) | Да |
| **Применение** | Частоты, оценка вероятностей | p-value, доверительные интервалы |



### Практическое применение в МО

**Сходимость SGD (ЗБЧ)**

Градиенты мини-батчей сходятся к истинному градиенту:

$$\frac{1}{B}\sum_{i=1}^{B} \nabla L(x_i, \theta) \xrightarrow{P} E[\nabla L(X, \theta)]$$

Это объясняет, почему SGD находит (локальные) минимумы, несмотря на зашумленные оценки.

**Распределение SGD (ЦПТ)**

Объясняет, что итерации SGD следуют Гауссовому распределению вокруг оптимума:

$$\sqrt{n}(\bar{\theta}_n - \theta^*) \xrightarrow{d} N(0, \Sigma_\infty)$$

**Методы бутстрэпа**

- ЗБЧ: Эмпирическое распределение сходится к истинному распределению
- ЦПТ: Обосновывает построение доверительных интервалов

**Доверительные интервалы**
ЦПТ позволяет строить:

$$\bar{X} \pm z_{\alpha/2} \cdot \frac{s}{\sqrt{n}}$$

Действительно независимо от распределения генеральной совокупности (для больших n).

**Ссылки:**
- [Закон больших чисел - Википедия](https://ru.wikipedia.org/wiki/Закон_больших_чисел)
- [Центральная предельная теорема - Википедия](https://ru.wikipedia.org/wiki/Центральная_предельная_теорема)

---

## В2 — EDA для набора данных с одной переменной

### Метрики для расчета

#### Для числовой переменной:

**Центральная тенденция:**
- Среднее: 

$$\bar{x} = \frac{1}{n}\sum x_i$$

- Медиана: Средний элемент в отсортированном ряду
- Мода: Наиболее часто встречающееся значение

**Разброс:**
- Дисперсия:

$$s^2 = \frac{1}{n-1}\sum(x_i - \bar{x})^2$$
 
- Стандартное отклонение:

$$s = \sqrt{s^2}$$

- IQR (межквартильный размах):

$$Q_3 - Q_1$$

- Мин, Макс, Размах

**Форма:**
- Асимметрия: Мера асимметрии распределения
- Эксцесс: Мера "тяжести" хвостов

**Визуализации:**
- Гистограмма
- Ящик с усами (Box plot)
- Q-Q plot (проверка на нормальность)
- Скрипичная диаграмма (Violin plot)


**Простой случай 1**: Эффект умножения на константу k на дисперсию

Если все значения умножить на k:

$$\text{Var}(kX) = k^2 \cdot \text{Var}(X)$$

Пример: Умножение на 2 → дисперсия увеличивается в 4 раза

Почему: Дисперсия измеряет разброс, который масштабируется квадратично.

**Простой случай 2**: Как "умножить значения выше порога на 3" влияет на медиану

**Медиана изменится только если:**
1. Порог приходится на медианный элемент, ИЛИ
2. Порог ниже медианы

**Почему:**
- Медиана зависит от **позиции**, а не от значений
- Если порог > медианы → изменяется только верхняя половина, медиана не меняется
- Если порог ≤ медианы → медианный элемент умножается на 3

**Пример:**

```
Данные: [1, 2, 3, 4, 5], медиана = 3
Порог = 3, умножить на 3
Новые данные: [1, 2, 9, 12, 15], медиана = 9 (увеличилась в 3 раза)
```


### Сравнение двух наборов данных

**Статистические тесты:**
- **t-критерий Стьюдента:** Сравнение средних (если данные нормально распределены)
- **U-критерий Манна-Уитни:** Непараметрическая альтернатива
- **Критерий Колмогорова-Смирнова:** Сравнение распределений целиком
- **Хи-квадрат:** Для категориальных данных

**Визуальное сравнение:**
- Наложенные гистограммы
- Ящики с усами рядом
- Q-Q plot (одно распределение против другого)

### Если набор данных содержит только 0 и 1 (CTR - Click-Through Rate)

**Это бинарные/Бернулли данные!**

**Метрики:**
- **Среднее = доля 1** (показатель CTR)
- **Дисперсия:**

$$p(1-p) \text{ где } p = \text{среднее}$$

- **Биномиальные доверительные интервалы**

**Сравнение:**
- **Хи-квадрат тест:** Сравнение долей
- **Точный тест Фишера:** Для малых выборок
- **Z-тест для долей:** Для больших выборок

**Ссылки:**
- [Разведочный анализ данных - Википедия](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных)
- [Статистическая проверка гипотез - Википедия](https://ru.wikipedia.org/wiki/Статистическая_проверка_гипотез)

---

## В2Б — Типы корреляции

### Матрица корреляции по типам переменных


| Тип X | Тип Y | Метод использования |
|---|---|---|
| **Числовой** | **Числовой** | **Пирсон** (линейная), **Спирмен** (монотонная) |
| **Категориальный** | **Категориальный** | **V Крамера**, тест χ² |
| **Категориальный** | **Числовой** | **Корреляционное отношение (η)**, ANOVA |
| **Бинарный (0/1)** | **Числовой** | **Точечно-бисериальный** |
| **Порядковый** | **Числовой** | **Спирмен**, **Кендалл** |
| **Категориальный** | **Бинарная цель** | **Взаимная информация**, **WoE** |

### Корреляция Пирсона

**Формула:**

$$r = \frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum(x_i - \bar{x})^2 \sum(y_i - \bar{y})^2}}$$

**Диапазон:** [-1, 1]
- 1 = идеальная положительная линейная связь
- 0 = нет линейной связи
- -1 = идеальная отрицательная линейная связь

**Использовать когда:** Обе переменные числовые, связь линейная

### Корреляция Спирмена

**Формула:** Корреляция Пирсона на **ранговых** данных

**Использовать когда:**
- Нелинейная монотонная связь
- Присутствуют выбросы
- Порядковые данные

### V Крамера (Категориальный ↔ Категориальный)

**Формула:**

$$V = \sqrt{\frac{\chi^2}{n \cdot \min(k-1, r-1)}}$$

Где:
- χ² = Статистика Хи-квадрат
- n = размер выборки
- k = количество столбцов
- r = количество строк

**Диапазон:** [0, 1]
- 0 = нет связи
- 1 = идеальная связь

**Интерпретация (рекомендации Коэна):**

| df | Маленькая | Средняя | Большая |
|---|---|---|---|
| 1 | 0.10 | 0.30 | 0.50 |
| 2 | 0.07 | 0.21 | 0.35 |
| 3 | 0.06 | 0.17 | 0.29 |

**Использовать когда:** Обе переменные категориальные (номинальные)

### Точечно-бисериальный (Бинарный ↔ Числовой)

**Формула:**

$$r_{pb} = \frac{M_1 - M_0}{s_n} \sqrt{\frac{n_1 \cdot n_0}{n^2}}$$

Где:
- M₁ = среднее Y при X=1
- M₀ = среднее Y при X=0
- sₙ = стандартное отклонение Y
- n₁, n₀ = размеры выборок для каждой группы

**Примечание:** Это математически эквивалентно корреляции Пирсона, когда одна переменная бинарная (кодируется как 0/1).

**Связь с t-тестом:** Тест значимости для точечно-бисериальной корреляции дает **тот же p-value**, что и независимый t-тест!

**Использовать когда:** Одна переменная бинарная, одна непрерывная

### Корреляционное отношение (η - Эта)

**Формула:**

$$\eta^2 = \frac{SS_{between}}{SS_{total}} = \frac{\sum n_k(\bar{y}_k - \bar{y})^2}{\sum(y_i - \bar{y})^2}$$

**Диапазон:** [0, 1]
- 0 = нет связи
- 1 = идеальная связь

**Использовать когда:** Категориальный предиктор, числовой результат (по сути, размер эффекта из ANOVA)

**Ссылки:**
- [Point-Biserial Correlation - Wikipedia](https://en.wikipedia.org/wiki/Point-biserial_correlation_coefficient)
- [Cramér's V Tutorial](https://www.spss-tutorials.com/cramers-v-what-and-why/)
- [Correlation and Dependence - Wikipedia](https://en.wikipedia.org/wiki/Correlation_and_dependence)

---
## В2С — Парадокс Симпсона

Визуальная интерпретация: Парадокс Симпсона возникает, когда тренд появляется в нескольких группах данных, но исчезает или меняется на противоположный при объединении групп.

**Классический пример: Прием в Беркли**: Мужчины принимаются в 40% случаев, женщины в 25% → кажется, что есть предвзятость в пользу мужчин (в целом)

По факультетам:
- Естественные науки: Высокий процент приема, подало больше мужчин
- Социальные науки: Низкий процент приема, подало больше женщин

Внутри каждого факультета: Женщин принимали с равной или более высокой вероятностью!

**Почему это происходит**

Два эффекта происходят одновременно:
1. **Размеры групп очень разные**
2. **Смешивающая переменная** (например, выбор факультета) влияет на обе переменные

**Визуальный пример**

* До группировки: Отрицательная корреляция (с ростом X, Y уменьшается)
* После выявления групп: Каждая группа показывает положительную корреляцию!

Агрегированные данные скрыли истинную связь внутри подгрупп.

**Ключевой урок**: Всегда проверяйте на наличие смешивающих переменных!

При анализе данных:
1. Смотрите на общие тренды
2. **Также** стратифицируйте по потенциальным смешивающим переменным
3. Понимайте причинно-следственные связи, а не только корреляции

Причинная интерпретация имеет значение: Статистические ассоциации могут меняться в зависимости от того, по каким переменным вы проводите условный анализ.

Известные примеры:
- Лечение камней в почках: Новое лечение казалось хуже в целом, но было лучше как для маленьких, так и для больших камней
- Рейтинги ресторанов: Более высокий общий рейтинг, но более низкий рейтинг в каждой возрастной подгруппе

**Ссылки:**
- [Парадокс Симпсона - Википедия](https://ru.wikipedia.org/wiki/Парадокс_Симпсона)
- [Simpson's Paradox - Britannica](https://www.britannica.com/topic/Simpsons-paradox)
- [Simpson's Paradox Explained - Statistics By Jim](https://statisticsbyjim.com/basics/simpsons-paradox/)

---
## В3 — Энтропия

**Интуитивное объяснение**: Энтропия = Мера неопределенности

Простой тест: Насколько сложно угадать следующий элемент?

**Низкая энтропия:**
```
Последовательность: АААААА
Легко предсказать → Низкая неопределенность → Низкая энтропия
```

**Высокая энтропия:**
```
Последовательность: AG4l9Pq!D8...
Сложно предсказать → Высокая неопределенность → Высокая энтропия
```

### Формула энтропии Шеннона

Для дискретной случайной величины X:

$$H(X) = -\sum_{x \in \mathcal{X}} p(x) \log p(x) = E[-\log p(X)]$$ 

**Соглашение:** $0 \log 0 = 0$

Единицы измерения:
- log₂ → **биты**
- ln → **наты**
- log₁₀ → **диты**

**Почему логарифм?**

1. Свойство аддитивности:
Для независимых событий A и B:

$$I(A \cap B) = I(A) + I(B)$$

Только логарифм удовлетворяет:

$$\log(p_A \cdot p_B) = \log p_A + \log p_B$$

2. Информационное содержание:
Редкое событие → много информации:

$$I(x) = -\log p(x)$$

3. Интерпретация в битах:
log₂(n) = минимальное количество бит, необходимое для различения n исходов

**Свойства**

- Неотрицательность: H(X) ≥ 0
- Максимум: H(X) ≤ log₂(n) для n исходов
  - Максимум при равномерном распределении
- Минимум: H(X) = 0 при детерминированности
- Условие уменьшает энтропию: H(X|Y) ≤ H(X)

### Бинарная энтропия

Для подбрасывания монеты с p(орел) = p:

$$H(X) = -p\log_2 p - (1-p)\log_2(1-p)$$

Максимум при p = 0.5 → 1 бит энтропии

### Применения в МО

**Деревья решений** (Прирост информации)

Энтропия узла: $H(t) = -\sum p_c \log_2 p_c$

Прирост информации:

$$IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)$$

Выбирается атрибут, максимизирующий IG для каждого разбиения - Жадный алгоритм строит дерево

**Случайный лес**: Использует энтропию в каждом разбиении деревьев, агрегирует для уменьшения дисперсии

**Градиентный бустинг**: Функции потерь часто связаны с кросс-энтропией (классификация)

**LLM (Потери на основе кросс-энтропии)**

$$H(p, q) = -\sum_x p(x) \log q(x)$$

Где:
- $p$ = истинное распределение (one-hot кодированный токен)
- $q$ = предсказание модели (выход softmax)

Минимизация кросс-энтропии = Минимизация дивергенции Кульбака-Лейблера:

$$D_{KL}(P \| Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}$$

Ключевые свойства:
- Неотрицательность: D_KL ≥ 0
- Ноль тогда и только тогда, когда P = Q
- Асимметричность: D_KL(P||Q) ≠ D_KL(Q||P)

Фундаментальное соотношение:

$$H(p, q) = H(p) + D_{KL}(p \| q)$$

Так как H(p) константа (истинные метки), минимизация H(p,q) = минимизация дивергенции KL

**Ссылки:**
- [Энтропия (теория информации) - Википедия](https://ru.wikipedia.org/wiki/Энтропия_(теория_информации))
- [Обучение деревьев решений - Википедия](https://ru.wikipedia.org/wiki/Дерево_решений#Алгоритмы_построения_деревьев_решений)

---
## В4 — Ошибки I и II рода

Определения

Ошибка I рода (Ложноположительный результат):
- Отклонение истинной $H_0$
- Вероятность = $\alpha$ (уровень значимости)
- **Пример:** Здоровый пациент диагностирован как больной

Ошибка II рода (Ложноотрицательный результат):
- Не удалось отклонить ложную $H_0$
- Вероятность = $\beta$
- **Пример:** Больной пациент диагностирован как здоровый

Аналогия с матрицей ошибок

| | H₀ Истинна | H₀ Ложна |
|---|---|---|
| **Отклонить H₀** | Ошибка I рода (α) | Верно ✓ |
| **Не отклонять H₀** | Верно ✓ | Ошибка II рода (β) |


**Мощность теста** = Вероятность правильного отклонения ложной H₀

$$\text{Мощность} = 1 - \beta$$

Какая ошибка серьезнее - зависит от контекста.

#### Ошибка I рода серьезнее

Уголовное правосудие - Осуждение невиновного
- "Лучше 10 виновных на свободе, чем 1 невинный осужден"
- **Решение:** Высокий стандарт доказывания (вне всяких разумных сомнений)

Спам-фильтр - Пометка важного письма как спама
- Можно пропустить критически важное сообщение
- **Решение:** Консервативный порог


#### Ошибка II рода серьезнее

Медицинский скрининг - пропуск больного пациента
- Болезнь прогрессирует без лечения
- **Решение:** Низкий порог (высокая чувствительность/полнота)

Проверка безопасности - Пропуск угрозы
- Нарушение безопасности
- **Решение:** Чувствительное обнаружение (допускается больше ложных тревог)

### Компромисс

Фундаментальное соотношение:
- Уменьшение α (I род) → Увеличение β (II род)
- Более строгий порог → Меньше ложноположительных, больше ложноотрицательных

Как уменьшить обе ошибки:
- **Увеличить размер выборки** (n ↑)
- Использовать более мощный тест
- Уменьшить шум в данных

### Выбор оптимального порога

**ROC-кривая:** График TPR против FPR при различных порогах
- Помогает визуализировать компромисс
- Выбор порога на основе стоимости ошибок

Обучение с учетом стоимости:

$$\text{Стоимость} = C_{FP} \cdot FP + C_{FN} \cdot FN$$

Установить порог для минимизации общей стоимости.

**Ссылки:**
- [Ошибки первого и второго рода - Википедия](https://ru.wikipedia.org/wiki/Ошибки_первого_и_второго_рода)
- [Статистическая мощность - Википедия](https://ru.wikipedia.org/wiki/Статистическая_мощность)

---
## В5 — Алгоритмы классификации

Сравнение алгоритмов


| Алгоритм | Скорость обучения | Интерпретируемость | Устойчивость к шуму | Требования к данным |
|---|---|---|---|---|
| Логистическая регрессия | Быстрая | Высокая | Средняя | Низкие |
| SVM | Медленная | Низкая | Низкая | Средние |
| Дерево решений | Быстрая | Очень высокая | Низкая | Низкие |
| Случайный лес | Средняя | Средняя | Высокая | Средние |
| Градиентный бустинг | Медленная | Средняя | Средняя | Средние-Высокие |
| KNN | Нет | Средняя | Низкая | Низкие |
| Наивный Байес | Очень быстрая | Высокая | Средняя | Низкие |
| Нейронные сети | Очень медленная | Очень низкая | Средняя | Очень высокие |


### Логистическая регрессия

**Преимущества:**
- Высокая интерпретируемость (коэффициенты = логарифм шансов)
- Хорошо откалиброванные вероятности
- Устойчива с регуляризацией (L1/L2)
- Быстрое обучение и предсказание O(n)
- Хорошо откалиброванные вероятностные выходы
- Устойчива с регуляризацией (предотвращает переобучение)


**Математическая основа:**
Моделирует вероятность с помощью сигмоидной функции:

$$P(y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + ... + \beta_nx_n)}}$$

**Функция потерь (Log-Loss):**

$$J(\beta) = -\frac{1}{n}\sum_{i=1}^{n}\left[y_i \log(p_i) + (1-y_i)\log(1-p_i)\right]$$

**Регуляризованные версии:**
- L2 (Ridge): $J(\beta) + \lambda\|\beta\|_2^2$ - сжимает коэффициенты, справляется с мультиколлинеарностью
- L1 (Lasso): $J(\beta) + \lambda\|\beta\|_1$ - создает разреженные решения, отбор признаков
- ElasticNet: $J(\beta) + \lambda_1\|\beta\|_1 + \lambda_2\|\beta\|_2^2$ - сочетает оба

**Недостатки:**
- Не может улавливать нелинейные зависимости
- Чувствительна к выбросам без регуляризации
- Требует масштабирования признаков

**Лучше всего для:** Бинарной классификации с требованиями к интерпретируемости, многомерных разреженных данных


### SVM (Метод опорных векторов)

**Преимущества:**
- Эффективен в пространствах высокой размерности
- Эффективен по памяти (использует только опорные векторы)
- Ядерный трюк для нелинейных границ

**Недостатки:**
- Медленное обучение O(n² до n³)
- Требует масштабирования признаков
- Выбор ядра сложен
- Не очень хорошо откалиброванные вероятности

**Лучше всего для:** Классификации текстов, многомерных данных с четкими границами

### Деревья решений

**Критерии разбиения:**
- Джини:

$$G = 1 - \sum p_i^2$$

- Энтропия:

$$H = -\sum p_i \log_2(p_i)$$

**Преимущества:**
- Высокая интерпретируемость (визуальное дерево)
- Не требует масштабирования признаков
- Обрабатывает смешанные типы данных (числовые и категориальные)
- Улавливает нелинейные зависимости

**Недостатки:**
- Склонны к переобучению (высокая дисперсия)
- Нестабильны (небольшое изменение данных = другое дерево)
- Не могут экстраполировать
- Жадный алгоритм (может не найти глобальный оптимум)

### Случайный лес

**Преимущества:**
- Уменьшает переобучение по сравнению с одним деревом (уменьшение дисперсии)
- Оценки важности признаков
- Хорошо работает "из коробки"
- Устойчив к выбросам
- Обрабатывает пропущенные значения
- Параллелизуемый

**Недостатки:**
- Менее интерпретируемый, чем одно дерево
- Медленнее в инференсе, чем линейные модели
- Требует много памяти

#### Градиентный бустинг (XGBoost, LightGBM, CatBoost)

**Преимущества:**
- Часто достигает наилучшей точности
- Встроенная регуляризация
- Обрабатывает пропущенные значения
- Важность признаков

**Недостатки:**
- Склонен к переобучению без настройки
- Последовательное обучение (медленнее, не параллелизуемый)
- Много гиперпараметров для настройки
- Менее интерпретируемый

### KNN (K-ближайших соседей)

**Преимущества:**
- Простой, интуитивно понятный
- Нет фазы обучения
- Непараметрический (без предположений)

**Недостатки:**
- Медленное предсказание O(n×d)
- Проклятие размерности
- Чувствителен к нерелевантным признакам
- Требует выбора метрики расстояния

### Наивный Байес

**Преимущества:**
- Очень быстрое обучение и инференс
- Хорошо работает с небольшими наборами данных
- Хорош для классификации текстов
- Хорошо справляется с высокой размерностью

**Недостатки:**
- Сильное предположение о независимости (редко выполняется)
- Плохие оценки вероятностей

### Нейронные сети

**Преимущества:**
- Универсальный аппроксиматор функций
- Автоматическое обучение признаков
- State-of-the-art на неструктурированных данных (изображения, текст, аудио)
- Возможность трансферного обучения

**Недостатки:**
- "Черный ящик" - низкая интерпретируемость
- Требует больших наборов данных
- Вычислительно дорогой
- Много гиперпараметров
- Склонен к переобучению без регуляризации

**Ссылки:**
- [Comparison of Statistical Classification Algorithms - Wikipedia](https://en.wikipedia.org/wiki/Statistical_classification)

---
## В6 — Метрики классификации и ROC-AUC vs F1

### Основные метрики

Матрица ошибок

| | Предсказано Положит. | Предсказано Отрицат. |
|---|---|---|
| **Фактически Положит.** | Истинно-положительные (TP) | Ложноотрицательные (FN) |
| **Фактически Отрицат.** | Ложноположительные (FP) | Истинно-отрицательные (TN) |


**Точность (Accuracy):**

$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$

Ограничение: Вводит в заблуждение на несбалансированных данных — 95% точности ничего не значат, если 95% данных одного класса


**Точность (Precision):**

$$\text{Precision} = \frac{TP}{TP + FP}$$

Интуиция: "Когда модель предсказывает положительный класс, как часто она права?"

Использовать когда: Ложноположительные результаты дорого обходятся (спам-фильтр, одобрение лекарств)


**Полнота (Recall/Sensitivity):**

$$\text{Recall} = \frac{TP}{TP + FN}$$

Интуиция: "Из всех фактических положительных случаев, сколько мы поймали?"

Использовать когда: Ложноотрицательные результаты дорого обходятся (скрининг рака, обнаружение мошенничества)

#### Специфичность

$$\text{Specificity} = \frac{TN}{TN + FP}$$

Использовать когда: Важно правильно идентифицировать отрицательные случаи (подтверждение отсутствия болезни)

**F1-мера:**

$$F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$

Гармоническое среднее (штрафует за экстремальные значения)


Почему гармоническое среднее? Штрафует за крайние значения — нельзя достичь высокого F1, преуспев только в одной метрике.

*Почему F1 необходим*:
- Точность и полнота находятся в обратной зависимости
- Единая сбалансированная оценка для сравнения моделей
- Важен для несбалансированных наборов данных

**F-бета мера:**

$$F_\beta = (1 + \beta^2) \times \frac{\text{Precision} \times \text{Recall}}{(\beta^2 \times \text{Precision}) + \text{Recall}}$$

- β < 1: Больше веса точности
- β > 1: Больше веса полноте

### Продвинутые метрики

#### ROC-AUC

ROC-кривая: График TPR (ось Y) против FPR (ось X) при всех порогах

**AUC (Площадь под кривой):**
- AUC = 1.0: Идеальный классификатор
- AUC = 0.5: Случайное угадывание
- AUC > 0.9: Отлично

#### PR-AUC vs ROC-AUC

**Ключевое различие:**
- ROC использует TN в расчете FPR
- PR-AUC полностью игнорирует TN

**Когда PR-AUC лучше:**
- Сильно несбалансированные наборы данных (положительный класс < 10%)
- Когда истинно-отрицательные не имеют значения
- Обнаружение мошенничества, обнаружение аномалий

Вероятностная интерпретация: Вероятность того, что случайно выбранный положительный пример будет ранжирован выше, чем случайно выбранный отрицательный

#### ROC-AUC vs F1

| Аспект | ROC-AUC | F1-мера |
|---|---|---|
| **Порог** | Независим от порога | Зависим от порога |
| **Несбалансированные данные** | Может вводить в заблуждение | Лучше для несбалансированных |
| **Что измеряет** | Способность к ранжированию | Баланс точности и полноты |
| **Использует TN** | Да (в FPR) | Нет |
| **Лучше всего для** | Сравнение моделей, ранжирование | Конкретный порог, несбалансированные данные |

Когда что использовать: Руководство по принятию решений

| Сценарий | Рекомендуемая метрика |
|---|---|
| Сбалансированные классы, равные затраты | Accuracy, ROC-AUC |
| Несбалансированные, важен положительный класс | PR-AUC, F1 |
| FP дорого обходятся (спам-фильтр) | Precision, F0.5 |
| FN дорого обходятся (скрининг рака) | Recall, F2 |
| Сравнение моделей, способность к ранжированию | ROC-AUC |
| Производительность при конкретном пороге | F1 при пороге |


---

**Резюме:**

Недостатки ROC-AUC: он не учитывает стоимость ошибок I и II рода. Вместо этого следует использовать взвешенную по стоимости точность или взвешенную по стоимости полноту.

* Accuracy: Сбалансированные классы, равные стоимости
* Precision: Минимизировать ложноположительные (спам-фильтр, одобрение лекарств)
* Recall: Минимизировать ложноотрицательные (скрининг рака, обнаружение мошенничества)
* F1: Баланс точности и полноты, несбалансированные данные
* Macro F1: Мультиклассовая, все классы равны
* Micro F1: Мультиклассовая, взвешивание по частоте класса

**ROC-AUC:**
- Сравнение моделей
- Когда важны ранжирование/вероятности
- Сбалансированные наборы данных

**PR-AUC (Precision-Recall AUC):**
- Сильно несбалансированные наборы данных (положительный класс < 10%)
- Когда истинно-отрицательные не имеют значения

## В8 — Работа с дисбалансом классов

Методы:
1. **Ресэмплинг:**
   - SMOTE (увеличение миноритарного класса)
   - Случайное уменьшение мажоритарного класса

2. **Веса классов:**
   - Больше штрафовать за ошибки на миноритарном классе
   - Большинство классификаторов sklearn поддерживают `class_weight='balanced'`

3. **Корректировка порога:**
   - Уменьшить порог для увеличения полноты
   - Оптимизировать порог на валидационном наборе

4. **Ансамблевые методы:**
   - Сбалансированный случайный лес
   - EasyEnsemble, BalancedBagging

5. **Использование подходящих метрик:**
   - F1-мера вместо точности
   - PR-AUC вместо ROC-AUC

**Ссылки:**
- [Матрица ошибок - Википедия](https://ru.wikipedia.org/wiki/Матрица_ошибок)
- [Receiver Operating Characteristic - Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)

---
## В9 — Обработка неизвестных категорий в продакшене

Проблема: Модель встречает категорию, которую она никогда не видела во время обучения.

Пример:
- Обучение: категории [A, B, C]
- Продакшен: появляется новая категория D


### 1. OneHotEncoder с `handle_unknown='ignore'`

```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown='ignore')
```

Поведение: Неизвестная категория → вектор из нулей
- Фактически рассматривается как "нейтральная"
- Модель использует только другие признаки


### 2. Возврат к самой частой категории

Во время инференса:
```python
if category not in known_categories:
    category = most_frequent_category
```

Когда использовать: Когда категории достаточно похожи


### 3. Добавление категории 'Unknown' во время обучения

Стратегия:
- Во время обучения добавить синтетическую категорию "unknown"
- Присвоить ей небольшую долю обучающих данных
- ИЛИ: Отложить некоторые категории как "неизвестные"

Преимущество: Модель учится явно обрабатывать неизвестные


### 4. Target Encoding с возвратом к глобальному среднему

Target Encoding:
```python
category_means = df.groupby('category')['target'].mean()
```

Для неизвестной категории:
```python
if category in category_means:
    value = category_means[category]
else:
    value = global_mean # Возврат к глобальному среднему
```


### 5. Подход на основе эмбеддингов

Для категорий с высокой кардинальностью:
- Использовать эмбеддинги сущностей (нейронные сети)
- Аппроксимировать неизвестную категорию ближайшим известным эмбеддингом
- ИЛИ: Использовать хэш-трюк для отображения в фиксированное пространство


### 6. Иерархические категории

Если категории имеют иерархию:
```
Продукт → Категория → Подкатегория
"Новая модель телефона" → "Электроника" → "Телефоны"
```

Возврат к родительской категории, если конкретная подкатегория неизвестна


### Лучшие практики

✅ Мониторинг: Отслеживать частоту неизвестных категорий
✅ Переобучение: Периодически переобучать с новыми категориями
✅ Оповещение: Настроить оповещения, когда неизвестные превышают порог
✅ A/B-тестирование: Сравнивать различные стратегии обработки

**Ссылки:**
- [OneHotEncoder Documentation - sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)
- [Entity Embeddings of Categorical Variables](https://arxiv.org/abs/1604.06737)

---
## В6 — Линейная регрессия

**Формулировка модели**: Матричная форма

$$\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$$

Предположения (LINE)

| Предположение | Описание | Диагностика |
|---|---|---|
| **L**inearity (Линейность) | Линейная зависимость | График остатков против предсказанных значений |
| **I**ndependence (Независимость) | Независимые наблюдения | Тест Дарбина-Уотсона |
| **N**ormality (Нормальность) | Нормальные ошибки | Q-Q plot |
| **E**qual variance (Равная дисперсия) | Гомоскедастичность | Тест Бреуша-Пагана |

Интерпретация коэффициентов

- $\beta_0$ (Intercept): Ожидаемое y, когда все предикторы = 0
- $\beta_j$ (Slope): Ожидаемое изменение y при увеличении x_j на одну единицу, при прочих равных


## Методы оптимизации

### OLS (Аналитическое решение)

$$\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$$

Сложность: O(np² + p³)

Использовать когда: n < 10,000, p < 1,000


### Градиентный спуск

$$\boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} - \eta \nabla_{\boldsymbol{\beta}} J$$

**Градиент для MSE:**
$$\nabla_{\boldsymbol{\beta}} J = -\frac{2}{n}\mathbf{X}^T(\mathbf{y} - \mathbf{X}\boldsymbol{\beta})$$

Варианты: Пакетный ГС, Стохастический ГС, Мини-пакетный ГС

Использовать когда: Очень большие наборы данных


## Регуляризация

**Ridge (L2)**

$$\min \|\mathbf{y} - \mathbf{X}\boldsymbol{\beta}\|^2 + \lambda\|\boldsymbol{\beta}\|_2^2$$

**Аналитическое решение:**

$$\hat{\boldsymbol{\beta}}_{ridge} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}$$

- Сжимает коэффициенты к нулю
- Справляется с мультиколлинеарностью
- Никогда не обнуляет признаки

**Lasso (L1)**

$$\min \|\mathbf{y} - \mathbf{X}\boldsymbol{\beta}\|^2 + \lambda\|\boldsymbol{\beta}\|_1$$

- Создает разреженные решения (некоторые β = 0)
- Автоматический отбор признаков
- Нет аналитического решения

**ElasticNet**

$$\min \|\mathbf{y} - \mathbf{X}\boldsymbol{\beta}\|^2 + \lambda_1\|\boldsymbol{\beta}\|_1 + \lambda_2\|\boldsymbol{\beta}\|_2^2$$

- Сочетает отбор (L1) со стабильностью (L2)
- Группирует коррелированные переменные


| Метод | Отбор признаков | Мультиколлинеарность | Решение |
|---|---|---|---|
| Ridge | Нет | Отлично | Аналитическое |
| Lasso | Да | Плохо | Итерационное |
| ElasticNet | Да | Хорошо | Итерационное |

Геометрическая интерпретация

Решение OLS $\hat{y} = X \hat{\beta}$ является **ортогональной проекцией** y на пространство столбцов X. Остатки ортогональны этому пространству: $X^{op} e = 0$.

**Визуально:** В p+1 мерном пространстве предсказанные значения лежат в p-мерном подпространстве, натянутом на столбцы X. Вектор остатков перпендикулярен этому подпространству.


## В8 — Регуляризация: L1 vs L2

Почему нужна регуляризация - **без регуляризации модели могут:**
- Запоминать обучающие данные (переобучение)
- Учить шум вместо закономерностей
- Иметь нестабильные, большие веса
- Плохо обобщаться на новые данные

### L1 (Lasso) Регуляризация

**Функция потерь:**

$$\text{Loss} + \lambda \sum_i |w_i|$$

Градиент:

$$\frac{\partial}{\partial w_i} = \lambda \cdot \text{sign}(w_i)$$

Постоянный градиент (величины λ) независимо от размера веса

Эффект:
- Разреженные решения: Многие веса точно равны нулю
- Отбор признаков: Автоматически исключает неважные признаки
- Интерпретируемость: Меньше признаков в итоговой модели


### L2 (Ridge) Регуляризация

Функция потерь:

$$\text{Loss} + \lambda \sum_i w_i^2$$

Градиент:

$$\frac{\partial}{\partial w_i} = 2\lambda w_i$$

Пропорциональный градиент (уменьшается по мере приближения w к 0)

**Эффект:**
- Сжимает все веса к нулю
- Редко обнуляет их полностью
- Хорошо справляется с мультиколлинеарностью
- Все признаки остаются в модели


### ПОЧЕМУ L1 создает разреженность, а L2 нет

**Алгебраическая интуиция**

L1:
- Постоянный "толчок" к нулю:

$$\lambda \cdot \text{sign}(w)$$

- Даже крошечные веса получают тот же толчок → достигают нуля

L2:
- Пропорциональное "притяжение":

$$2\lambda w$$

- Маленькие веса получают крошечное притяжение → редко достигают нуля

**Геометрическая интуиция**

Области ограничений:
- L1: Форма ромба (имеет углы на осях)
- L2: Форма круга (гладкая, без углов)

Оптимизация:
- Контуры функции потерь пересекают ромб L1 **часто в углах** (где w=0 для некоторых измерений)
- Контуры редко попадают точно на ось для круга L2

Визуально: Острые углы L1 способствуют решениям, где многие веса = 0


### ElasticNet (L1 + L2)

$$\text{Loss} + \lambda_1 \sum_i |w_i| + \lambda_2 \sum_i w_i^2$$

Лучшее из обоих миров - сочетает:
- Отбор признаков (L1)
- Стабильность и обработку мультиколлинеарности (L2)



### Сравнительная таблица

| Свойство | L1 (Lasso) | L2 (Ridge) |
|---|---|---|
| **Разреженность** | Да (обнуляет веса) | Нет (сжимает, редко обнуляет) |
| **Отбор признаков** | Да | Нет |
| **Мультиколлинеарность** | Плохо | Отлично |
| **Интерпретируемость** | Высокая (меньше признаков) | Ниже |
| **Оптимизация** | Итерационная (нет аналитического решения) | Есть аналитическое решение |
| **Градиент** | Постоянная величина | Пропорционален весу |


Использовать L1, когда:
- Нужен автоматический отбор признаков
- Много нерелевантных признаков
- Важна интерпретируемость
- Нужны разреженные модели (память/скорость)

Использовать L2, когда:
- Все признаки потенциально полезны
- Присутствует мультиколлинеарность
- Предпочтительно гладкое распределение весов

Использовать ElasticNet, когда:
- Нужно лучшее из обоих
- Многомерные данные с группами коррелированных признаков

**Ссылки:**
- [Regularization in Machine Learning - Wikipedia](https://en.wikipedia.org/wiki/Regularization_(mathematics))
- [Lasso vs Ridge - Towards Data Science](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b)

---
## В9 — Метрики линейной регрессии


### Средняя абсолютная ошибка (MAE)

$$\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$

**Преимущества:**
- Легко интерпретировать (те же единицы, что и у цели)
- Устойчива к выбросам
- Все ошибки взвешиваются одинаково

**Недостатки:**
- Недифференцируема в нуле (сложнее оптимизация)
- Менее чувствительна к большим ошибкам

**Когда использовать:** Когда выбросы не должны доминировать, нужна интерпретируемая метрика


### Среднеквадратичная ошибка (MSE)

$$\text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

**Преимущества:**
- Дифференцируема везде
- Сильно штрафует за большие ошибки
- Широко используется, хорошо изучена

**Недостатки:**
- Единицы в квадрате (трудно интерпретировать)
- Чувствительна к выбросам


### Корень из среднеквадратичной ошибки (RMSE)

Самая распространенная метрика регрессии

$$\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

**Преимущества:**
- Те же единицы, что и у цели (интерпретируема)
- Штрафует за большие ошибки
- Дифференцируема

**Недостатки:**
- Все еще чувствительна к выбросам



### Средняя абсолютная процентная ошибка (MAPE)

$$\text{MAPE} = \frac{100\%}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

**Преимущества:**
- Независима от масштаба (можно сравнивать на разных наборах данных)
- Легко интерпретировать (процент)

**Недостатки:**
- Неопределена при y=0
- Асимметрична: Штрафует за переоценку больше, чем за недооценку
- Смещена в сторону недооценки

**Когда использовать:** Когда относительная ошибка важнее абсолютной


### $R^2$ (Коэффициент детерминации)

$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$$


Интерпретация $R^2$:
- $R^2 = 0$: Модель не лучше, чем среднее
- $R^2 = 1$: Идеальное соответствие
- $R^2 < 0$: Модель хуже, чем среднее (переобучение)

Обнаружение мультиколлинеарности - VIF (Фактор инфляции дисперсии):

$$VIF_j = \frac{1}{1 - R_j^2}$$

Где $R_j^2$ - это $R^2$ из регрессии $X_j$ на все остальные предикторы.

| VIF | Интерпретация |
|---|---|
| 1 | Нет корреляции |
| 1-5 | Умеренная |
| 5-10 | Высокая |
| >10 | Серьезная |

Вызываемые проблемы:
- Завышенные стандартные ошибки
- Нестабильные оценки коэффициентов
- Сложная интерпретация

Решения:
- Удалить избыточные переменные
- Использовать PCA
- Применить регуляризацию Ridge/ElasticNet


**Преимущества:**
- Нормализован (диапазон 0-1... обычно)
- Указывает долю объясненной дисперсии

**Недостатки:**
- Всегда увеличивается с добавлением признаков (используйте скорректированный R²)
- Может быть отрицательным на тестовом наборе


### Скорректированный $R^2$

$$R_{adj}^2 = 1 - \frac{(1-R^2)(n-1)}{n-p-1}$$

Где:
- n = размер выборки
- p = количество предикторов

Штрафует за добавление признаков, которые не улучшают соответствие значительно


### Потери Хьюбера (Устойчивая альтернатива)

$$L_\delta(y, \hat{y}) = \begin{cases}
\frac{1}{2}(y - \hat{y})^2 & \text{если } |y - \hat{y}| \leq \delta \\
\delta(|y - \hat{y}| - \frac{1}{2}\delta) & \text{в противном случае}
\end{cases}$$

**Поведение:**
- Квадратична для малых ошибок (как MSE)
- Линейна для больших ошибок (как MAE)
- **Устойчива к выбросам**, оставаясь при этом дифференцируемой


### Руководство по выбору метрики

| Сценарий | Рекомендуемая метрика |
|---|---|
| Присутствуют выбросы | MAE, Хьюбер |
| Нет выбросов, нужна дифференцируемость | MSE, RMSE |
| Нужна независимость от масштаба | MAPE (если нет нулей), R² |
| Нужна объясненная дисперсия | R², Скорректированный R² |
| Большие ошибки очень дороги | MSE, RMSE |
| Сравнение моделей | R², Скорректированный R² |

**Ссылки:**
- [Regression Validation Metrics - scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)

---
## В10 — Градиентный бустинг

Основной принцип - **Последовательно добавлять слабые ученики**, каждый из которых исправляет ошибки предыдущего ансамбля, Принцип аддитивной модели

$$F_m(x) = F_{m-1}(x) + \eta \cdot h_m(x)$$

Где:
- $F_m$ = ансамбль после m деревьев
- $\eta$ = скорость обучения (сжатие)
- $h_m$ = новое дерево, обученное на псевдо-остатках

Алгоритм

**1. Инициализация:** $F_0(x) = \text{константа}$ (например, среднее для регрессии)

Для MSE:

$$ \ F_0(x) = \mathbb{E}[y] 
$$

Для log-loss:

$$ \ F_0(x) = \log\left(\frac{p}{1 - p}\right), \quad \text{где } p = \mathbb{E}[y] 
$$

**2. Для m = 1 до M:**
   - **Вычислить псевдо-остатки:** 

$$r_{im} = -\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\bigg|_{F=F_{m-1}}$$
   
   - Обучить дерево $h_m$ на остатках $r_{im}$
   - Обновить: $F_m = F_{m-1} + \eta \cdot h_m$

3. Вывод: $F_M(x)$

**Для потерь MSE**

Потери: $L(y, F) = \frac{1}{2}(y - F)^2$

Псевдо-остаток: $r = y - F_{m-1}(x)$ (обычный остаток)

Интуиция: Обучить следующее дерево на том, что мы до сих пор ошибались

**Для Log-Loss (Классификация)**

Потери: $L(y, F) = -[y\log(p) + (1-y)\log(1-p)]$ где $p = \sigma(F)$

Псевдо-остаток: $r = y - \sigma(F_{m-1}(x))$


### Техники регуляризации

#### 1. Скорость обучения (Сжатие)

$$F_m = F_{m-1} + \eta \cdot h_m, \quad 0 < \eta \leq 1$$

Меньшая $\eta$:
- Нужно больше деревьев
- Лучшее обобщение
- **Типично:** 0.01 - 0.3


#### 2. Ограничения на деревья

- Максимальная глубина: 3-8 (неглубокие деревья предотвращают переобучение)
- Минимальное количество примеров в листе
- Максимальное количество листовых узлов


#### 3. Подвыборка (Стохастический ГБ)

 Уменьшает переобучение, добавляет случайность

- Выборка строк: Использовать случайные 50-80% данных для каждого дерева
- Выборка столбцов: Использовать случайные признаки для каждого дерева/разбиения


#### 4. Регуляризация XGBoost

$$\Omega(h) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^{T} w_j^2$$

Где:
- $T$ = количество листьев, штрафует за размер дерева
- $w_j$ = веса листьев
- $\gamma$ = штраф за сложность, препятствует добавлению новых листьев: разбиение должно уменьшить потери как минимум на $\gamma$
- $\lambda$ = L2 на веса, сжимает предсказания и предотвращает экстремальные значения в листьях


### Градиентный бустинг vs Случайный лес

| Аспект | ГБ | СЛ |
|---|---|---|
| **Обучение** | Последовательное | Параллельное |
| **Уменьшает** | Смещение | Дисперсию |
| **Базовые ученики** | Неглубокие деревья (3-8) | Глубокие деревья |
| **Риск переобучения** | Выше | Ниже |
| **Точность** | Часто лучше | Хорошая |
| **Скорость** | Медленнее обучение | Быстрее обучение |

* Когда использовать ГБ: Максимальная точность, готовность к настройке
* Когда использовать СЛ: Быстрый базовый уровень, меньше настроек


### Современные реализации

**XGBoost:**
- Использует градиент + Гессиан (2-я производная)
- Регуляризованная целевая функция
- Обрабатывает пропущенные значения
- Гистограммные разбиения

**LightGBM:**
- Рост по листьям (быстрее, но рискованнее)
- GOSS (Gradient-based One-Side Sampling)
- EFB (Exclusive Feature Bundling)

**CatBoost:**
- Упорядоченный бустинг (предотвращает утечку)
- Нативная обработка категориальных признаков
- Симметричные деревья

**Ссылки:**
- [Градиентный бустинг - Википедия](https://ru.wikipedia.org/wiki/Градиентный_бустинг)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)

---
## В11 — Компромисс смещения-дисперсии

* [разложение смещение-дисперсия](https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition)
* [объяснение компромисса смещение-дисперсия](https://www.linkedin.com/feed/update/groupPost:961087-7266231655042838528)

TL;DR:

- **Смещение (Bias)** = ошибка от **неправильных предположений** в модели.
- **Дисперсия (Variance)** = ошибка от **чувствительности к малым изменениям** в обучающих данных.
- Вы хотите **сбалансировать** оба для лучшей производительности.


**Высокое смещение (недообучение):** (классификация)

- Модель слишком проста, чтобы уловить закономерности.
- Неправильно классифицирует многие примеры — плохая производительность как на **обучающем, так и на тестовом наборах**.
- Пример: Использование логистической регрессии на данных со сложными нелинейными границами.

**Высокая дисперсия (переобучение):** (классификация)

- Модель слишком сложна и подстраивается под шум в обучающих данных.
- Очень хорошая производительность на **обучающих данных**, но плохое обобщение на **тестовых данных**.
- Пример: Глубокое дерево решений, идеально классифицирующее обучающие данные, но не справляющееся с новыми.

| Сложность модели | Смещение ↓ | Дисперсия ↑ |
|---|---|---|
| Простая модель | Высокое | Низкая |
| Сложная модель | Низкое | Высокая |

Цель — найти золотую середину, где оба показателя достаточно низки для хорошего обобщения.

**На практике**:

- Используйте **кросс-валидацию** для оценки ошибки обобщения.
- Техники, такие как **регуляризация**, **обрезка (pruning)** или использование **ансамблевых методов** (например, случайные леса), помогают контролировать этот компромисс.
- Инструменты визуализации, такие как **кривые обучения**, могут показать, имеете ли вы дело с высоким смещением или высокой дисперсией.

Случайный лес - низкое смещение (глубокие деревья), высокая дисперсия

**Математическое разложение**

$$\text{Ожидаемая ошибка} = \text{Смещение}^2 + \text{Дисперсия} + \text{Неустранимая ошибка}$$


Для квадратичной функции потерь ожидаемая ошибка предсказания раскладывается как:

$$\text{EPE}(x) = \underbrace{(f(x) - E[\hat{f}(x)])^2}_{\text{Смещение}^2} + \underbrace{E[(\hat{f}(x) - E[\hat{f}(x)])^2]}_{\text{Дисперсия}} + \underbrace{\sigma^2}_{\text{Неустранимая}}$$

Где:
- Смещение²: Насколько среднее предсказание отличается от истинной функции
- Дисперсия: Насколько предсказания варьируются на разных обучающих наборах
- Неустранимая ошибка: Внутренний шум в данных (σ²)

**Смещение:** Ошибка от неверных предположений
- Высокое смещение = недообучение
- Модель слишком проста

**Дисперсия:** Ошибка от чувствительности к обучающим данным
- Высокая дисперсия = переобучение
- Модель слишком сложна

**Неустранимая ошибка:** Шум в данных (σ²)


### Примеры

**Модели с высоким смещением:**
- Линейная регрессия на нелинейных данных
- Наивный Байес с сильными предположениями
- Логистическая регрессия с недостаточным количеством признаков
- Неглубокие деревья решений

**Модели с высокой дисперсией:**
- Глубокие деревья решений без обрезки
- KNN с k=1
- Полиномиальная регрессия высокой степени
- Нейронные сети без регуляризации


### Управление компромиссом

**Уменьшить смещение:**
- Добавить признаки / сложность
- Уменьшить регуляризацию
- Увеличить емкость модели

**Уменьшить дисперсию:**
- Добавить регуляризацию (L1/L2)
- Уменьшить количество признаков
- Получить больше обучающих данных
- Ансамблевые методы


### Ансамблевые методы

#### Бэггинг (Уменьшает дисперсию)

**Принцип:** Обучить несколько моделей на бутстрэп-выборках, усреднить предсказания

$$\hat{f}_{bag}(x) = \frac{1}{B}\sum_{b=1}^{B} \hat{f}_b(x)$$

**Уменьшение дисперсии:**
$$\text{Var}(\hat{f}_{bag}) = \rho\sigma^2 + \frac{1-\rho}{B}\sigma^2$$


**Ключевая идея:** Усреднение уменьшает дисперсию, не увеличивая смещение. Лучше всего работает с базовыми моделями с высокой дисперсией (глубокие деревья).

**Улучшение случайного леса:**
- Подвыборка признаков при каждом разбиении уменьшает корреляцию ρ между деревьями
- Обычно используют √p признаков для классификации, p/3 для регрессии
- Дальнейшее уменьшение дисперсии по сравнению с простым бэггингом

**Ошибка Out-of-Bag (OOB):**
Каждое дерево обучается на ~63% данных, можно валидировать на оставшихся ~37% без отдельного валидационного набора.


#### Бустинг (Уменьшает смещение)

**Принцип:** Последовательно обучать модели, каждая из которых исправляет ошибки предыдущей

**Примеры:** Градиентный бустинг, AdaBoost


**Механизм уменьшения смещения:**
- Начинаем с модели с высоким смещением (неглубокое дерево)
- Каждая итерация подгоняется под псевдо-остатки (ошибки текущего ансамбля)
- Систематически исправляет там, где текущая модель работает плохо
- Постепенно строит сложную границу решения

**Эффект:** В основном уменьшает смещение; может увеличить дисперсию при чрезмерном бустинге.

**Ключевое отличие от бэггинга:**
- Бэггинг: Независимые модели, уменьшает дисперсию
- Бустинг: Зависимые модели, уменьшает смещение


#### Стекинг

**Принцип:** Обучить мета-модель на предсказаниях базовых моделей


Архитектура:
- Уровень-0: Обучить несколько разнообразных базовых моделей h₁(x), ..., h_K(x)
- Уровень-1: Обучить мета-модель g на предсказаниях Уровня-0

$$\hat{y}_{stack} = g(h_1(x), h_2(x), ..., h_K(x))$$

**Избегание переобучения:**
Использовать K-блочную кросс-валидацию для генерации предсказаний вне фолдов для обучения мета-модели. **Критически важно:** Никогда не обучать мета-модель на тех же предсказаниях, которые использовались для обучения базовых моделей.

**Процесс:**
1. Разделить обучающие данные на K фолдов
2. Для каждой базовой модели:
   - Обучить на K-1 фолдах, предсказать на отложенном фолде
   - Повторить K раз, чтобы получить предсказания вне фолдов для всего обучающего набора
3. Обучить мета-модель на объединенных предсказаниях вне фолдов
4. Для тестовых данных: Усреднить предсказания от K базовых моделей, обученных на разных фолдах

**Выбор базовой модели:**
Лучше всего работают разнообразные модели (разные алгоритмы, гиперпараметры). Распространенные комбинации:
- Линейная модель + Дерево + Нейронная сеть
- XGBoost + LightGBM + CatBoost

**Мета-модель:**
Обычно простая модель (Логистическая регрессия, Ridge), чтобы избежать переобучения.


### Когда что использовать

| Сценарий | Рекомендуемый метод | Обоснование |
|---|---|---|
| Базовые модели с высокой дисперсией (глубокие деревья) | Бэггинг / Случайный лес | Уменьшение дисперсии |
| Базовые модели с высоким смещением (линейные, неглубокие деревья) | Бустинг | Уменьшение смещения |
| Доступны разнообразные типы моделей | Стекинг | Сочетает разные сильные стороны |
| Максимальная точность, соревнования | Градиентный бустинг + Стекинг | State-of-the-art |
| Быстрый базовый уровень, надежность | Случайный лес | Работает "из коробки" |
| Нужно быстрое обучение | Случайный лес | Параллелизуемый |



### Высокое смещение vs Высокая дисперсия

**Высокое смещение, низкая дисперсия (Недообучение):**
- Линейная регрессия на нелинейных данных
- Неглубокие деревья решений
- Сильно регуляризованные модели (высокий λ)
- **Симптом:** Высокая ошибка на обучении И на тесте
- **Решение:** Увеличить сложность модели, уменьшить регуляризацию

**Низкое смещение, высокая дисперсия (Переобучение):**
- Глубокие необрезанные деревья решений
- KNN с k=1
- Полиномиальная регрессия высокой степени
- Нейронные сети без регуляризации
- **Симптом:** Низкая ошибка на обучении, высокая на тесте
- **Решение:** Регуляризация, больше данных, уменьшение сложности

**Ссылки:**
- [Bias-Variance Tradeoff - Wikipedia](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)

---
## В12 — Рекомендательные системы


**Цель:** Предсказать предпочтения пользователя для элементов, с которыми он еще не взаимодействовал

**Матрица взаимодействий R:**
- Строки: Пользователи (m пользователей)
- Столбцы: Элементы (n элементов)
- Записи: Рейтинги, клики, покупки или неявная обратная связь

**Проблемы:**
- Разреженность: Обычно >99% пропущенных значений
- Холодный старт: Новые пользователи/элементы без истории
- Масштабируемость: Миллионы пользователей × элементов

### Основные подходы

Коллаборативная фильтрация
- На основе пользователей: Найти похожих пользователей
- На основе элементов: Найти похожие элементы
- Матричная факторизация: Модели скрытых факторов

На основе контента
- Рекомендовать элементы, похожие на те, которые понравились пользователю
- На основе признаков элементов

**Метод:** Косинусное сходство между векторами признаков элементов

$$\text{sim}(i, j) = \frac{\mathbf{v}_i \cdot \mathbf{v}_j}{||\mathbf{v}_i|| \cdot ||\mathbf{v}_j||}$$

**Преимущества:**
- Нет холодного старта для новых пользователей (рекомендации на основе текущего взаимодействия)
- Прозрачные объяснения
- Стабильность со временем

**Недостатки:**
- Ограниченное разнообразие (фильтр-пузырь)
- Требуются признаки элементов


#### Гибридный

- Сочетание коллаборативного + контентного подходов


### Ключевые алгоритмы RecSys

#### K-ближайших соседей (KNN)

* На основе пользователей: Найти K самых похожих пользователей, предсказать рейтинг как взвешенное среднее
* На основе элементов: Найти K самых похожих элементов, которые оценил пользователь, предсказать как взвешенное среднее
* Сходство: Косинус, корреляция Пирсона, Жаккар

Плюсы: Простой, интерпретируемый
Минусы: Не масштабируется, чувствителен к разреженности


#### Матричная факторизация

$$\hat{r}_{ui} = \mu + b_u + b_i + \mathbf{p}_u^T \mathbf{q}_i$$

Где:
- μ = глобальное среднее
- b_u, b_i = смещение пользователя/элемента
- p_u, q_i = скрытые факторы

**Потери:**
$$\min \sum_{(u,i) \in observed} (r_{ui} - \hat{r}_{ui})^2 + \lambda(||p_u||^2 + ||q_i||^2)$$



#### ALS (Alternating Least Squares)

**Алгоритм:**
1. Зафиксировать Q, решить для P (аналитическое решение)
2. Зафиксировать P, решить для Q (аналитическое решение)
3. Чередовать до сходимости

Плюсы: Параллелизуемый, обрабатывает неявную обратную связь
Минусы: Предполагает, что все пропущенные = отрицательные


#### BPR (Bayesian Personalized Ranking)

**Цель:** Максимизировать попарное ранжирование

$$\max \sum_{(u,i,j)} \log \sigma(\hat{r}_{ui} - \hat{r}_{uj})$$

Где:
- i = положительный элемент (наблюдаемый)
- j = отрицательный элемент (ненаблюдаемый)

Лучше для неявной обратной связи (клики, просмотры)


#### На основе сессий

**Подход:** Предсказать следующее действие на основе текущей последовательности сессии

**Метод:**
- RNN (GRU, LSTM) для моделирования последовательностей
- Трансформеры (само-внимание над сессией)
- Графовые нейронные сети (сессия как граф)

Сферы применения:
- Просмотр товаров в электронной коммерции
- Стриминг музыки (следующая песня)
- Рекомендации видео

Преимущества:
- Улавливает краткосрочные намерения
- Не требуется профиль пользователя
- Работает для анонимных пользователей


### Ключевые метрики


#### Precision@K
$$\text{Precision@K} = \frac{|\text{Релевантные элементы в топ K}|}{K}$$

**Интерпретация:** Какая доля из K рекомендаций понравилась пользователю?

#### Recall@K
$$\text{Recall@K} = \frac{|\text{Релевантные элементы в топ K}|}{|\text{Все релевантные элементы}|}$$

**Интерпретация:** Какую долю из всех элементов, которые понравились бы пользователю, мы порекомендовали?

#### MAP (Mean Average Precision)
$$\text{MAP@K} = \frac{1}{|U|}\sum_{u=1}^{|U|} \frac{1}{\min(m_u, K)} \sum_{k=1}^{K} P(k) \cdot \text{rel}(k)$$

Где P(k) = точность на позиции k, rel(k) = 1, если элемент k релевантен

**Интерпретация:** Вознаграждает размещение релевантных элементов выше в ранжировании

#### NDCG (Normalized Discounted Cumulative Gain)
$$\text{DCG@K} = \sum_{i=1}^{K} \frac{2^{rel_i} - 1}{\log_2(i+1)}$$

$$\text{NDCG@K} = \frac{DCG@K}{IDCG@K}$$

Где IDCG = идеальный DCG (идеальное ранжирование)

**Интерпретация:**
- Учитывает градированную релевантность (1-5 звезд)
- Штрафует за релевантные элементы, появляющиеся ниже
- Нормализован до [0, 1]


### Проблема холодного старта

**Новый пользователь:**
- Рекомендации на основе популярности
- Запросить начальные предпочтения
- Использовать демографическую информацию

**Новый элемент:**
- Контентные признаки
- Курирование экспертами

**Ссылки:**
- [Рекомендательные системы - Википедия](https://ru.wikipedia.org/wiki/Рекомендательная_система)

---
## В13 — Предобработка текста (Разреженный поиск)


### Конвейер предобработки

#### 1. Токенизация
Разделение текста на токены (слова, подслова, символы)

**Методы:**
- Разделение по пробелам
- На основе правил (зависит от языка)
- Подслова: BPE, WordPiece


#### 2. Приведение к нижнему регистру
`"Python" → "python"`

**Компромисс:** Теряется информация (компания Apple vs фрукт apple)


#### 3. Очистка
- Удаление HTML-тегов
- Удаление специальных символов
- Нормализация пробелов
- Удаление/нормализация чисел


#### 4. Удаление стоп-слов
Удаление общих слов: "the", "is", "a", "an"

**Компромисс:**
- ✅ Уменьшает размер индекса
- ❌ Может повредить фразовые запросы ("to be or not to be")


#### 5. Стемминг / Лемматизация

**Стемминг (Портер, Сноуболл):**
```
running → run
happiness → happi # Не настоящее слово!
```

**Лемматизация (WordNet):**
```
running → run
better → good
geese → goose # Настоящие слова
```


| Аспект | Стемминг | Лемматизация |
|---|---|---|
| Метод | На основе правил | Словарь + POS |
| Скорость | Быстрый | Медленная |
| Вывод | Может быть не словом | Всегда валидное слово |
| Точность | Ниже | Выше |


### Мешок слов (BoW)

**Представление:** Документ как вектор частот слов

**Свойства:**
- Игнорирует порядок слов
- Игнорирует семантику
- Высокоразмерный, разреженный
- Простой базовый уровень


### TF-IDF

$$\text{TF-IDF}(t, d, D) = \text{TF}(t, d) \times \text{IDF}(t, D)$$

**Частота термина:**
$$\text{TF}(t, d) = \frac{f_{t,d}}{\sum_{t'} f_{t',d}}$$

Или: $\text{TF} = \log(1 + f_{t,d})$ (сублинейная)

**Обратная частота документа:**
$$\text{IDF}(t) = \log\frac{N}{|\{d : t \in d\}|}$$

**Интуиция:** Высокий TF-IDF = термин часто встречается в документе, но редко в корпусе


### BM25 (Best Matching 25)

Формула:

$$\text{score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})}$$

Где:
- $q_i$: Термины запроса
- $f(q_i, D)$: Частота термина q_i в документе D
- $\|D\|$: Длина документа
- avgdl: Средняя длина документа в корпусе
- **k₁:** Параметр насыщения частоты термина (типично: 1.2-2.0)
- **b:** Параметр нормализации длины (типично: 0.75)

**Компонент IDF:**

$$\text{IDF}(q_i) = \log \frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}$$

Где N = общее количество документов, n(q_i) = количество документов, содержащих q_i

**Ключевые особенности:**

1. **Насыщение термина:** Уменьшающаяся отдача от повторяющихся терминов
   - 1 вхождение: вносит большой вклад
   - 100 вхождений: не вносит в 100 раз больше

2. **Нормализация длины:** Штрафует длинные документы
   - Предотвращает доминирование длинных документов
   - b=0: Нет нормализации
   - b=1: Полная нормализация

Улучшения по сравнению с TF-IDF:
- Нелинейная частота термина (насыщение)
- Лучшая нормализация длины
- Настраиваемые параметры

Применение: Стандартный базовый уровень для поиска по тексту, используется в Elasticsearch, Lucene

Для многомерных разреженных данных хорошо работает косинусное сходство


### Инвертированный индекс

**Структура:** Термин → Список (DocID, метаданные)

Пример:
```
"cat": [(Doc1, TF=2, позиции=[5,12]), (Doc3, TF=1, позиции=[7])]
"dog": [(Doc2, TF=1, позиции=[3]), (Doc3, TF=3, позиции=[2,8,15])]
```

Обработка запроса:
1. Найти термины запроса в индексе
2. Получить списки postings
3. Вычислить оценки (BM25, TF-IDF)
4. Ранжировать и вернуть топ-K

Оптимизации:
- Пропускающие указатели: Перепрыгивать через документы, которые не могут совпасть
- Сжатие: Varbyte кодирование, дельта-кодирование
- Кэширование: Часто запрашиваемые термины

**Сложность:**
- Без индекса: $\( O(N \times M) \)$, где $\( N \)$ = количество документов, а $\( M \)$ = средняя длина документа
- С индексом: $\( O(K \times L) \)$, где $\( K \)$ = количество терминов запроса, а $\( L \)$ = средняя длина списка postings



### Word2Vec


| Аспект | CBOW | Skip-gram |
|---|---|---|
| **Вход** | Контекстные слова | Целевое слово |
| **Выход** | Целевое слово | Контекстные слова |
| **Скорость** | Быстрее обучается | Медленнее |
| **Редкие слова** | Хуже работает | Лучшее представление |
| **Требования к данным** | Работает с меньшим количеством данных | Требует больше данных |
| **Применение** | Большой корпус | Маленький-средний корпус |


**CBOW:** Предсказать целевое слово из контекста
**Skip-gram:** Предсказать контекст из целевого слова

**Ключевое отличие от BoW:**
- BoW: Разреженный, высокоразмерный, без семантики
- Word2Vec: Плотный (50-300d), улавливает семантическое сходство

**Семантические свойства:**
```
король - мужчина + женщина ≈ королева
Париж - Франция + Италия ≈ Рим
```

**Ограничения:**
- Один вектор на слово (нет многозначности)
- Обучен на статическом корпусе
- Нет обработки слов вне словаря



**Трюки обучения:**
- **Negative sampling:** Вместо softmax по всему словарю, сэмплировать K отрицательных слов
- **Иерархический softmax:** Двоичная древовидная структура для эффективного обучения


**Ссылки:**
- [TF-IDF - Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
- [BM25 - Wikipedia](https://en.wikipedia.org/wiki/Okapi_BM25)

---
## В14 — Векторный поиск

**Цель:** Отобразить текст/изображения/другие данные в плотные векторы, которые улавливают семантическое сходство


### Предобученные модели

**Текстовые эмбеддинги:**
- **Sentence-BERT (SBERT):** Сиамская архитектура, дообученный BERT для сходства предложений
- **Эмбеддинги OpenAI:** text-embedding-ada-002, text-embedding-3-small/large
- **BGE (BAAI General Embedding):** Современный открытый исходный код
- **E5:** Многоязычный, настроенный на инструкции
- **Cohere embed-v3:** Поддерживает сжатие для конкретных задач

**Мультимодальные:**
- **CLIP:** Совместный эмбеддинг текста и изображений
- **BLIP-2:** Визуальные вопросы и ответы


#### Методы дообучения

**Контрастивное обучение:**
Потери способствуют сближению похожих пар и отдалению непохожих

**Triplet Loss:**
$$L = \max(0, d(a, p) - d(a, n) + \text{margin})$$

Где a=якорь, p=положительный, n=отрицательный

**Майнинг сложных негативных примеров:**
Выбор сложных негативных примеров (высокое сходство, но нерелевантны) для лучшей дискриминации

**Адаптация к домену:**
Дообучение на данных конкретного домена (медицинские, юридические, научные)


### Метрики расстояния

#### Косинусное сходство
$$\text{cosine}(A, B) = \frac{A \cdot B}{||A|| \times ||B||}$$

**Диапазон:** [-1, 1] (обычно [0, 1] для семантических эмбеддингов)
**Косинусное расстояние:** 1 - косинусное сходство

**Использовать когда:**
- Направление важнее величины
- Текстовое сходство (эмбеддинги обычно нормализованы)


#### Евклидово расстояние
$$d_2(\mathbf{A}, \mathbf{B}) = ||\mathbf{A} - \mathbf{B}||_2 = \sqrt{\sum_{i=1}^{n}(A_i - B_i)^2}$$

**Использовать когда:**
- Величина имеет значение
- Низкоразмерные данные
- Кластеризация (K-means использует евклидово расстояние)


#### Скалярное произведение
$$\mathbf{A} \cdot \mathbf{B} = \sum_{i=1}^{n} A_i B_i$$

**Для нормализованных векторов:** Скалярное произведение = Косинусное сходство


**Использовать когда:** Нужны быстрые вычисления, векторы нормализованы

#### Манхэттенское расстояние (L1)
$$d_1(\mathbf{A}, \mathbf{B}) = \sum_{i=1}^{n} |A_i - B_i|$$

**Использовать когда:** Решетчатые пространства, устойчивость к выбросам


### Векторные базы данных

| База данных |
|---|---|
| **Milvus** | Распределенная, поддержка GPU, 10+ индексов |
| **Pinecone** | Полностью управляемая, бессерверная |
| **Weaviate** | GraphQL API, гибридный поиск |
| **Qdrant** | На Rust, фильтрация по полезной нагрузке |
| **Redis Vector** | В памяти, низкая задержка |
| **Chroma** | Встраиваемая, дружелюбная к разработчикам |

**Ключевые возможности:**
- CRUD операции с векторами
- Фильтрация по метаданным
- Гибридный поиск (плотный + разреженный)
- Шардирование и репликация
- ACID транзакции (некоторые)


### ANN (Приближенный поиск ближайших соседей)

Проклятие размерности: Почему ближайший сосед в 100D почти так же далек, как самый дальний?

Это явление происходит из-за разреженности данных в многомерном пространстве, что приводит к сходимости всех расстояний (т.е. разница между ближайшим и самым дальним соседями становится незначительной).

В низких измерениях (например, 2D или 3D) точки **относительно близки друг к другу**, и ближайший сосед **намного ближе**, чем самый дальний. Однако в **многомерном пространстве (100D+) данные экспоненциально разреживаются**, что приводит к тому, что все расстояния становятся похожими.

🔹 **Ключевая причина:**

- С увеличением размерности точки данных занимают больший объем.
- Среднее расстояние между точками увеличивается.
- Разница между ближайшей и самой дальней точками становится **незначительно малой** по сравнению с общим диапазоном расстояний.

Какой тип графика лучше всего подходит для визуализации выбросов в ваших обучающих данных? → Ящик с усами

Какое распределение данных будет релевантно для подбрасывания монеты? → Биномиальное распределение



#### HNSW (Hierarchical Navigable Small World)

**Структура:** Многоуровневый граф

**Сложность:** O(log n) в среднем

**Структура:** Граф с несколькими слоями
- Верхний слой: Разреженные, дальние связи
- Нижний слой: Плотный, полный граф

**Алгоритм поиска:**
1. Начать с верхнего слоя
2. Жадным образом двигаться к ближайшему соседу
3. Спуститься на следующий слой
4. Повторять до нижнего слоя

**Сложность:** O(log N) в среднем

**Плюсы:**
- Отличная полнота (>95% при правильных параметрах)
- Быстрые запросы
- Поддерживает инкрементальные обновления

**Минусы:**
- Высокое потребление памяти (хранит полный граф)
- Время построения может быть долгим

**Параметры:**
- **M:** Макс. количество соединений на узел (типично: 16-64)
- **efConstruction:** Глубина поиска во время построения (типично: 200-400)
- **efSearch:** Глубина поиска во время запроса (типично: 100-500)


#### IVF (Inverted File Index)

**Структура:** Кластеризация K-means + инвертированный индекс

1. Кластеризовать векторы на K разделов (k-means)
2. Присвоить каждый вектор ближайшему кластеру
3. Создать инвертированный индекс: ClusterID → Список векторов

**Поиск:** Искать только в топ-nprobe кластерах
1. Найти nprobe ближайших центроидов кластеров к запросу
2. Искать только векторы в этих кластерах
3. Вернуть топ-K в целом


**Сложность:** O(K + nprobe × N/K)

**Плюсы:**
- Хороший компромисс между полнотой и скоростью
- Меньше памяти, чем у HNSW
- Поддерживает ускорение на GPU

**Минусы:**
- Требуется фаза обучения
- Чувствителен к качеству кластеризации
- Не идеален для обновлений (требуется переобучение)

**Параметры:**
- **K:** Количество кластеров (типично: от √N до N/100)
- **nprobe:** Количество кластеров для поиска (типично: 10-100)


#### LSH (Locality Sensitive Hashing)

**Принцип:** Похожие векторы хэшируются в один и тот же бакет

**Распространенные семейства LSH:**
- **Случайная проекция:** для косинусного сходства
- **MinHash:** для сходства Жаккара
- **p-стабильные:** для расстояний L_p

**Алгоритм:**
1. Создать L хэш-таблиц с K хэш-функциями в каждой
2. Для запроса, хэшировать во все L таблиц
3. Получить кандидатов из совпадающих бакетов
4. Ранжировать кандидатов

**Плюсы:**
- Сублинейное время запроса O(N^ρ), где ρ < 1
- Постоянное время обновления
- Работает в очень высоких измерениях

**Минусы:**
- Ниже полнота, чем у HNSW/IVF
- Требуется много хэш-таблиц для хорошей полноты
- Разработка хэш-функции сложна


| Индекс | Полнота | Скорость | Память | Время построения | Обновления |
|---|---|---|---|---|---|
| **HNSW** | Отличная | Отличная | Высокая | Среднее | Хорошие |
| **IVF** | Хорошая | Хорошая | Средняя | Быстрое | Плохие |
| **LSH** | Умеренная | Умеренная | Средняя | Очень быстрое | Отличные |
| **Flat (Точный)** | Идеальная | Медленная | Низкая | Мгновенное | Отличные |

**Рекомендации:**
- **Статические данные, лучшая полнота:** HNSW
- **Динамические данные, частые обновления:** LSH
- **Большой масштаб, доступен GPU:** IVF с GPU
- **<100K векторов:** Рассмотрите точный поиск

**Ссылки:**
- [Approximate Nearest Neighbor - Wikipedia](https://en.wikipedia.org/wiki/Nearest_neighbor_search)

---
## В15 — Трансформеры


### Ограничения RNN/LSTM

**Рекуррентные нейронные сети:**
$$h_t = f(W_{hh} h_{t-1} + W_{xh} x_t)$$

**Проблемы:**

1. **Исчезающие градиенты:**
   - Градиенты экспоненциально затухают с расстоянием
   - Практическая длина контекста: ~100-500 токенов
   - LSTM/GRU помогают, но не решают проблему полностью

2. **Последовательная обработка:**
   - Нельзя распараллелить: h_t зависит от h_{t-1}
   - Время обучения O(T) для последовательности длиной T
   - GPU используется неэффективно

3. **Ограниченный контекст:**
   - Информация сжимается в скрытое состояние фиксированного размера
   - Трудно справляться с дальними зависимостями, могут обрабатывать ~100-500 токенов
   - Механизмы внимания добавлены как "заплатка"

**Улучшения LSTM:**
- Гейты (забывания, входа, выхода) помогают потоку градиентов
- Ограниченный контекст: Могут обрабатывать ~1000 токенов
- Все еще фундаментально последовательны

**Решения Трансформера:**

**Ключевое нововведение:** Заменить рекуррентность само-вниманием

- Параллельная обработка (все позиции одновременно)
- Прямые связи (внимание)
- Нет исчезновения градиентов
- Более длинный контекст (тысячи токенов)
- Время обучения O(1) на слой (O(log T) в целом с глубиной)

### Механизм само-внимания


**Вход:** Последовательность векторов X = [x₁, ..., x_n]


**Шаг 1: Линейные проекции**

Создать представления Query, Key, Value:
$$Q = XW^Q, \quad K = XW^K, \quad V = XW^V$$

Где W^Q, W^K, W^V ∈ ℝ^{d×d_k}

**Интуиция:**
- **Query:** "Что я ищу?"
- **Key:** "Что я содержу?"
- **Value:** "Какую информацию я имею?"


**Шаг 2: Масштабированное скалярное произведение**

Оценки внимания

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$


**Шаги:**
1. Вычислить логиты внимания: QK^T (каждый запрос × все ключи)
2. Масштабировать на √d_k
3. Применить softmax (преобразовать в вероятности)
4. Взвешенная сумма значений

**Почему масштабирование на √d_k:**
- Скалярные произведения растут с размерностью: Var(q·k) = d_k
- Без масштабирования: большие d_k → экстремальное насыщение softmax
- Градиенты исчезают, когда выходы softmax ≈ [0, 0, ..., 1, 0]

**Сложность:** O(n² × d), где n = длина последовательности, d = размерность


### Многоголовое внимание


**Мотивация:** Разные головы улавливают разные отношения (синтаксис, семантика, позиция)

$$\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O$$

Где:
$$\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$

**Параметры:**
- h: Количество голов (типично: 8-16)
- d_k = d_model / h (размерность на голову)

**Примеры специализаций:**
- Голова 1: Согласование подлежащего и сказуемого
- Голова 2: Семантическое сходство
- Голова 3: Позиционные отношения
- Голова 4: Разрешение кореферентности

**Преимущества:**
- Более богатые представления
- Ансамбль паттернов внимания
- Та же вычислительная стоимость (d_model разделяется между головами)


### Позиционное кодирование


**Проблема:** Само-внимание инвариантно к перестановкам — нужна информация о позиции

**Синусоидальное кодирование (оригинал):**
$$PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d}}\right)$$
$$PE_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d}}\right)$$

**Свойства:**
- Детерминированное
- Уникально для каждой позиции
- Относительная позиция кодируется: PE_{pos+k} является линейной функцией от PE_{pos}
- Экстраполируется на более длинные последовательности

**Обучаемые позиционные эмбеддинги:**
- Обучаемые эмбеддинги позиций (как в BERT)
- Не могут экстраполироваться за пределы длины обучения
- Часто работают лучше на практике

**Относительное позиционное кодирование:**
- Кодирование относительных расстояний (T5, DeBERTa)
- Лучшее обобщение по длине
- Более эффективно по параметрам


### Токенизация


#### Byte Pair Encoding (BPE)

**Алгоритм:**
1. Начать со словарного запаса символов
2. Итеративно объединять самую частую пару
3. Повторять до достижения нужного размера словаря

**Пример:**
```
Начальный: ["l", "o", "w", "e", "r"]
Объединить "e"+"r" → "er"
Объединить "er"+" " → "er "
...
Конечный: ["low", "er", " ", "wide", "st"]
```

**Используется в:** GPT-2, GPT-3, RoBERTa

#### WordPiece

**Отличие от BPE:**
Объединяет на основе увеличения правдоподобия, а не частоты

**Используется в:** BERT, DistilBERT

#### SentencePiece

**Ключевая особенность:** не зависит от языка, рассматривает пробел как символ

**Алгоритмы:** BPE или Unigram LM

**Используется в:** T5, XLNet, многоязычных моделях

**Преимущества:**
- Не требуется предварительная токенизация
- Работает для языков без пробелов
- Обратимый

**Ссылки:**
- [Attention Is All You Need - Paper](https://arxiv.org/abs/1706.03762)

---
## В16 — Температура при сэмплировании в LLM


### Формула температуры

$$P(x_i) = \frac{e^{z_i/\tau}}{\sum_j e^{z_j/\tau}}$$

Где:
- z_i = логиты из модели
- τ = температура


### Эффект температуры

**τ < 1 (низкая температура):**
- Более резкое распределение
- Более детерминировано
- Менее креативно

**τ = 1:**
- Исходные вероятности модели

**τ > 1 (высокая температура):**
- Более плоское распределение
- Более случайно
- Более креативно

**τ → 0:**
- Жадное декодирование (всегда выбирать токен с наивысшей вероятностью)


### Практические рекомендации

| Температура | Применение |
|---|---|
| 0.0 - 0.3 | Фактические вопросы и ответы, код, математика |
| 0.4 - 0.7 | Сбалансированный, общий чат |
| 0.8 - 1.2 | Креативное письмо, мозговой штурм |
| 1.5+ | Экспериментально, очень случайно |


### Другие методы сэмплирования

**Top-k:** Оставить только k наиболее вероятных токенов

Оставить только k наиболее вероятных токенов, перераспределить вероятность

**Алгоритм:**
1. Отсортировать токены по вероятности
2. Оставить топ k
3. Перенормировать
4. Сэмплировать

**Эффект:** Устраняет длинный хвост маловероятных токенов

**Типичное k:** 40-50


**Top-p (Nucleus):** Оставить наименьший набор с совокупной вероятностью ≥ p
- Адаптируется к уверенности модели
- Типичное p = 0.9-0.95

Оставить наименьший набор токенов с совокупной вероятностью ≥ p

**Алгоритм:**
1. Отсортировать токены по вероятности
2. Добавлять, пока сумма ≥ p
3. Перенормировать
4. Сэмплировать

**Преимущество перед Top-k:**
- Адаптируется к уверенности
- Высокая уверенность → меньше токенов
- Низкая уверенность → больше токенов


**Пример:**
- Высокая уверенность: "Столица Франции - ___" → ядро ≈ 1-2 токена
- Низкая уверенность: "Однажды в студеную зимнюю пору ___" → ядро ≈ 50+ токенов


**Штраф за повторение:** Уменьшить вероятность уже сгенерированных токенов
**Штраф за частоту:** Уменьшить на основе общей частоты в ответе
**Штраф за присутствие:** Уменьшить, если токен появился хотя бы раз


**Ссылки:**
- [Temperature Sampling - Hugging Face](https://huggingface.co/blog/how-to-generate)

---
## В17 — Контекстное окно


**Определение:** Максимальное количество токенов, которое модель может обработать


**Ограничения:**
- Память: O(n²) для внимания
- Вычисления: O(n² × d) на слой
- Позиционные кодировки могут не экстраполироваться


### Эволюция

- GPT-3: 2048 токенов
- GPT-3.5: 4096 токенов
- GPT-4: 8K → 32K → 128K токенов
- Claude 3: 200K токенов
- Gemini 1.5 Pro: 1M токенов


### Методы расширения

#### RoPE (Rotary Position Embedding)

**Принцип:** Кодировать позицию путем вращения векторов Q/K (запрос/ключ)


**Формула:**
$$f_q(x_m, m) = (W_q x_m) e^{im\theta}$$

Где θ - параметр частоты

**Преимущества:**
- Относительная позиция сохраняется во внутреннем произведении
- Лучшая экстраполяция, чем у обучаемых эмбеддингов

Ротационные позиционные эмбеддинги (RoPE) незаметно лежат в основе большинства современных LLM.
Это одна из причин, по которой модели с длинным контекстом действительно работают.

Почему это важно
- Внимание заботится об относительном расстоянии, а не об абсолютной позиции
- RoPE делает обобщение на длинные контексты гораздо более стабильным, чем обучаемые позиционные эмбеддинги

Как работает RoPE
- Запросы и ключи разделяются на пары измерений
- Каждая пара рассматривается как 2D-вектор
- Эти векторы вращаются на угол, зависящий от позиции токена
- Вращение сохраняет величину, но изменяет направление
- Близкие друг к другу токены имеют схожие вращения
- Далекие друг от друга токены имеют большие разности фаз
- Во время внимания Q·K эти разности фаз естественным образом кодируют относительное расстояние

Почему RoPE лучше абсолютных позиционных эмбеддингов
- Нет фиксированной таблицы поиска позиций
- Кодирует относительные смещения непосредственно внутри внимания
- Лучше экстраполируется на более длинные последовательности
- Добавляет сильный индуктивный сдвиг, соответствующий тому, как работает внимание

**Техники расширения:**

**Интерполяция позиций (PI):**
- Сжимать позиции во время дообучения
- Обучать на 2048, сжимать для использования 4096
- Сохраняет относительные расстояния

**YaRN (Yet another RoPE extensioN method):**
- Частотно-зависимая интерполяция
- Разные частоты расширяются по-разному
- Лучшая экстраполяция, чем у PI

#### ALiBi (Attention with Linear Biases)

**Принцип:** Добавить линейное смещение к оценкам внимания на основе расстояния

$$\text{softmax}(QK^T + m \cdot [-1, -2, -3, ..., -n])$$

**Преимущества:**
- Не требуются позиционные эмбеддинги
- Превосходная экстраполяция
- Можно обучать на 2K, инференс на 10K+

**Ссылки:**
- [RoPE - Paper](https://arxiv.org/abs/2104.09864)

---
## В18 — Токенизация: BPE


### Byte Pair Encoding (BPE)

**Алгоритм:**
1. Начать со словарного запаса символов
2. Подсчитать все смежные пары
3. Объединить самую частую пару
4. Добавить в словарь
5. Повторять до достижения желаемого размера словаря

**Пример:**
```
Начальный: ["l", "o", "w", "e", "r"]
Объединить "e"+"r" → "er"
Объединить "er"+" " → "er "
...
Конечный словарь: ["low", "er", " ", "wide", "st"]
```

**Преимущества:**
- Балансирует размер словаря и длину последовательности
- Обрабатывает редкие слова (разбивает на подслова)
- Нет неизвестных токенов (всегда можно вернуться к символам)

**Используется в:** GPT-2, GPT-3, RoBERTa


### WordPiece

**Отличие:** Объединяет на основе **увеличения правдоподобия**, а не частоты

**Используется в:** BERT, DistilBERT


### SentencePiece

**Ключевая особенность:** не зависит от языка, рассматривает пробел как символ

**Алгоритмы:** BPE или Unigram LM

**Преимущества:**
- Работает для языков без пробелов (китайский, японский)
- Обратимый

**Используется в:** T5, XLNet, многоязычных моделях

**Ссылки:**
- [BPE - Neural Machine Translation](https://arxiv.org/abs/1508.07909)

---
## В19 — GPT vs BERT


### GPT (Generative Pre-trained Transformer)

**Архитектура:** Только декодер с причинным (маскированным) вниманием

**Внимание:** Может обращать внимание только на предыдущие токены

$$\text{Mask}_{ij} = \begin{cases} 0 & \text{если } i \geq j \\ -\infty & \text{если } i < j \end{cases}$$

**Цель обучения:**

$$\mathcal{L} = -\sum_{t=1}^{T} \log P(x_t | x_1, ..., x_{t-1})$$

Предсказание следующего токена (языковое моделирование слева направо)

**Сильные стороны:**
- Генерация текста
- Авторегрессионные задачи
- Обучение на нескольких примерах (in-context)
- Диалоги/чат

**Слабые стороны:**
- Не может заглядывать вперед
- Менее эффективен для задач понимания

**Используется для:** ChatGPT, GPT-4, генерации текста, диалогов


### BERT (Bidirectional Encoder Representations from Transformers)

**Архитектура:** Только энкодер с двунаправленным вниманием

**Внимание:** Может обращать внимание на все токены (прошлые и будущие)

**Цели обучения:**

1. **MLM (Masked Language Modeling):**
   - Случайно маскировать 15% токенов
   - Предсказывать замаскированные токены, используя контекст

$$\mathcal{L}_{MLM} = -\sum_{i \in masked} \log P(x_i | x_{\backslash i})$$

2. **NSP (Next Sentence Prediction):**
   - Дано [CLS] Предложение_A [SEP] Предложение_B [SEP]
   - Предсказать, следует ли Предложение_B за Предложением_A
   - Убрано в RoBERTa (не сильно помогало)

**Сильные стороны:**
- Классификация (настроение, NER, QA)
- Понимание двунаправленного контекста
- Трансферное обучение для задач NLP

**Слабые стороны:**
- Не может генерировать текст естественным образом
- Несоответствие: [MASK] в предобучении, но не в дообучении

**Используется для:**
- Классификация (настроение, NER)
- Ответы на вопросы
- Сходство предложений
- Понимание двунаправленного контекста


### Сравнение архитектур

| Аспект | GPT (Декодер) | BERT (Энкодер) |
|---|---|---|
| **Внимание** | Причинное (однонаправленное) | Двунаправленное |
| **Обучение** | Предсказание следующего токена | Masked LM + NSP |
| **Основное использование** | Генерация | Понимание |
| **Контекст** | Слева направо | Полная последовательность |
| **Задачи** | Генерация текста, чат, завершение | Классификация, NER, QA, эмбеддинги |
| **Архитектура** | Стек декодеров | Стек энкодеров |
| **Вывод** | Один токен за раз | Все токены одновременно |

**Сравнительная таблица**

| Аспект | GPT | BERT |
|---|---|---|
| **Внимание** | Однонаправленное | Двунаправленное |
| **Обучение** | Следующий токен | MLM + NSP |
| **Генерация** | Да ✓ | Нет ✗ |
| **Понимание** | Ограниченное | Отличное |
| **Применение** | Чат, завершение | Классификация, QA |

**Ссылки:**
- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [GPT-2 Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

---
## В20 — SFT, RLHF, DPO (Обучение по инструкциям)


### Конвейер обучения

#### 1. Предобучение

**Цель:** Изучить языковые закономерности на огромных текстовых корпусах

**Данные:**
- Веб-краулинг (Common Crawl)
- Книги, Википедия
- Репозитории кода (GitHub)
- Всего: Триллионы токенов

**Потери:** Предсказание следующего токена

$$\mathcal{L} = -\sum_{t=1}^{T} \log P_\theta(x_t | x_{<t})$$

**Результат:** Базовая модель с сильным пониманием языка, но:
- Не следует инструкциям
- Непредсказуемое поведение
- Может продолжать запрос пользователя, а не отвечать на него

**Пример:**
- Пользователь: "Напиши стих об ИИ"
- Базовая модель: "Напиши стих о робототехнике Напиши стих о..." (завершение, а не следование инструкции)



#### 2. SFT (Supervised Fine-Tuning)

**Цель:** Научить модель следовать инструкциям

**Формат данных:** пары (инструкция, вывод)
```
{
  "instruction": "Переведи на французский: Hello, how are you?",
  "output": "Bonjour, comment allez-vous?"
}
```

**Обучение:** Стандартное обучение с учителем

$$\mathcal{L}_{SFT} = -\sum_i \log P_\theta(y_i | x_i)$$

**Размер набора данных:** 10K - 100K высококачественных примеров


**Пример:**
```json
{
  "instruction": "Переведи на французский: Hello",
  "output": "Bonjour"
}
```

**Ключевая идея:** Качество >> Количество
- 1,000 отличных примеров > 100,000 посредственных
- Важно разнообразие (покрытие многих типов задач)

**Источники:**
- Человеческие демонстрации
- Дистилляция из сильных моделей (GPT-4, Claude)
- Self-instruct (модель генерирует свои собственные обучающие данные)

**Результат:** Модель, которая следует инструкциям, но:
- Может быть многословной, излишне извиняющейся
- Не соответствует человеческим предпочтениям
- Не знает, когда отказывать


#### 3. RLHF (Reinforcement Learning from Human Feedback)

**Двухэтапный процесс:**

**Этап 1: Обучение модели вознаграждения**
- Сбор пар предпочтений (ответ A > ответ B)
- Обучение классификатора для предсказания человеческих предпочтений


**Сбор данных:**
1. Сэмплировать промпты из набора данных
2. Сгенерировать несколько ответов от модели SFT
3. Люди ранжируют ответы (A > B > C)

**Модель:** Классификатор, предсказывающий человеческие предпочтения

$$r_\theta(x, y) \in \mathbb{R}$$

**Потери (Модель Брэдли-Терри):**

$$\mathcal{L}_r = -E \left[\log \sigma(r_\theta(x, y_w) - r_\theta(x, y_l))\right]$$

Где y_w = предпочтительный (победитель), y_l = менее предпочтительный (проигравший)

**Интуиция:** Модель вознаграждения оценивает, насколько "хорош" ответ


**Этап 2: Дообучение с помощью RL (PPO)**

**Цель:**

$$\mathcal{J}(\theta) = E_{x \sim D, y \sim \pi_\theta}[r_\theta(x, y)] - \beta \cdot D_{KL}(\pi_\theta || \pi_{ref})$$

**Компоненты:**
- **Вознаграждение:** r_θ(x, y) от модели вознаграждения
- **Штраф KL:** Предотвращает слишком сильное расхождение модели от референсной (SFT) модели
  - Без KL: Модель может "взломать" модель вознаграждения
  - β контролирует силу регуляризации (типично: 0.01-0.1)

**PPO (Proximal Policy Optimization):**
- Стабильный алгоритм RL
- Ограничивает обновления, чтобы предотвратить большие изменения политики
- Несколько эпох на батч

**Результат:** Модель, согласованная с человеческими предпочтениями

**Проблемы:**
- Вычислительно дорого (4 модели в памяти)
- Нестабильное обучение
- Взлом вознаграждения (модель находит обходные пути)

#### 4. DPO (Direct Preference Optimization)


**Ключевая идея:** Обойти модель вознаграждения, оптимизировать политику непосредственно из предпочтений

**Математическая основа:**
Оптимальная политика для RLHF удовлетворяет:
$$\pi^*(y|x) \propto \pi_{ref}(y|x) \exp\left(\frac{r(x,y)}{\beta}\right)$$

Перегруппировав:
$$r(x,y) = \beta \log \frac{\pi^*(y|x)}{\pi_{ref}(y|x)} + \beta \log Z(x)$$

**Потери DPO:**
$$\mathcal{L}_{DPO} = -E\left[\log \sigma\left(\beta \log \frac{\pi_\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \beta \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)}\right)\right]$$

**Интуиция:**
- Увеличить вероятность предпочтительного ответа y_w
- Уменьшить вероятность непредпочтительного ответа y_l
- Относительно референсной политики

**Преимущества перед RLHF:**
- Не требуется модель вознаграждения
- Более стабильное обучение
- Только 2 модели вместо 4 (политика + референсная)
- Более простая реализация

**Данные:** Те же данные предпочтений, что и для RLHF

**Результат:** Качество, сопоставимое с RLHF, при более простом обучении


### Сравнение

| Аспект | SFT | RLHF | DPO |
|---|---|---|---|
| **Данные** | Демонстрации | Предпочтения | Предпочтения |
| **Обучение** | С учителем | RL | С учителем |
| **Модели** | 1 | 4 | 2 |
| **Стабильность** | Высокая | Низкая | Средняя |
| **Вычисления** | Низкие | Очень высокие | Средние |

**Типичный конвейер:**
1. Предобучение на триллионах токенов
2. SFT на 10K-100K демонстраций
3. RLHF или DPO на 100K-1M пар предпочтений


**Последние тенденции:**
- **RLAIF:** Замена человеческой обратной связи на обратную связь от ИИ
- **Конституционный ИИ:** Модель критикует свои собственные выводы
- **Многоцелевой RLHF:** Оптимизация на полезность, безвредность, честность
- **Итеративный DPO:** Несколько раундов с обновленной референсной моделью


**Ссылки:**
- [InstructGPT Paper](https://arxiv.org/abs/2203.02155)
- [DPO Paper](https://arxiv.org/abs/2305.18290)

---
## В21 — Оптимизация инференса LLM


### Техники оптимизации эмбеддингов

#### 1. Снижение размерности

**PCA (Principal Component Analysis):**
Проецирование на топ-k главных компонент

**UMAP/t-SNE:**
Нелинейное снижение, сохраняет локальную структуру

**Применение:** Снизить 1536d до 384d с потерей качества <5%



#### 2. Квантование

**Скалярное квантование**: INT8/INT4 вместо FP32:
- Уменьшение размера в 2-8 раз
- Более быстрые вычисления (INT операции)
- Минимальная потеря качества (<1% обычно)


**Процесс:**
1. Найти min/max каждого измерения
2. Отобразить диапазон в [0, 255]
3. Сохранить параметры квантования

**Сжатие:** в 4 раза меньше
**Скорость:** Быстрые скалярные произведения (int8 SIMD)
**Качество:** Минимальное ухудшение (<1% падение полноты)

**Методы:**
- Пост-тренировочное квантование (PTQ)
- Квантово-осознанное обучение (QAT)

**Инструменты:** GPTQ, GGML/GGUF, bitsandbytes


**Продуктовое квантование (PQ):**
1. Разделить d-мерный вектор на m подвекторов
2. Квантовать каждый подвектор независимо (k-means с 256 центроидами)
3. Хранить ID центроидов (по 1 байту каждый)

**Сжатие:** d × 4 байта → m байт (часто в 32 или 64 раза)
**Качество:** Умеренное ухудшение (2-5% падение полноты)

**Бинарное квантование:**
Преобразование в бинарный вид: x_i → sign(x_i)

**Сжатие:** в 32 раза меньше
**Скорость:** Расстояние Хэмминга = инструкция POPCNT
**Качество:** Значительное ухудшение (использовать для фильтрации, затем переранжировать)



#### 3. Прунинг (Обрезка)

**Удаление весов с малой величиной:**
- Структурированный прунинг (целые слои/каналы)
- Неструктурированный прунинг (отдельные веса)

**Результат:** Меньшая, более быстрая модель


### Дистилляция знаний


**Обучение меньшей модели имитировать большую:**
$$\mathcal{L} = \alpha \cdot \mathcal{L}_{student} + (1-\alpha) \cdot \text{KL}(T_{teacher}, T_{student})$$


**Процесс:**
1. Обучить студенческую модель имитировать эмбеддинги учителя
2. Потери: MSE(student_embed, teacher_embed) + task_loss

**Результат:** Меньшая модель (например, 7B → 400M параметров) с похожим качеством

**Пример:** distilbert-base → на 40% меньше, 97% качества


#### 4. Пакетная обработка (Batching)

**Обработка нескольких запросов одновременно:**
- Амортизация постоянных затрат
- Лучшее использование GPU

**Динамический батчинг:** Группировка запросов "на лету"


#### 5. KV-кэш

**Кэширование тензоров ключ/значение для авторегрессионных моделей:**
- Избежание пересчета для уже сгенерированных токенов
- Необходимо для эффективной генерации

**Компромисс:** Память против вычислений


#### 6. Flash Attention

**Оптимизированные ядра CUDA:**
- Эффективное по памяти точное внимание
- Ускорение в 2-4 раза
- Без аппроксимации

**Разреженное внимание:** Обращать внимание на подмножество токенов
**Скользящее окно:** Локальное + глобальное внимание
**Токены-ориентиры:** Специальные токены, обобщающие контекст



#### 7. Спекулятивное декодирование

**Использование маленькой модели для предложения, большой для проверки:**
- Генерация нескольких токенов параллельно
- Ускорение в 2-3 раза для авторегрессионной генерации


#### 8. Аппаратная оптимизация

**Специализированные ускорители:**
- TensorRT (NVIDIA)
- ONNX Runtime
- A100, H100 GPU
- Пользовательские ASIC (TPU, Inferentia)


### Оптимизация моделей

Форматы моделей для локального инференса

#### GGUF (GPT-Generated Unified Format)

**Преемник GGML**

**Особенности:**
- Формат одного файла
- Включает тензоры + метаданные + словарь
- Поддерживает квантование (2-8 бит)
- Загрузка с отображением в память

**Уровни квантования:**
- **Q2_K:** 2-битное (экстремальное сжатие, потеря качества)
- **Q4_K_M:** 4-битное среднее (хороший баланс)
- **Q5_K_M:** 5-битное среднее (лучшее качество)
- **Q8_0:** 8-битное (минимальная потеря качества)

**Примеры размеров файлов (модель 7B):**
- FP16: 14 ГБ
- Q8_0: 7.5 ГБ
- Q4_K_M: 4.1 ГБ
- Q2_K: 2.7 ГБ


#### Ollama

**Особенности:**
- Удобный CLI и API
- Управление моделями (скачивание, запуск, удаление)
- Опыт, похожий на Docker
- REST API, совместимый с OpenAI
- Легкое переключение моделей

**Применение:**
- Быстрые эксперименты
- Локальная разработка
- Нетехнические пользователи


#### vLLM

**Особенности:**
- **PagedAttention:** Оптимизация KV-кэша
- Высокая пропускная способность (в 10-100 раз выше наивного)
- Пакетная обработка, стриминг
- Готов к продакшену
- Совместим с HuggingFace

**Применение:**
- Развертывание в продакшене
- Приложения с высоким трафиком
- Обслуживание моделей в масштабе

**Сравнение:**

| Инструмент | Лучше всего для | Скорость | Простота использования |
|---|---|---|---|
| **llama.cpp** | Оптимизация, исследования | Очень быстро | Средняя |
| **Ollama** | Быстрый старт, эксперименты | Быстро | Очень легко |
| **vLLM** | Обслуживание в продакшене | Очень быстро (пропускная способность) | Средняя |



### Стек оптимизации

**Модель → Квантование → Компиляция → Аппаратное обеспечение**

**Пример конвейера:**
1. Квантовать в INT8
2. Скомпилировать с помощью TensorRT
3. Развернуть на A100 GPU
4. Использовать динамический батчинг
5. Включить KV-кэш

**Результат:** Ускорение в 10-100 раз по сравнению с наивной реализацией

**Ссылки:**
- [Flash Attention Paper](https://arxiv.org/abs/2205.14135)
- [GPTQ - Quantization](https://arxiv.org/abs/2210.17323)
- [vLLM - Inference Engine](https://github.com/vllm-project/vllm)

---
## В22 — Этапы ML-проекта


### 1. Определение проблемы
- Понять бизнес-цель
- Определить метрики успеха
- Оценить выполнимость


### 2. Сбор данных
- Определить источники данных
- Собрать и консолидировать
- Документировать происхождение


**Ключевые техники/инструменты:**
- SQL базы данных, NoSQL (MongoDB), озера данных (AWS S3, Azure Data Lake)
- Веб-скрапинг (BeautifulSoup, Scrapy)
- API (REST, GraphQL)
- Инструменты разметки данных (Labelbox, Amazon Mechanical Turk)
- ETL-конвейеры (Apache Airflow, Luigi)

**Распространенные ошибки:**
- **Смещение выборки**: Сбор нерепрезентативных образцов
- **Недостаточный объем данных**: Недостаточное количество образцов для обобщения модели (сколько образцов вам нужно для обучения модели)
- **Низкое качество данных**: Пропущенные значения, дубликаты, несогласованные форматы
- **Юридические/этические вопросы**: Нарушение правил конфиденциальности (GDPR, HIPAA)

**Лучшие практики:**
- Документировать источники данных, методы сбора и временные метки
- Внедрить версионирование данных (DVC, MLflow)
- Обеспечить сбалансированное представительство классов для задач классификации

EDA - это процесс анализа наборов данных для обобщения основных характеристик, обнаружения аномалий, выявления закономерностей и формирования гипотез с использованием статистических и визуальных методов.

**Ключевые техники/инструменты:**
- Статистический анализ: Среднее, медиана, стандартное отклонение, корреляционные матрицы
- Визуализация: Гистограммы, ящики с усами, диаграммы рассеяния, тепловые карты
- Инструменты: Pandas, Matplotlib, Seaborn, Polars


### 3. EDA (Разведочный анализ данных)
- Статистические сводки
- Визуализации
- Выявление закономерностей, аномалий
- Формулирование гипотез


### 4. Предобработка
- **Очистка**: Обработка пропущенных значений (импутация, удаление), обработка выбросов
- **Кодирование**: One-hot кодирование, label кодирование, target кодирование
- **Масштабирование**: StandardScaler, MinMaxScaler, RobustScaler
- **Создание признаков**: Полиномиальные признаки, биннинг, логарифмические преобразования
- **Отбор признаков**: Методы фильтрации, методы-обертки (RFE), встроенные методы (L1 регуляризация)

**Критическая ошибка - Утечка данных:**
Использование информации из тестовых данных во время предобработки делает оценку недействительной.


### 5. Инжиниринг признаков
- Создание новых признаков
- Отбор признаков
- Снижение размерности


### 6. Выбор модели
- Выбрать кандидатов в алгоритмы
- Обучить базовые модели
- Сравнить производительность


### 7. Обучение и настройка гиперпараметров

**Методы кросс-валидации:**
- K-Fold, Stratified K-Fold (для классификации)
- Time Series Split (для временных данных)
- Leave-One-Out (маленькие наборы данных)

**Настройка гиперпараметров:**
- Grid Search: Исчерпывающий, но вычислительно дорогой
- Random Search: Часто более эффективен
- Bayesian Optimization (Optuna): Наиболее эффективен для дорогих вычислений


### 8. Оценка
- Тестирование на отложенном наборе
- Анализ ошибок
- Сравнение с бизнес-метриками

Углубленный анализ
- Анализ неправильных классификаций по категориям
- Отчет о доверительных интервалах
- Оценка справедливости по демографическим группам


### 9. Развертывание
- Контейнеризация (Docker)
- Разработка API (FastAPI, Flask)
- CI/CD конвейер
- A/B-тестирование


### 10. Мониторинг
- Отслеживание метрик производительности
- Обнаружение дрейфа данных/концепции
- Настройка оповещений
- Планирование переобучения

**Лучшие практики:**
- Определить SLA для производительности модели
- Внедрить автоматическое обнаружение дрейфа
- Установить триггеры и графики переобучения


### Структура репозитория

```
project/
├── data/
│   ├── raw/           # Исходные данные (неизменяемые)
│   ├── processed/     # Очищенные данные
├── notebooks/         # EDA, эксперименты
├── src/
│   ├── data/          # Обработка данных
│   ├── features/      # Инжиниринг признаков
│   ├── models/        # Определения моделей
│   ├── evaluation/    # Метрики, валидация
├── models/            # Сохраненные модели
├── configs/           # Конфигурационные файлы (YAML, JSON)
├── tests/             # Юнит-тесты
├── requirements.txt
├── Dockerfile
└── README.md
```

**Ссылки:**
- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

---
## В23 — RAG (Retrieval-Augmented Generation)


**Проблемы с обычными LLM:**
- **Ограничение знаний:** Не могут получить доступ к свежей информации
- **Галлюцинации:** Генерируют правдоподобную, но неверную информацию
- **Специфичность домена:** Отсутствие специализированных знаний
- **Атрибуция источников:** Не могут цитировать источники

**Преимущества RAG:**
- Актуальная информация (извлечение из текущих документов)
- Уменьшение галлюцинаций (основано на извлеченных доказательствах)
- Адаптация к домену без дообучения
- Экономичность: Дешевле, чем переобучение


### Архитектура

**Конвейер:** Извлечение → Ранжирование → Генерация

```
Запрос пользователя → Эмбеддинг → Векторный поиск → Извлечение топ-K 
           ↓
    Переранжирование → Контекст + Запрос → LLM → Ответ
```


### Компоненты

#### 1. Индексация

**Чанкинг:** Документы слишком длинные для контекстного окна, Разделение документов на чанки (512-1024 токенов)


### Стратегии чанкинга

**Проблема:**

#### Чанкинг фиксированного размера
- Разделение каждые N символов/токенов
- Просто, но может разорвать середину предложения/абзаца
- Типично: 512-1024 токенов с перекрытием в 50-100 токенов

#### Семантический чанкинг
- Разделение по границам тем
- Использование эмбеддингов предложений для обнаружения смены тем
- Лучшая связность, но сложнее

#### Рекурсивный чанкинг
- Иерархическое разделение: главы → разделы → абзацы
- Сохраняет структуру документа
- Хорошо для структурированных документов

#### Окно предложений
- **Индекс:** Отдельные предложения
- **Извлечение:** Окружающие предложения (окно)
- Лучший баланс точности/контекста


**Эмбеддинг:** sentence-transformers, эмбеддинги OpenAI, BGE

**Хранение:** Векторная БД (Pinecone, Weaviate, FAISS, Milvus, Qdrant)

#### 2. Извлечение

**Методы:**
- **Плотный (Семантический):** Косинусное сходство на эмбеддингах
- **Разреженный (Ключевые слова):** BM25 для точного совпадения ключевых слов
- **Гибридный:** α·плотный + (1-α)·разреженный. Комбинирование обоих с взвешенной суммой

$$\text{score}_{hybrid} = \alpha \cdot \text{score}_{dense} + (1-\alpha) \cdot \text{score}_{sparse}$$

**Типично:** Извлечение топ-20 до топ-100

**Фильтрация перед генерацией:**
- Удаление документов с низкой релевантностью (порог оценки)
- Проверка на противоречия между источниками
- Приоритет свежим/авторитетным источникам


#### 3. Переранжирование

**Цель:** Улучшить точность лучших результатов

**Кросс-энкодер:** Совместное кодирование [запрос; документ]
- Более точный, чем би-энкодер
- Медленнее - Необходимо кодировать каждую пару (только для топ-K)

**Метод:**
- **Кросс-энкодер:** Совместное кодирование [запрос; документ]
- Более точный, чем би-энкодер (раздельное кодирование)

**Уменьшение топ-100 → топ-10**


**Популярные переранжировщики:**
- Cohere rerank
- bge-reranker
- Модели кросс-энкодеров (SBERT)


#### 4. Генерация

**Промпт:**
```
Контекст:
{retrieved_doc_1}
{retrieved_doc_2}
...

Вопрос: {user_query}

Ответь на основе контекста. Если информации нет в контексте, скажи "Я не знаю".
```

**Ключевые элементы:**
- Явная инструкция использовать контекст
- Инструкция признавать неопределенность
- (Опционально) Запрос на цитирование


### Уменьшение галлюцинаций

**1. Требования к цитированию:**
- Требовать от модели цитирования источников
- Проверять, подтверждают ли цитаты утверждения

**2. Оценки уверенности:**
- Просить об уверенности (0-10)
- Если низкая, воздержаться или пометить для проверки человеком

**3. Самосогласованность:**
- Сгенерировать несколько ответов (разная температура/сэмплирование)
- Проверить согласие. Если ответы значительно отличаются, пометить неопределенность

**4. Проверка логического следования:**
- Использовать модель NLI для проверки утверждений

**Пример:**
- Утверждение: "Компания была основана в 2015 году"
- Контекст: "С момента своего основания в 2015 году..."
- Логическое следование: ИСТИНА ✓


### Продвинутые техники: 


#### HyDE (Hypothetical Document Embeddings)

**Процесс:**
1. Сгенерировать гипотетический ответ на запрос (без извлечения)
2. Использовать гипотетический ответ как поисковый запрос
3. Извлечь документы, похожие на гипотетический ответ
4. Сгенерировать окончательный ответ из извлеченных документов

**Преимущество:** Преодолевает разрыв в словарном запасе (язык запроса vs язык документа)

#### Декомпозиция запроса

**Процесс:**
1. Разбить сложный запрос на более простые подзапросы
2. Извлечь для каждого подзапроса
3. Синтезировать окончательный ответ

**Пример:**
- Запрос: "Сравни рост выручки Apple и Microsoft в 2020-2023 годах"
- Подзапросы:
  - "Выручка Apple 2020-2023"
  - "Выручка Microsoft 2020-2023"

#### Self-RAG

**Добавляет токены рефлексии:**
- **Извлечь:** Да/Нет (должен ли я извлекать?)
- **ISREL:** Релевантно/Нерелевантно (релевантен ли извлеченный документ?)
- **ISSUP:** Полностью/Частично/Не поддерживается (поддерживает ли контекст вывод?)
- **ISUSE:** 5/4/3/2/1 (оценка полезности)

**Модель учится, когда извлекать и когда доверять сгенерированному контенту**


#### Актер-Критик для RAG

**Актер:** Генерирует запросы на извлечение
**Критик:** Оценивает качество извлеченного документа

**Итеративное уточнение:**
1. Актер извлекает документы
2. Критик оценивает релевантность
3. Если оценка низкая: Актер уточняет запрос, извлекает снова
4. Повторять до удовлетворительного результата


### Агентный RAG


### Что такое агенты?

[введение в сложных агентов](https://cold-scallion-5b8.notion.site/AI-agents-1979c76f79e8808291a4e463e8224bfc?pvs=74)

**Определение:** Автономные системы, которые могут:
1. **Воспринимать:** Понимать окружение/задачу
2. **Рассуждать:** Планировать и принимать решения о действиях
3. **Действовать:** Выполнять с помощью инструментов/API
4. **Учиться:** Адаптироваться на основе обратной связи

**В отличие от стандартных LLM:**
- **LLM:** Без состояния, однопроходный, пассивный
- **Агент:** С состоянием, многопроходный, проактивный


### Агенты vs Обычный RAG


**Динамический процесс с рассуждением:**
```
Запрос → Агент решает:
        ├─ Нужно извлечение? → Векторный поиск
        ├─ Можно ответить напрямую? → Ответ
        ├─ Нужен веб-поиск? → Web API
        └─ Нужны вычисления? → Калькулятор

Извлеченный контекст → Оценить качество
                  → Переформулировать при необходимости
                  → Сгенерировать и проверить → Вернуть
```

**Ключевое отличие от базового RAG:**
- Решает, КОГДА извлекать
- Использует НЕСКОЛЬКО инструментов
- ИТЕРАТИВНОЕ уточнение
- ЯВНЫЕ следы рассуждений

```
| Аспект | Обычный RAG | Агентный RAG |
|---|---|---|
| **Конвейер** | Фиксированный (извлечь → сгенерировать) | Динамический (решает, когда извлекать) |
| **Извлечение** | Однократное | Многошаговое, итеративное |
| **Инструменты** | Нет | Множество инструментов (поиск, вычисления, вызовы API) |
| **Рассуждение** | Неявное | Явное (цепь мыслей) |
| **Адаптация** | Нет | Самокоррекция на основе результатов |
```

**Пример:**
- **Обычный RAG:** "Какая погода?" → Извлечь → Ответ
- **Агентный RAG:** "Какая погода?" → Использовать API погоды → Распарсить результат → Ответ в предпочитаемых пользователем единицах


### Вызов инструментов

**Определение:** LLM вызывает внешние функции/API

#### Процесс

**1. Определить инструменты (JSON Schema)**
```json
{
  "name": "get_weather",
  "description": "Получить текущую погоду для местоположения",
  "parameters": {
    "type": "object",
    "properties": {
      "location": {"type": "string"},
      "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
    },
    "required": ["location"]
  }
}
```

**2. LLM генерирует вызов функции**
```json
{
  "tool": "get_weather",
  "arguments": {
    "location": "Paris",
    "unit": "celsius"
  }
}
```

**3. Приложение выполняет функцию**
```python
result = get_weather(location="Paris", unit="celsius")
# Возвращает: {"temperature": 15, "condition": "cloudy"}
```

**4. Результат добавляется в контекст**
LLM продолжает с результатом функции

**5. LLM генерирует окончательный ответ**
"Текущая погода в Париже 15°C, облачно."

#### Категории инструментов

**Извлечение информации:**
- Веб-поиск
- Запросы к базам данных
- Извлечение документов

**Обработка данных:**
- Калькулятор
- Выполнение кода
- Преобразование данных

**Внешние действия:**
- Отправить email
- Создать событие в календаре
- Вызовы API (Slack, GitHub и т.д.)

**Множественные вызовы инструментов:**
Агент может вызывать несколько инструментов последовательно или параллельно


### Паттерн ReAct (Рассуждение + Действие)

**Структура:** Чередование следов рассуждений с действиями

**Формат:**
```
Мысль: [Рассуждение о том, что делать дальше]
Действие: [Инструмент для использования + аргументы]
Наблюдение: [Результат от инструмента]
Мысль: [Рассуждение о наблюдении]
Действие: [Следующий вызов инструмента]
Наблюдение: [Результат]
...
Мысль: [Окончательное рассуждение]
Ответ: [Окончательный ответ]
```

**Пример:**
```
Пользователь: "Какая столица страны, где проходили Олимпийские игры 2024 года?"

Мысль: Мне нужно найти, где проходили Олимпийские игры 2024 года
Действие: Поиск["место проведения Олимпийских игр 2024"]
Наблюдение: Париж, Франция

Мысль: Теперь я знаю, что это была Франция, мне нужно подтвердить столицу
Действие: Поиск["столица Франции"]
Наблюдение: Париж

Мысль: У меня есть ответ
Ответ: Столица - Париж, где также проходили Олимпийские игры 2024 года.
```

**Преимущества:**
- **Прозрачность:** Можно проследить рассуждения
- **Отлаживаемость:** Видно, где агент ошибается
- **Самокоррекция:** Может пересмотреть план на основе наблюдений
- **Работает "из коробки":** Не требует дообучения для сильных моделей

**Реализация:** Инжиниринг промптов — предоставление примеров в формате few-shot


### Подходы к планированию

#### План-и-выполнение

**Процесс:**
1. Создать полный план заранее
2. Выполнить шаги последовательно
3. Обработать ошибки, если какой-либо шаг не удался

**Пример:**
```
План:
1. Поиск "Нобелевская премия по физике 2023"
2. Извлечь имена победителей
3. Поиск "текущая должность {победителя}"
4. Обобщить выводы
```

**Плюсы:** Четкая структура
**Минусы:** Жесткий, не может адаптироваться, если промежуточные результаты неожиданные

#### Дерево мыслей (ToT)

**Процесс:**
1. Сгенерировать несколько путей рассуждений
2. Оценить каждый путь
3. Отсечь низкокачественные пути
4. Исследовать наиболее перспективные
5. Вернуться назад при необходимости

**Пример:**
```
        [Начальный запрос]
       /      |      \
   Путь A   Путь B  Путь C
    /|\       |      /|\
   ...       ...    ...
```

**Оценка:** LLM оценивает каждую мысль (1-10) или внешний оценщик

**Применение:** Сложные рассуждения, математические задачи, головоломки


#### Рефлексия

**Процесс:**
1. Сгенерировать начальное решение
2. Критиковать решение
3. Уточнить на основе критики
4. Итерировать до удовлетворительного результата

**Промпт:**
```
Задача: {задача}
Решение: {текущее_решение}

Критикуйте это решение. Что не так? Чего не хватает?
```

**Применение:** Написание текстов, генерация кода, сложный анализ


### Типы памяти

#### Краткосрочная (Рабочая память)
- Текущий контекст разговора
- Последние выводы инструментов
- Промежуточные результаты

**Реализация:** В контексте (часть промпта)


#### Долгосрочная память

**Эпизодическая (Память событий):**
- Прошлые взаимодействия
- Историческое использование инструментов
- Обратная связь от пользователя

**Семантическая (Память знаний):**
- Факты, изученные о пользователе
- Предпочтения
- Знания в домене

**Процедурная (Память навыков):**
- Изученные рабочие процессы
- Успешные стратегии
- Инструкции

**Реализация:**
- Векторная база данных (семантический поиск по прошлым взаимодействиям)
- Структурированное хранилище (SQLite, Redis)
- Извлечение по релевантности


### Дизайн агентного RAG

**Архитектура:** LLM как оркестратор с доступом к нескольким инструментам

**Инструменты:**
- **Векторный поиск:** Семантическое извлечение документов
- **Поиск по ключевым словам:** BM25 для точных совпадений
- **Веб-поиск:** Внешние знания
- **SQL база данных:** Структурированные данные
- **Калькулятор:** Числовые вычисления
- **Выполнение кода:** Сложные преобразования

#### Пример потока

**Запрос:** "Сравни наши продажи за 3 квартал со средними по отрасли и объясни отклонение"

**Выполнение агентом:**
```
Мысль: Нужны наши данные о продажах за 3 квартал
Действие: sql_query("SELECT sales FROM company_data WHERE quarter='Q3'")
Наблюдение: $5.2M

Мысль: Нужны средние по отрасли
Действие: web_search("средние продажи по отрасли за 3 квартал 2024")
Наблюдение: Среднее по отрасли - $6.1M

Мысль: Рассчитать отклонение
Действие: calculate("(5.2 - 6.1) / 6.1 * 100")
Наблюдение: -14.75%

Мысль: Поискать возможные причины
Действие: vector_search("факторы, влияющие на продажи в 3 квартале")
Наблюдение: [Замедление рынка в регионе X, отложенный запуск продукта]

Мысль: У меня достаточно информации
Ответ: Наши продажи за 3 квартал в размере $5.2M на 14.75% ниже среднего по отрасли 
в $6.1M. Ключевые факторы: [синтезированное объяснение]
```


#### Проблемы

**Надежность:**
- Ошибки вызова инструментов
- Галлюцинированные аргументы инструментов
- Бесконечные циклы

**Решения:**
- Логика повторных попыток с экспоненциальной задержкой
- Валидация аргументов
- Максимальные лимиты итераций

**Стоимость:**
Множественные вызовы LLM → выше стоимость

**Задержка:**
Последовательные вызовы инструментов → медленнее ответ


### Фреймворки для агентов

#### LangChain

**Особенности:**
- Модульные компоненты (агенты, инструменты, память, цепочки)
- 100+ интеграций
- Язык выражений для сложных рабочих процессов

**Сильные стороны:** Всеобъемлющий, зрелая экосистема
**Слабые стороны:** Может быть сложным, многословным


#### LlamaIndex

**Особенности:**
- Ориентирован на данные (коннекторы к 160+ источникам данных)
- Сильные примитивы RAG
- Движки запросов, агенты

**Сильные стороны:** Лучший в своем классе RAG, интеграция данных
**Слабые стороны:** Менее общий, чем LangChain


#### CrewAI

**Особенности:**
- Оркестрация нескольких агентов
- Ролевые агенты с определенной экспертизой
- Совместные рабочие процессы

**Пример:**
```python
researcher = Agent(role="Исследователь", goal="Найти информацию")
writer = Agent(role="Писатель", goal="Написать статью")
crew = Crew(agents=[researcher, writer], process="sequential")
```

**Сильные стороны:** Координация нескольких агентов
**Применение:** Сложные задачи, требующие нескольких специализированных агентов


#### Сравнение

| Фреймворк | Лучше всего для | Сложность | Фокус |
|---|---|---|---|
| **LangChain** | Агенты общего назначения | Высокая | Оркестрация, инструменты |
| **LlamaIndex** | Системы RAG | Средняя | Данные, извлечение |
| **CrewAI** | Рабочие процессы с несколькими агентами | Средняя | Сотрудничество агентов |


**Ссылки:**
- [ReAct Paper](https://arxiv.org/abs/2210.03629)
- [LangChain Documentation](https://python.langchain.com/)

---
## В24 — Агенты, вызов инструментов, ReAct


### Что такое агенты?

**Автономные системы, которые:**
1. Воспринимают окружение
2. Рассуждают о целях
3. Планируют действия
4. Выполняют через инструменты
5. Адаптируются на основе обратной связи


### Вызов инструментов

**Процесс:**

**1. Определить инструменты (JSON):**
```json
{
  "name": "get_weather",
  "description": "Получить текущую погоду",
  "parameters": {
    "location": {"type": "string"},
    "unit": {"type": "string", "enum": ["C", "F"]}
  }
}
```

**2. LLM генерирует вызов:**
```json
{
  "tool": "get_weather",
  "arguments": {"location": "Paris", "unit": "C"}
}
```

**3. Выполнить функцию, вернуть результат**

**4. LLM продолжает с результатом**


### Паттерн ReAct (Рассуждение + Действие)

**Структура:**
```
Мысль: [Рассуждение о том, что делать]
Действие: [Инструмент + аргументы]
Наблюдение: [Результат]
Мысль: [Рассуждение о наблюдении]
Действие: [Следующий инструмент]
Наблюдение: [Результат]
...
Ответ: [Окончательный ответ]
```

**Пример:**
```
Пользователь: "Какая столица страны-хозяйки Олимпийских игр 2024 года?"

Мысль: Мне нужно найти, где проходили Олимпийские игры 2024 года
Действие: Поиск["место проведения Олимпийских игр 2024"]
Наблюдение: Париж, Франция

Мысль: Теперь я знаю, что это была Франция
Действие: Поиск["столица Франции"]
Наблюдение: Париж

Мысль: У меня есть ответ
Ответ: Париж (который также принимал Олимпийские игры)
```

**Преимущества:**
- Прозрачные рассуждения
- Самокоррекция
- Работает без дообучения


### Фреймворки для агентов

#### LangChain
- Модульные компоненты
- 100+ интеграций
- Богатая экосистема


#### LlamaIndex
- Ориентирован на данные
- 160+ коннекторов
- Сильная поддержка RAG


#### CrewAI
- Оркестрация нескольких агентов
- Ролевые агенты
- Совместные рабочие процессы


### Дизайн агентного RAG

**Оркестрация нескольких инструментов:**
```python
tools = [
    VectorSearch(),      # Семантическое извлечение
    BM25Search(),        # Поиск по ключевым словам
    WebSearch(),         # Внешние знания
    SQLQuery(),          # Структурированные данные
    Calculator()         # Числовые вычисления
]

agent = Agent(llm=llm, tools=tools)
```

**Пример потока:**
```
Запрос: "Сравни наши продажи за 3 квартал со средними по отрасли"

Агент:
  Мысль: Нужны наши данные за 3 квартал
  Действие: SQL["SELECT sales FROM company WHERE quarter='Q3'"]
  Наблюдение: $5.2M
  
  Мысль: Нужны средние по отрасли
  Действие: WebSearch["средние продажи по отрасли за 3 квартал 2024"]
  Наблюдение: $6.1M
  
  Мысль: Рассчитать разницу
  Действие: Calculator["(5.2 - 6.1) / 6.1 * 100"]
  Наблюдение: -14.75%
  
  Мысль: Нужен контекст
  Действие: VectorSearch["факторы, влияющие на продажи в 3 квартале"]
  Наблюдение: [Замедление рынка, отложенный запуск продукта]
  
  Ответ: [Синтезированное объяснение]
```

**Ссылки:**
- [ReAct Paper](https://arxiv.org/abs/2210.03629)
- [LangChain Documentation](https://python.langchain.com/)

---
## Бонусные задачи


### Задача 1: Предсказания честной монетой

**Набор данных:**
- 1000 образцов
- 90 положительных (9%)
- 910 отрицательных (91%)

**Предсказание: Подбрасывание честной монеты (50/50)**

**Ожидаемые результаты:**
- E[TP] = 90 × 0.5 = 45
- E[FN] = 90 × 0.5 = 45
- E[TN] = 910 × 0.5 = 455
- E[FP] = 910 × 0.5 = 455

**Точность (Precision):**

$$\text{Precision} = \frac{TP}{TP + FP} = \frac{45}{45 + 455} = \frac{45}{500} = 0.09 = 9\%$$

**Полнота (Recall):**

$$\text{Recall} = \frac{TP}{TP + FN} = \frac{45}{45 + 45} = \frac{45}{90} = 0.5 = 50\%$$

**Ответ:**
- **Точность = 9%** (то же, что и базовый уровень!)
- **Полнота = 50%** (случайное угадывание ловит половину)


---


### Задача 2: Вероятность принятия заказа

**Условие:**
- 10 водителей
- Каждый водитель: 50% конверсия (принимает заказ)
- Заказ "сгорает", если НИКТО не принимает

**Вопрос: P(заказ сгорит)?**

**Решение:**

P(водитель откажется) = 0.5

P(все 10 откажутся) = (0.5)^10

$$P(\text{сгорит}) = 0.5^{10} = \frac{1}{1024} \approx 0.000977 = 0.0977\%$$

**Ответ: ~0.1%** (очень низкая вероятность)

**Альтернативно:**

$$P(\text{хотя бы один примет}) = 1 - 0.5^{10} = 1 - \frac{1}{1024} = \frac{1023}{1024} \approx 99.9\%$$

---