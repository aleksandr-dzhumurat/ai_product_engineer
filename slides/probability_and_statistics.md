# Практические задачи с теорией вероятностей


Будемм применять теорию к задачам по system design. Во всех этих задачах теория вероятностей помогает:

1. **Оценить риски** (SLA, fraud, data loss)
2. **Подобрать пороги** (rate limiting, connection pools)
3. **Спроектировать retry/fallback** (exponential backoff)
4. **Понять trade-offs** (false positives vs false negatives)
5. **Capacity planning** (M/M/c, Little's Law)

Без этого ты либо over-provision (тратишь деньги), либо under-provision (теряешь availability).

## 1. SLA и availability в distributed systems

**Задача:** У вас микросервисная архитектура с 5 сервисами в цепочке. Каждый сервис имеет uptime 99.9%. Какой будет итоговый SLA?

**Теория:** Независимые вероятности, умножение вероятностей.

$$P(\text{система работает}) = (0.999)^5 = 0.995 \approx 99.5\%$$

**Практический вывод:** 
- Цепочка из N сервисов → SLA деградирует
- Для 99.99% итогового SLA каждый сервис должен иметь 99.998%
- Нужны retries, circuit breakers, fallbacks

---

## 2. Cache hit rate и память

**Задача:** У вас есть 10GB RAM под cache, запросы идут по Zipf distribution (80% запросов к 20% ключей). Сколько данных кешировать?

**Теория:** 
- Распределение частот запросов
- Оптимизация hit rate vs память

**Практический подход:**
```
Если кешируем топ-20% ключей → hit rate ≈ 80%
Если кешируем топ-50% ключей → hit rate ≈ 95%
```

Дальше закон убывающей отдачи: 80% памяти даст только +5% hit rate.

---

## 3. Database connection pool sizing

**Задача:** Backend делает в среднем 5 DB запросов на request. Request rate = 200 rps. Средняя latency DB query = 10ms. Сколько нужно connections в pool?

**Теория:** Little's Law + вероятностные пики.

$$L = λ \cdot W$$

- λ = 200 × 5 = 1000 queries/sec
- W = 0.01 sec
- L (среднее) = 10 connections

**Но:** нужен буфер под p95/p99 пики → реально 20-30 connections.

**Если pool = 10:** при малейшем всплеске будет connection exhaustion.

---

## 4. Fraud detection: сколько ложных срабатываний?

**Задача:** Система детектит мошенничество с точностью 99% (1% false positive). В день 1 миллион транзакций, из них 0.1% реально фродовые.

**Теория:** Bayes' theorem, precision/recall.

```
Истинно фродовых: 1,000,000 × 0.001 = 1,000
Ложных срабатываний: 999,000 × 0.01 = 9,990
```

**Вывод:** На каждую реальную атаку — 10 ложных алертов! Нужно улучшать precision.

---

## 5. Retry policy и exponential backoff

**Задача:** API падает с вероятностью 5% на каждый request. Если делать retry, какова вероятность успеха?

**Теория:** Геометрическое распределение.

```
P(успех с 1 попытки) = 0.95
P(успех с 2 попыток) = 1 - (0.05)² = 0.9975
P(успех с 3 попыток) = 1 - (0.05)³ = 0.999875
```

**Практический вывод:**
- 1 retry → с 95% до 99.75%
- 2 retries → 99.9875%
- Но нужен exponential backoff, иначе thunder herd

---

## 6. Load balancer: probability of hot shard

**Задача:** У вас 10 backend instance, приходит burst из 100 requests за 1ms (быстрее, чем они успевают разобраться). При random routing какова вероятность, что какой-то instance получит ≥15 requests?

**Теория:** Binomial distribution → Poisson approximation.

$$λ = \frac{100}{10} = 10, \quad P(X ≥ 15) \approx e^{-10} \sum_{k=15}^{100} \frac{10^k}{k!}$$

Или через нормальную аппроксимацию: μ = 10, σ = √10 ≈ 3.16.

$$P(X ≥ 15) = P(Z ≥ \frac{15-10}{3.16}) ≈ P(Z ≥ 1.58) ≈ 0.057$$

**Вывод:** ≈5-6% вероятность, что instance получит перегрузку → нужен consistent hashing или least-connections routing.

---

## 7. Distributed consensus: вероятность split brain

**Задача:** Raft кластер из 5 нод. Вероятность network partition между любыми двумя нодами = 1%. Какова вероятность split brain (кластер разбился на 2 группы по 2 и 3 ноды)?

**Теория:** Комбинаторика + теория графов.

Упрощённая оценка: если 2 ноды изолированы от 3 остальных, нужно ≥2 рёбер оборваться.

**Практический вывод:** При low partition rate (1%) split brain очень редок, но при network flapping (10-20%) становится реальной проблемой → нужен quorum monitoring.

---

## 8. Rate limiting: сколько legitimate users заблокируем?

**Задача:** Rate limit = 100 rps на IP. Нормальный пользователь делает в среднем 2 rps с дисперсией (bursts). 1% пользователей — боты (200+ rps). Сколько false positives?

**Теория:** Распределение burst'ов + threshold analysis.

Если трафик пользователя ~ Poisson(2), вероятность burst ≥100 за секунду ничтожна.

Но если есть legitimate use case (например, batch upload), нужен token bucket вместо fixed window.

**Практический вывод:** Fixed rate limit блокирует легитимных пользователей → нужен leaky bucket / sliding window.

---

## 9. Backup retention: вероятность потери данных

**Задача:** Daily backup с вероятностью сбоя 0.1%. Храним 30 последних бэкапов. Какова вероятность, что ВСЕ 30 бэкапов битые?

**Теория:** Независимые события.

$$P(\text{все битые}) = (0.001)^{30} = 10^{-90}$$

Практически невозможно. Но если сбои коррелированы (например, bug в backup script), вероятность резко растёт.

**Практический вывод:** 
- Независимые сбои → можно хранить меньше копий
- Коррелированные сбои (software bug) → нужна диверсификация (разные tools, offsite)

---

## 10. Password brute force: когда блокировать?

**Задача:** Пароль из 6 цифр (10⁶ вариантов). Атакующий пробует 1000 паролей/сек. После скольких попыток блокировать аккаунт?

**Теория:** 
- Вероятность угадать за N попыток: $P = \frac{N}{10^6}$
- После 100 попыток: $P = 0.01\%$
- После 10,000 попыток: $P = 1\%$

**Практический вывод:**
```
Block after 3-5 attempts   → false positives (пользователь забыл пароль)
Block after 100 attempts   → reasonable (0.01% шанс угадать)
Block after 10,000 attempts → слишком поздно
```

Нужен CAPTCHA после 3-5 попыток, hard block после 10-20.

---


## 11 Расчёт количества instance

Это классический вопрос из теории массового обслуживания (ТМО), и важно показать, что ты понимаешь разницу между "в лоб" расчётом и корректной моделью.

Расчёт lower bound

**Дано:**
* входной поток: λ = 1000 rps
* производительность одного instance: μ = 100 rps

**Минимально необходимое число instance:**

$$c_{min} = \frac{λ}{μ} = \frac{1000}{100} = 10$$

⚠️ **Это абсолютный минимум, при котором:**
* система работает на 100% загрузке
* любая флуктуация ⇒ бесконечные очереди
* latency → ∞

Как расчитать "c запасом"
**Модель:**
* вход: пуассоновский поток → **M**
* время обслуживания: экспоненциальное → **M**
* `c` параллельных серверов → **M/M/c**

**Параметры:**
* λ = 1000 rps
* μ = 100 rps
* c = ?
* коэффициент загрузки:

$$ρ = \frac{λ}{c μ}$$

**Условие устойчивости:**

$$ρ < 1$$

В реальных системах обычно целятся в:
* **ρ ≈ 0.6–0.7** — низкие latency
* **ρ ≈ 0.7–0.8** — компромисс
* **ρ > 0.8** — очереди растут очень быстро

Возьмём ρ = 0.7:

$$c = \frac{λ}{ρ μ} = \frac{1000}{0.7 \cdot 100} \approx 14.3$$

Итог - *"Минимально нужно **10 instance**, но это система с загрузкой 100%, очередь будет расти бесконечно. Корректно моделировать это как **M/M/c**. Обычно целимся в загрузку **60–70%**, тогда потребуется около **15 instance**. Более точно число выбирается через **Erlang C** под SLA по latency."*
