
# Ğ’Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ² MLOps

![ivi_main](img/ml_dev_design.png)

References
* [genai-platform](https://huyenchip.com/2024/07/25/genai-platform.html)
* [ml system design](https://www.linkedin.com/feed/update/activity:7274347641138728961)
* [MLOps maturity model](https://www.linkedin.com/feed/update/activity:7229381328490622976)

## Ğ¨Ğ°Ğ³ 1: ÑÑ€ĞµĞ´Ğ° Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸

Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ¼Ğ¿ [messages.db](https://drive.google.com/file/d/1Ej6pV_GAXFDGxMk45Dntn2pnSlnn6IRs/view?usp=sharing) Ğ¸ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ² Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ [data](./data)

Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ ÑĞ±Ğ¾Ñ€ĞºÑƒ Ğ´Ğ¾ĞºĞµÑ€-ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ° Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸

```shell
make build
```

## Ğ¨Ğ°Ğ³ 2

Ğ­Ñ‚Ğ°Ğ¿ EDA (Exploratory Data Analysis) - Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Jupyter Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ "Ğ¿Ğ¾ĞºĞ¾Ğ¿Ğ°Ñ‚ÑŒÑÑ" Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

```shell
make notebook
```

ĞÑ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€ Ğ¿Ğ¾ ÑÑÑ‹Ğ»ĞºĞµ [localhost:8888](http://localhost:8888/)

ĞŸĞ¾ÑĞ»Ğµ EDA ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» [scored_corpus.csv](https://drive.google.com/file/d/1lRpQOCwxwt0JAU9wDUOvhJ3CaYZMYFO_/view?usp=share_link) Ğ² Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ `data` (Ğ»Ğ¸Ğ±Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¸Ğ· google drive Ğ¿Ğ¾ ÑÑÑ‹Ğ»ĞºĞµ)

## Ğ¨Ğ°Ğ³ 3: Ğ Ğ°Ğ·Ğ²Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ LabelStudio

ĞĞ° ÑÑ‚Ğ¾Ğ¼ ÑˆĞ°Ğ³Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ Ğ² LabelStudio. Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ¾Ğ¹

```shell
make labelstudio
```

Ğ”Ğ°Ğ»ĞµĞµ

* Ğ½Ğ° Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ `Sign up` Ğ²Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ»ÑĞ±Ğ¾Ğ¹ Ğ»Ğ¾Ğ³Ğ¸Ğ½ Ğ¸ Ğ¿Ğ°Ñ€Ğ¾Ğ»ÑŒ
* ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ½Ğ° Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ **Data import**
* 
* Ğ½Ğ° Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ `Labeling`  `Ordered By Time`
* Label all tasks
* Ñ€Ğ°Ğ·Ğ¼ĞµÑ‡Ğ°ĞµĞ¼ Ğ½Ğ° positive/negative
* ĞºĞ¾Ğ³Ğ´Ğ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‡ĞµĞ½ - Ğ½Ğ°Ğ¶Ğ¸Ğ¼Ğ°ĞµĞ¼ "export"

Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ² Ñ„Ğ°Ğ¹Ğ» `labeled_messages.csv`

# Ğ¨Ğ°Ğ³ 5: Ğ­ĞºÑĞ¿Ğ»ÑƒĞ°Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ [Ğ¿Ğ¾ ÑÑÑ‹Ğ»ĞºĞµ](https://drive.google.com/file/d/1MrxsEbeeJnIMdjL_GjsYysdKADyF5EQo/view?usp=sharing)

Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸Ñ

* [__main__](../src/train.py) - Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ f1 Ğ±Ğ¾Ğ»ÑŒÑˆĞµ 0.86106
    *  Bert Ğ´Ğ»Ñ Ñ„Ğ¸Ñ‡ĞµĞ¹
    * Ğ±Ğ¾Ğ»ĞµĞµ ÑĞ»Ğ¾Ğ¶Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (Ğ±ÑƒÑÑ‚Ğ¸Ğ½Ğ³?)
* [pridict_labell](../src/service.py) - Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² ÑĞµÑ€Ğ²Ğ¸Ñ Ğ¸ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ API
    * `feed`
    * `/messages/<string:identifier>'`
* Ğ¿Ñ€Ğ¸ÑĞ»Ğ°Ñ‚ÑŒ PR Ğ² Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹

# Experimentation environment

What does an ğ—˜ğ—³ğ—³ğ—²ğ—°ğ˜ğ—¶ğ˜ƒğ—² ğ— ğ—®ğ—°ğ—µğ—¶ğ—»ğ—² ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—˜ğ˜…ğ—½ğ—²ğ—¿ğ—¶ğ—ºğ—²ğ—»ğ˜ğ—®ğ˜ğ—¶ğ—¼ğ—» ğ—˜ğ—»ğ˜ƒğ—¶ğ—¿ğ—¼ğ—»ğ—ºğ—²ğ—»ğ˜ look like?

MLOps practices are there to improve Machine Learning Product development velocity, the biggest bottlenecks happen when Experimentation Environments and other infrastructure elements are integrated poorly.

Letâ€™s look into the properties that an effective Experimentation Environment should have. As a MLOps engineer you should strive to provide these to your users and as a Data Scientist, you should know what you should be demanding for.

ğŸ­: Access to the raw data. While handling raw data is the responsibility of Data Engineering function, Data Scientists need the ability to explore and analyze available raw data and decide which of it needs to be moved upstream the Data Value Chain (2.1).

ğŸ®: Access to the curated data. Curated data might be available in the Data Warehouse but not exposed via a Feature Store. Such Data should not be exposed for model training in production environments. Data Scientists need the ability to explore curated data and see what needs to be pushed downstream (3.1).

ğŸ¯: Data used for training of Machine Learning models should be sourced from a Feature Store if the ML Training pipeline is ready to be moved to the production stage.

ğŸ°: Data Scientists should be able to easily spin up different types of compute clusters - might it be Spark, Dask or any other technology - to allow effective Raw and Curated Data exploration.

ğŸ±: Data Scientists should be able to spin up a production like remote Machine Learning Training pipeline in development environment ad-hoc from the Notebook, this increases speed of iteration significantly.

ğŸ²: There should be an automated setup in place that would perform the testing and promotion to a higher env when a specific set of Pull Requests are created. E.g. a PR from feature/* to release/* branch could trigger a CI/CD process to test and deploy the ML Pipeline to a pre-prod environment.

ğŸ³: Notebooks and any additional boilerplate code for CI/CD should be part of your Git integration. Make it crystal clear where a certain type of code should live - a popular way to do this is providing repository templates with clear documentation.

ğŸ´: Experiment/Model Tracking System should be exposed to both local and remote pipelines.

ğŸ—: Notebooks have to be running in the same environment that your production code will run in. Incompatible dependencies should not cause problems when porting applications to production. It can be achieved by running Notebooks in containers.

# References

