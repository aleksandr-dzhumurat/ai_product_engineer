{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Wp3AQGfDxy"
      },
      "source": [
        "# Градиентное обучение на примере линейной регрессии\n",
        "\n",
        "## Исходные данные\n",
        "\n",
        "Для этого занятия нам понадобится файл `non_linear.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XhdLAtqfEKG",
        "outputId": "7cfffc79-9846-4756-a9d2-6ea96732b064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Google drive connected\n",
            "['nyt-ingredients-snapshot-2015.csv', 'insurance (1).csv', 'non_linear.csv', 'client_segmentation.csv', 'eigen.pkl', 'clustering.pkl', 'boosting_toy_dataset.csv', 'politic_meme.jpg', 'gray_goose.jpg', 'test_dataset.pkl', 'memes', 'optimal_push_time', 'sklearn_data', 'my_little_recsys', 'corpora', 'logs', 'nltk_data', 'recsys_data', 'MNIST', 'hymenoptera_data', 'pet_projects', 'ocr_dataset_sample.csv', 'geo_points.csv.gzip', 'scored_corpus.csv', 'labeled_data_corpus.csv', 'memes_stat_dataset.zip', 'als_model.pkl', 'raw_data.zip', 'json_views.tar.gz', 'test_data.csv', 'sales_timeseries_dataset.csv.gz', 'brand_tweets_valid.csv', 'brand_tweets.csv', 'Health_and_Personal_Care.jsonl.gz', 'models', 'final_dataset.zip', 'ocr_dataset.zip', 'bidmachine_logs.zip', 'meta_Health_and_Personal_Care.jsonl.gz', 'messages.db', 'user_item_views.zip', 'content_catalog.zip', 'ground_truth_dataset.pkl', 'insurance.csv']\n",
            "Содержимое директории /content/drive/MyDrive/ml_course_data: ['nyt-ingredients-snapshot-2015.csv', 'insurance (1).csv', 'non_linear.csv', 'client_segmentation.csv', 'eigen.pkl', 'clustering.pkl', 'boosting_toy_dataset.csv', 'politic_meme.jpg', 'gray_goose.jpg', 'test_dataset.pkl', 'memes', 'optimal_push_time', 'sklearn_data', 'my_little_recsys', 'corpora', 'logs', 'nltk_data', 'recsys_data', 'MNIST', 'hymenoptera_data', 'pet_projects', 'ocr_dataset_sample.csv', 'geo_points.csv.gzip', 'scored_corpus.csv', 'labeled_data_corpus.csv', 'memes_stat_dataset.zip', 'als_model.pkl', 'raw_data.zip', 'json_views.tar.gz', 'test_data.csv', 'sales_timeseries_dataset.csv.gz', 'brand_tweets_valid.csv', 'brand_tweets.csv', 'Health_and_Personal_Care.jsonl.gz', 'models', 'final_dataset.zip', 'ocr_dataset.zip', 'bidmachine_logs.zip', 'meta_Health_and_Personal_Care.jsonl.gz', 'messages.db', 'user_item_views.zip', 'content_catalog.zip', 'ground_truth_dataset.pkl', 'insurance.csv']\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)  # гарантируем воспроизводимость\n",
        "\n",
        "run_env = os.getenv('RUN_ENV', 'COLLAB')\n",
        "if run_env == 'COLLAB':\n",
        "  from google.colab import drive\n",
        "  ROOT_DIR = '/content/drive'\n",
        "  drive.mount(ROOT_DIR)\n",
        "  print('Google drive connected')\n",
        "  root_data_dir = os.path.join(ROOT_DIR, 'MyDrive', 'ml_course_data')\n",
        "  sys.path.append(os.path.join(ROOT_DIR, 'MyDrive', 'src'))\n",
        "else:\n",
        "  root_data_dir = os.getenv('DATA_DIR', '/srv/data')\n",
        "\n",
        "print(os.listdir(root_data_dir))\n",
        "\n",
        "if not os.path.exists(root_data_dir):\n",
        "  raise RuntimeError('Отсутствует директория с данными')\n",
        "else:\n",
        "  print('Содержимое директории %s: %s' % (root_data_dir, os.listdir(root_data_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nNQLgELvYCw"
      },
      "source": [
        "Прочитаем `non_linear.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Xo_PT1EFlosg",
        "outputId": "55834641-9beb-4736-b028-a6245459eb5a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 34,\n  \"fields\": [\n    {\n      \"column\": \"x_train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2020474319990933,\n        \"min\": 1.1824212590087708,\n        \"max\": 4.937237703839815,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          4.641632389087622,\n          2.9120268240481963,\n          4.188790204786391\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8758000059467159,\n        \"min\": -0.336119849248448,\n        \"max\": 2.430015341483141,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          1.304593203003925,\n          0.1333746110430174,\n          0.0503130509855171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e190d712-aba7-40c5-9f1d-1411b57261a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_train</th>\n",
              "      <th>y_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.182421</td>\n",
              "      <td>1.860341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.251605</td>\n",
              "      <td>1.878928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.270474</td>\n",
              "      <td>2.430015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.402553</td>\n",
              "      <td>2.327856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.427711</td>\n",
              "      <td>2.203649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e190d712-aba7-40c5-9f1d-1411b57261a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e190d712-aba7-40c5-9f1d-1411b57261a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e190d712-aba7-40c5-9f1d-1411b57261a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f3c06e1b-9c28-4d23-838a-85f003ee6467\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3c06e1b-9c28-4d23-838a-85f003ee6467')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f3c06e1b-9c28-4d23-838a-85f003ee6467 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    x_train   y_train\n",
              "5  1.182421  1.860341\n",
              "6  1.251605  1.878928\n",
              "7  1.270474  2.430015\n",
              "8  1.402553  2.327856\n",
              "9  1.427711  2.203649"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "raw_data_file = os.path.join(root_data_dir, 'non_linear.csv')\n",
        "data = pd.read_csv(raw_data_file, sep=',')\n",
        "\n",
        "data = data[\n",
        "            (data.x_train > 1) & (data.x_train < 5)\n",
        "].copy()\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7rxP1_Cvht7"
      },
      "source": [
        "Визуализируем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "t1YNLriavgou",
        "outputId": "1a85b6a8-6e7b-4ddc-e48c-f8c7a1acb26c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.scatter(\n",
        "    data.x_train, data.y_train,\n",
        "    s=40, c='g', marker='o', alpha=0.8\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoyqHUCEPeKT"
      },
      "source": [
        "Создадим две отдельные переменные\n",
        "\n",
        "* $y$ для целевой переменной из столбца `y_train`. Удалим из исходного датафрейма с помощью `.drop()`\n",
        "* Все оставшиеся после удаления столбцы - это матрица объекты-признаки $X$\n",
        "\n",
        "Для матрицы объекты-признаки добавляем \"дефолтный\" признак из единиц."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2t7ZXPhBPcnK"
      },
      "outputs": [],
      "source": [
        "num_examlpes = data.shape[0]\n",
        "num_features = data.shape[0] - 1  # вычитаем единичку т.к. убрали столбец y\n",
        "X = np.zeros((num_examlpes, num_features + 1))  # размерность увеличилась на дефолтный столбец\n",
        "\n",
        "\n",
        "#-------- ВАШ КОД ТУТ -------------------\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA3w5X68b3tN"
      },
      "source": [
        "Создаём отложенную выборку для валидации - см. предыдущий семинар"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X2_WHqrb3-D"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZAjRY0ow4tt"
      },
      "source": [
        "### Аналитическое решение\n",
        "\n",
        "Для начала напишем код для аналитического вычисления коэффициентов линейной регрессии по формуле $\\overline{w} = \\left(X^TX\\right)^{-1}X^T\\overline{y}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "JIRf6h0XmnbC",
        "outputId": "14ce12c2-5623-4377-ba9c-6df1e2dcd6ea"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-400e4ad2d0bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# вычисляем к-ты линейной регрессии\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mw_analytic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#-------- ВАШ КОД ТУТ -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_features' is not defined"
          ]
        }
      ],
      "source": [
        "from numpy.linalg import inv\n",
        "import numpy as np\n",
        "\n",
        "# вычисляем к-ты линейной регрессии\n",
        "w_analytic = np.zeros(num_features)\n",
        "#-------- ВАШ КОД ТУТ -------------------\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------\n",
        "\n",
        "print(f'Аналитически определённые коэффициенты {w_analytic}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnWsfBHb9XrW"
      },
      "source": [
        "$$\n",
        "y = x_0*2.98 + x*(-0.67)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu0YN9WjZOQz"
      },
      "source": [
        "Плучите коэффициенты из класса `LinearRegression` - мы уже делали так на прошлом семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9FXb6uxZOg4",
        "outputId": "e998ef9e-6880-42f9-e551-0175b308d013"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "#-------- ВАШ КОД ТУТ -------------------\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL2lZQjPZJLu"
      },
      "source": [
        "Сравните по евклидовому расстоянию коэффициенты из класса `LinearRegression` и полученные аналитическим способом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LX9cURsvqsx"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import inv, norm\n",
        "\n",
        "#-------- ВАШ КОД ТУТ -------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lYoS48UaNAi"
      },
      "source": [
        "Проверка на правильность - пишем юнит-тест!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch2c16IbaEpg"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "\n",
        "\n",
        "class TestNotebook(unittest.TestCase):\n",
        "    def test_task(self):\n",
        "        self.assertAlmostEqual(linalg_norm, 0.000000, places=6)\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Критика аналитического решения\n",
        "\n",
        "почему не всегда работает - проверим на примере\n",
        "\n",
        "В уроке про варидацию столкнулись с ворненгом **LinAlgWarning** что это за ошибка? Почему она возникает? Как её побороть? На эти вопросы даст ответ градиентный спуск - способ обучения моделей, **не использующий матричное умножение**.\n",
        "\n",
        "## Основные понятия SGD\n",
        "\n",
        "Мы помним, что в случае многомерной линейной регрессии (когда количество фичей $m$) аналитическое решение имеет вид\n",
        "$$\n",
        "\\overline{w} = \\left(X^TX\\right)^{-1}X^T\\overline{y}\n",
        "$$\n",
        "\n",
        "Где $X$ - т.н. матрица объекты-признаки размености *количество объектов* x *количество признаков*.\n",
        "\n",
        "У аналитического решения есть ряд недостатков\n",
        "* вычислительная сложность из-за матричного перемножения $O(n^3)$, где $n$ - размерность матрицы. При увеличении размерности матрицы в 10 раз сложность вычислений увеличивается в $10^3=1000$ раз\n",
        "* **неустойчивость вычислений** - пытаемся найти обратную матрицу, которая может не существовать, в этом случае в алгоритме нахождения обратной матрицы возникает деление на ноль\n",
        "\n",
        "С неустойчивостью вычислений, например, связано предупреждение **LinAlgWarning:** которое мы видели в первом уроке. Пример такой матрицы:\n",
        "$$\n",
        "X^TX =\n",
        "\\left[\n",
        "\\begin{array}{cc}\n",
        "5 & 25 \\\\\n",
        "2 & 10\n",
        "\\end{array}\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "Допустим, хотим вычислить коэффициенты аналитически. Если попытаемся найти обратную матрицу $(X^TX)^{-1}$, мы получим сообщение об ошибке:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# матрица из примера\n",
        "X = np.array([\n",
        "    [5, 25],\n",
        "    [2, 10]\n",
        "])\n",
        "# пытаемся найти обратную\n",
        "np.linalg.inv(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Это очень печально - значит, мы не всегда можем применять аналитическую формулу $\\overline{w} = \\left(X^TX\\right)^{-1}X^T\\overline{y}$ для нахождения коэффициентов $\\overline{w}$ Как же быть, если задачу решать все равно надо?\n",
        "\n",
        "Решение этих проблем нашли математики - давайте вычислять коэффициенты линейной регрессии не аналитически, а с помощью приближённых численных методов. Тогда не надо будет перемножать матрицы или находить обратные матрицы. Самый простой и эффективный из этих методов называется методом *градиентного спуска*. Суть метода состоит в обновлении параметров модели $w$ по маленьким шажкам (вместо того, чтобы находить их сразу) - это и есть градиентный спуск.\n",
        "\n",
        "Каждый такой шажок назвается \"итерация\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Мы знаем, что коэффициенты обучаются при помощи минимизации функции ошибок:\n",
        "\n",
        "$$\n",
        "L(y,w) = \\sum_{i=1}^{N}\\left(y_i - \\hat{y_i}\\right)^2\n",
        "$$\n",
        "\n",
        "Эта функция квадратичная - следовательно, имеет форму параболы. Минимум параболы соответствует минимуму ошибки - давайте как-то понемногу \"подкручивать\" параметры, чтобы по шажкам спуститься в точку, где ошибка будет минимальной - в этой точке и находятся параметры $w$, которые мы ищем. Правила обновления весов должны быть очень простыми и не содержать матричных перемножений\n",
        "\n",
        "![grad_descent_single_measure](img/grad_descent_single_measure.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В трёхмерном случае картинка более красивая - мы движемся как бы ландшафту и хотим найти самую нижнюю точку на этом ландшафте:\n",
        "\n",
        "![grad_descent_single_measure](img/grad_descent_multi_measure.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В в библиотеке sklearn уже есть класс, в котором реализована логика такого путешествия - это класс `sklearn.linear_model.SGDRegressor`. Давайте посмотрим, как он работает на примере нашей выборки из прошлого урока - начнём с загрузки исходных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trz0jpmbHN04"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# для регрессии\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.spatial import distance\n",
        "%matplotlib inline\n",
        "\n",
        "data = pd.read_csv('data/non_linear.csv', sep=',')\n",
        "data = data[(data.x_train > 1) & (data.x_train < 5)].copy()\n",
        "\n",
        "y = data['y_train'].reshape(-1, 1)  # таргет\n",
        "X = data.drop('y_train', axis=1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgAXuGzgcfcG"
      },
      "source": [
        "## Градиентный спуск из sklearn\n",
        "\n",
        "Используем готовую реализацию и функцию [.fit_partial()](https://scikit-learn.org/0.15/modules/scaling_strategies.html#incremental-learning)\n",
        "\n",
        "Для градиентного спуска мы используем готовый класс [sklearn.linear_model.SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html). Класс принимает следующие параметры\n",
        "\n",
        "* `learning_rate='constant'` используем самую простую модификацию спуска из нескольких возможных (см. доументацию)\n",
        "* `eta0=0.009` - шаг градиентного спуска, в формуле мы его обозначали буквой $\\eta$\n",
        "* `fit_intercept=True` - чтобы обучить коэффициент при \"свободном члене\" $w_0$ линейной регрессии (см. лекцию)\n",
        "* `random_state=RANDOM_SEED` - этот параметр встречали ранее в этом модуле, он нужен для воспроизводимости вычислений.\n",
        "\n",
        "Псевдокод решения (нужно закодить самостоятельно, если возникнут сложности - подсмотреть в лекции):\n",
        "\n",
        "* инициализируем `w_current` рандомом, `weight_evolution` и `rmse_evolution` пустыми списками, и критерий остановки $\\varepsilon=0.0001$\n",
        "* задаём максимальное число шагов `800` и далее на каждом шаге\n",
        "  * вызываем `.partial_fit`\n",
        "  * `.coef_` содержит текущие веса - применяем [from scipy.spatial.distance.euclidean](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean) и сверяем с критерием остановки. Если критерий не выполняется - обновляем rmse с помощью [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) на `y_valid` и предикт на `X_valid` и переназначаем `w_current` на атрибут `.coef_.copy()`\n",
        "\n",
        "Когда критерий остановки выполнился - визуализируем `rmse_evolution`, мы должны увидеть т.н. кривую обучения с помощью `.plot(range(step), rmse_evolution)`\n",
        "\n",
        "Новая библиотека в нашем арсенале  - scipy, изучите её документацию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "WD_RpbQjcjdP",
        "outputId": "f5200b17-f5d7-4a84-c85d-2cd786b49ad6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-24 17:55:49,213 : INFO : Обучение закончилось\n",
            "2022-01-24 17:55:49,216 : INFO : Количество пройденных итераций 160\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5378c89910>]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# можно установить None для эксперимента\n",
        "rand_state = 42\n",
        "\n",
        "sgd_regressor = SGDRegressor(\n",
        "    learning_rate='constant',\n",
        "    eta0=0.009,\n",
        "    fit_intercept=True,\n",
        "    random_state=rand_state\n",
        ")\n",
        "\n",
        "# инициализация весов случайным образом\n",
        "w_current = np.random.random(2)\n",
        "epsilon = 0.0001\n",
        "\n",
        "# изменения весов и ошибка на валидации\n",
        "weight_evolution, rmse_evolution = [], []\n",
        "\n",
        "for step in list(range(800)):\n",
        "    # шаг градиентного спуска\n",
        "    sgd_regressor = sgd_regressor.partial_fit(X_train, y_train)\n",
        "    # отслеживаем изменения весов\n",
        "    weight_evolution.append(\n",
        "        distance.euclidean(w_current, sgd_regressor.coef_)\n",
        "    )\n",
        "    # проверяем критерий остановки\n",
        "    if weight_evolution[-1] < epsilon:\n",
        "        print(\"Итарации остановлены на шаге %d\" % step); break\n",
        "    rmse_evolution.append(\n",
        "        mean_squared_error(y_valid, sgd_regressor.predict(X_valid))\n",
        "    )\n",
        "    # обновление весов регрессии\n",
        "    w_current = sgd_regressor.coef_.copy()\n",
        "plt.plot(range(step), rmse_evolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4FbEsKOe_hi"
      },
      "source": [
        "Визуализируйте решение на графике\n",
        "\n",
        "Примерный результат который следует ожидать\n",
        "\n",
        "![fitteg_reg](img/linear_regression_fitted.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Coy40Ffbe_2b"
      },
      "outputs": [],
      "source": [
        "x_linspace = np.linspace(data['x_train'].min(), data['x_train'].max(), num=100)\n",
        "\n",
        "y_linspace= sgd_regressor.predict(x_linspace.reshape(-1,1))\n",
        "\n",
        "plt.plot(x_linspace, y_linspace)\n",
        "plt.scatter(data.x_train, data.y_train, 40, 'g', 'o', alpha=0.8, label='data')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Практическое задание** очевидно, что чем больше шаг градиентного спуска (параметр *eta0* класса *SGDRegressor*), тем быстрее мы придём к оптимальным значениям. Используя под выше, поиграйтесь с параметром *eta0* и добейтесь , чтобы градиентный спуск закончился быстрее, чем за 200 шагов.\n",
        "\n",
        "Сколько шагов у вас получилось? Какое качество *RMSE* у Вашего решения?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------- ВАШ КОД ТУТ -------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qohl7GmfcLD"
      },
      "source": [
        "Готово! Мы получили решение задачи линейной регрессии, обучив параметры линейной регресии небольшими \"шажками\". Мы не использовали сложных матричных вычислений - тем не менее получили линию регрессии, которая лежит в середине облака точек. Когда стоит использовать градиентный спуск в реальных задачах?\n",
        "\n",
        "* когда данных очень много - в этом случае компьютер может не справится с перемножением матриц\n",
        "* когда нужно контролировать точность обучения - остановить итерации можно в любой момент (не дожидаясь, пока дойдем до \"идеальных\" значений.\n",
        "\n",
        "Когда не стоит применять градиентный спуск? Когда данных мало - в этом случае лучше воспользоваться точным решением"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UApF2WKHeq3z"
      },
      "source": [
        "**Практическое задание** очевидно, что чем больше шаг градиентного спуска (параметр *eta0* класса *SGDRegressor*), тем быстрее мы придём к оптимальным значениям. Используя под выше, поиграйтесь с параметром *eta0* и добейтесь , чтобы градиентный спуск закончился быстрее, чем за 200 шагов.\n",
        "\n",
        "Сколько шагов у вас получилось? Какое качество *RMSE* у Вашего решения на валидационной выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X9HVuNUerDM"
      },
      "outputs": [],
      "source": [
        "#-------- ВАШ КОД ТУТ -------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNrWHNTUe8Kt"
      },
      "source": [
        "## Реализация GD на python\n",
        "\n",
        "\n",
        "\"Маленькие шажки\", которыми мы двигаемся к оптимальному решению в виде формулы выглядят следующим образом:\n",
        "$$\n",
        "w^{k+1} = w^k - \\eta\\nabla L(w)\n",
        "$$\n",
        "Переменная $\\eta$ в формуле - т.н. *шаг градиентного спуска*.\n",
        "\n",
        "Где $\\nabla L(w)$ - вектор градиента функции. Этот вектор обладает следующими свойствами:\n",
        "\n",
        "* имеет размерность вектора параметров. Если два параметра $[w_1,w_0]$ - в векторе будет два элемента\n",
        "* элемент градиента под номером $i$ - это частная производная (вспоминаем математику за 11 класс и [смотрим в Википедию](https://ru.wikipedia.org/wiki/Производная_функции ) ) функции потерь $L(y, w)$ по параметру $w_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Вектор антиградиента всегда направлен в сторону уменьшения функции - в этом и есть всё волшебство! Мы будем двигаться в сторону минимума функции ошибки, потому что знаем как туда попасть - надо следовать по антиградиенту.\n",
        "\n",
        "На картинке одномерный случай. Синяя стрелка - градиент, красная - антиградиент. Видно, что если двигаться по вектору антиградиента, то свалимся в минимум функции за конечное число шагов\n",
        "![grad_vector](img/grad_vector.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Алгоритм визуально выглядит довольно интуитивно - (1) у тебя есть вектор-стрелочка (2) шагай по стрелочке, пока не попадёшь на дно \"оврага\", который представляет собой целевую функцию . В трёхмерном случае оптимальное значение функции находится в центре концентрицеских эллипсов (эллипс - проекция трёхмерной фигуры функции потерь на плоскость):\n",
        "\n",
        "![grad_descent](img/grad_descent_intuit.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как туда добраться, двигаясь маленькими шажками?\n",
        "\n",
        "1. Стартуем алгоритм в случайной начальной точке $x^0$  \n",
        "1. Вычисляем направление антиградиента $-f'(x^0)$ (буквально: производная со знаком \"минус\")\n",
        "1. Перемещаемся по направлению градиента в точку $x^1 = x^0 - \\eta f'(x^0)$\n",
        "1. Повторяем шаги (1-3) для попадания в точку $x^2$\n",
        "1. $\\ldots$\n",
        "1. Profit! Достигли оптимальной точки $x^*$\n",
        "\n",
        "Алгоритм выше - универсальный, он позволяет найти точку минимума любой функции $f(x)$. А как же нам найти минимум функции качества линейной регрессии $L$?\n",
        "\n",
        "$$\n",
        "L(y,w) = \\sum_{i=1}^{N}\\left(y_i - \\hat{y_i}\\right)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Чтобы реализовать алгоритм градиентного спуска, выпишем частные прозводные функции качества линейной регрессии $L$ для параметров $\\overline{w} = [w_1,\\ldots,w_m]$ в простейшем случае $n=1$, то есть для одного обучающего примера (одного наблюдения):\n",
        "$$\n",
        "\\left\\{\n",
        "\\begin{array}{cc}\n",
        "\\frac{\\partial L}{\\partial w_0} = 2\\cdot(-1)\\cdot1\\cdot (y_1 - (w_0x_0^1 + \\ldots+w_mx_m^1)) &\\\\\n",
        "\\frac{\\partial L}{\\partial w_k} = 2\\cdot(-1)\\cdot x_1^1 \\cdot (y_1 - (w_0x_0^1 + \\ldots+w_mx_m^1)) &  k\\neq 0\\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "В формуле все обозначения вам известны\n",
        "\n",
        "* $w_0, \\ldots, w_m$ - коэффициенты линейной регрессиии $m$ - количество фичей\n",
        "* $x_0, \\ldots, x_m$ - фичи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Эту формулу с частными производными можно легко обобщить на случай, когда в обучающей выборке не один объект, а $n$ - просто добавляем сумму по всем объектам от 1 до $n$:\n",
        "$$\n",
        "\\left\\{\n",
        "\\begin{array}{cc}\n",
        "\\frac{\\partial L}{\\partial w_0} = \\frac{2}{n}\\cdot(-1)\\cdot \\sum_{i=1}^{n} 1\\cdot \\left(y_i - \\sum_{j=1}^{m}w_jx_j^i\\right) &\\\\\n",
        "\\frac{\\partial L}{\\partial w_k} = \\frac{2}{n}\\cdot(-1)\\cdot \\sum_{i=1}^{n} x_k^i \\cdot\\left(y_i - \\sum_{j=1}^{m}w_jx_j^i\\right) & k\\neq 0 \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Что значат переменные в этой формуле?\n",
        "* $n$ - число точек в обучающей выборке\n",
        "* $m$ - число фичей в датасете\n",
        "* $k$ - номер коэффициента в списке параметров линейной регрессии $w = [w_0,\\ldots,w_m]$\n",
        "* $y_i$ - значение целевой переменной на объекте обучающей выборки под номером $i$\n",
        "* $x_j^i$ - значение фичи под номером $j$ на объекте обучающей выборки под номером $i$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Алгоритм градиентного спуска следующий:\n",
        "\n",
        "1. Вычислить градиент $\\nabla L(w)$\n",
        "1. Вычислить новый вектор  $w^{k+1} = w^k - \\eta\\nabla L(w)$\n",
        "1. Повторять пункты до тех пор, пока $w^{k+1}$ и $w^{k}$ не сойдутся вместе, то есть вектор весов перестанет обновляться\n",
        "\n",
        "Чтобы лучше понять этот метод, давайте реализуем его \"с нуля\" на языке Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHX2RxBNe7Ei"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradient(X, y, w, alpha=0) -> np.array:\n",
        "    \"\"\"Вычисляем градиент в точке\"\"\"\n",
        "    # количество обучающих примеров в выборке\n",
        "    n = X.shape[0]\n",
        "    # считаем прогноз\n",
        "    y_hat = X.dot(w.T)\n",
        "    # вычисляем ошибку прогноза\n",
        "    error = y - y_hat\n",
        "    # дальше pointwise перемножение - умножаем каждую из координат на ошибку\n",
        "    pointwise_errors = np.multiply(X, error) + X\n",
        "    # вычисляем градиент и ошибку\n",
        "    grad = pointwise_errors.sum(axis=0)*(-1.0)*2.0 / n\n",
        "    return grad, error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd_ZB5TBjwhg"
      },
      "source": [
        "Делаем шаг градиентного спуска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM40X0QPe1Yl"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "def eval_w_next(X, y, eta, w_current):\n",
        "    \"\"\"Делаем шаг градиентного спуска\"\"\"\n",
        "    # вычисляем градиент\n",
        "    grad, error = gradient(X, y, w_current)\n",
        "    # делаем шаг градиентного спуска\n",
        "    w_next = w_current - eta*grad\n",
        "    # проверяем условие сходимости\n",
        "    weight_evolution = distance.euclidean(w_current, w_next)\n",
        "    return (w_next, weight_evolution, grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6-FWVBVlBZ4"
      },
      "source": [
        "Повторяем шаги (1,2) до сходимости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxuc9S74lB8_"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X: np.array, y: np.array, eta=0.01, epsilon=0.001) -> np.array:\n",
        "    m = X.shape[1] # количество фичей\n",
        "    # инициализируем рандомом веса\n",
        "    w = np.random.random(m).reshape(1, -1)\n",
        "    w_next, weight_evolution, grad = eval_w_next(X, y, eta, w)\n",
        "    step = 0\n",
        "    # повторяем до сходимости вектора весов\n",
        "    while weight_evolution > epsilon:\n",
        "        w = w_next\n",
        "        w_next, weight_evolution, grad = eval_w_next(X, y, eta, w)\n",
        "        step += 1\n",
        "        if step % 100 ==0:\n",
        "            logger.info(\"step %s |w-w_next|=%.5f, grad=%s\", step, weight_evolution, grad)\n",
        "    return w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KC41Nu-lRQM"
      },
      "source": [
        "Запускаем обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06DCGLtBlRce"
      },
      "outputs": [],
      "source": [
        "# трансформируем плоский массив X в вектор-столбец\n",
        "X = data['x_train'].values.reshape(-1, 1)\n",
        "n = X.shape[0]\n",
        "# добавляем тривиальный признак w_0, столбец из единиц. См. прошлый урок, почему так\n",
        "X = np.hstack([\n",
        "    np.ones(n).reshape(-1,1),\n",
        "    X\n",
        "])\n",
        "w = gradient_descent(\n",
        "    X,\n",
        "    data['y_train'].values.reshape(-1, 1),\n",
        "    eta=0.008\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "102VDJxOlaSn"
      },
      "source": [
        "У нас произошло несколько сотен итераций, на каждой итерации мы:\n",
        "* вычисляем вектор весов\n",
        "* смотрим расстояние между новым вектором весов и векторов весов с предыдущего шага\n",
        "* если изменения в векторе весов небольшие (скажем, четвёртый знак поcле запятой) - останавливаем итерации\n",
        "\n",
        "Когда вектор перестаёт меняться - говорят, что алгоритм \"сошёлся\" (имеется в виду сходимость к оптимальной точке) - это значит, что итерации можно останавливать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWCXrJmila2v"
      },
      "outputs": [],
      "source": [
        "support = np.linspace(X.min(), X.max(), num=100)\n",
        "# делаем предикт - считаем предсказания модели в каждой точке обучающей выборке в виде y=X*w\n",
        "y_hat = np.hstack([\n",
        "    np.ones(support.size).reshape(-1, 1),\n",
        "    support.reshape(-1, 1)\n",
        "]).dot(w.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PghJGwPEllda"
      },
      "source": [
        "визуализируем результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_bTZVbBld8D"
      },
      "outputs": [],
      "source": [
        "# строим график\n",
        "plt.plot(support, y_hat, 'b--', alpha=0.5, label='manifold')\n",
        "plt.scatter(data['x_train'], data['y_train'], 40, 'g', 'o', alpha=0.8, label='data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Особенности градиентного спуска**\n",
        "\n",
        "1. Нужно подбирать параметр $\\eta$. Еcли выбрать параметр слишком малым, то обучение регрессии будет происходить слишком медленно. Если слишком большим - вычисления не сойдутся к оптимуму. Вариант решения - адаптивный выбор величины шага\n",
        "1. Долгие вычисления, если размер выборки $n$ становится большим. В этом случае мы можем вычислять градиент не по всей выборке за один шаг, а по одному случайному элементу выборки - в этом случае вычислений значительно меньше.\n",
        "\n",
        "Кроме того, градиент можно считать не только по одному объекту, но и по случайной подвыборке (батчу). Такая модификация алгоритма называется градиентным спуском по мини-батчам.\n",
        "\n",
        "\n",
        "Хорошая теория [тут](http://www.machinelearning.ru/wiki/images/6/68/voron-ML-Lin.pdf). Неплохая статья с разбором [формул обновления весов](https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd). Видео от [специализации ШАД на coursera](https://ru.coursera.org/lecture/supervised-learning/gradiientnyi-spusk-dlia-linieinoi-rieghriessii-adARX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
