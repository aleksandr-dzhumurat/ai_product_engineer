{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngEBDlPa5Q2Y"
   },
   "source": [
    "# Feature egineering\n",
    "\n",
    "Подключаем google диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NFkdRiFT5RLv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Содержимое директории %s: %s /Users/adzhumurat/PycharmProjects/ai_product_engineer/data ['client_segmentation.csv', 'messages.db', 'labeled_data_corpus.csv', 'content_description.csv', 'nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)  # гарантируем воспроизводимость\n",
    "\n",
    "run_env = os.getenv('RUN_ENV', 'COLLAB')\n",
    "if run_env == 'COLLAB':\n",
    "  from google.colab import drive\n",
    "  ROOT_DIR = '/content/drive'\n",
    "  drive.mount(ROOT_DIR)\n",
    "  print('Google drive connected')\n",
    "  DRIVE_DATA_DIR = 'ml_course_data'\n",
    "  root_data_dir = os.path.join(ROOT_DIR, 'MyDrive', DRIVE_DATA_DIR)\n",
    "else:\n",
    "  root_data_dir = os.getenv('DATA_DIR', '/srv/data')\n",
    "\n",
    "if not os.path.exists(root_data_dir):\n",
    "  raise RuntimeError('Отсутствует директория с данными')\n",
    "else:\n",
    "  print('Содержимое директории %s: %s', root_data_dir, os.listdir(root_data_dir)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMpcMke_8ErE"
   },
   "source": [
    "Библиотеки для работы с картинками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I90TPsOdOzoW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/Users/adzhumurat/PycharmProjects/ai_product_engineer/data/models'\n",
      "Модель загружена\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "TORCH_MODELS_DIR = os.path.join(root_data_dir, 'models')\n",
    "try:\n",
    "  os.mkdir(TORCH_MODELS_DIR)\n",
    "except FileExistsError as e:\n",
    "  print(e)\n",
    "\n",
    "os.environ['TORCH_HOME'] = TORCH_MODELS_DIR # TORCH_MODEL_ZOO is deprecated\n",
    "rn18 = resnet18(weights=True)\n",
    "\n",
    "# запускаем вычисления на GPU\n",
    "# rn18 = rn18.to('cuda:0')\n",
    "print('Модель загружена')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ajlIo1veOAh"
   },
   "source": [
    "# Эмбеддинги картинок\n",
    "\n",
    "Для начала посмотрим, какие слои есть в сети\n",
    "\n",
    "Кроме `.modules` можно было воспользоваться `.named_children()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JsS8ABYWjZPe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "avgpool\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "for layer in rn18._modules:\n",
    "  print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR0Y-xXhjcvj"
   },
   "source": [
    "Нам нужен слой `avgpool`\n",
    "\n",
    "Каждый слой это по сути массив c весами модели - нам нужно оставить все слои ДО того слоя, который нас интересует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O0vT7v73V9cd"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, output_layer, torch_model):\n",
    "        super().__init__()\n",
    "        self.output_layer = output_layer\n",
    "        self.pretrained = torch_model\n",
    "        self.children_list = []\n",
    "        for n,c in self.pretrained.named_children():\n",
    "            self.children_list.append(c)\n",
    "            if n == self.output_layer:\n",
    "                print('final layer archived: %s' % output_layer)\n",
    "                break\n",
    "\n",
    "        self.net = nn.Sequential(*self.children_list)\n",
    "        self.pretrained = None\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnR8wWKSpRhV"
   },
   "source": [
    "Создаём объект-экстрактор с выборанным слоем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NAiIQvreOvL-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final layer archived: avgpool\n"
     ]
    }
   ],
   "source": [
    "resnet_extractor = FeatureExtractor(output_layer='avgpool', torch_model=rn18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IO1wL1d4Fs2E"
   },
   "source": [
    "Проверяем директорию с картинками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJXkiao5FtGl"
   },
   "outputs": [],
   "source": [
    "ROOT_MEMES_DIR = os.path.join(root_data_dir, 'memes')\n",
    "\n",
    "os.listdir(ROOT_MEMES_DIR)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTVdn7QPNG18"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "filename = os.path.join(ROOT_MEMES_DIR, '7f3ywc.jpeg')\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "type(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwJLliIoV9fm"
   },
   "outputs": [],
   "source": [
    "from torch import no_grad, cuda\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# transform = transforms.ToTensor()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "image_tensor = preprocess(input_image)\n",
    "input_batch = image_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    resnet_extractor.to('cuda')\n",
    "\n",
    "with no_grad():\n",
    "    output = resnet_extractor(input_batch)\n",
    "    numpy_vector = output.reshape(-1).cpu().numpy()  # flatten(output)\n",
    "    print(type(output), output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXbdwdq4kc1M"
   },
   "outputs": [],
   "source": [
    "numpy_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7srLON2V9jL"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL.JpegImagePlugin import JpegImageFile\n",
    "from torch import no_grad, cuda\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "def img2embedding(input_meme_filename: str) -> np.array:\n",
    "  OUTPUT_SHAPE = 512\n",
    "  numpy_vector = np.zeros(OUTPUT_SHAPE)\n",
    "  preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "\n",
    "  try:\n",
    "    input_img = Image.open(input_meme_filename) # type: JpegImageFile\n",
    "  except UnidentifiedImageError:\n",
    "    return numpy_vector\n",
    "  try:\n",
    "    image_tensor = preprocess(input_img)\n",
    "  except RuntimeError:\n",
    "    #  logger.info('error with %s meme', meme_filename.split('/')[-1])\n",
    "    return numpy_vector\n",
    "  input_batch = image_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "  # move the input and model to GPU for speed if available\n",
    "  if cuda.is_available():\n",
    "      input_batch = input_batch.to('cuda')\n",
    "      resnet_extractor.to('cuda')\n",
    "\n",
    "  with no_grad():\n",
    "      output = resnet_extractor(input_batch)\n",
    "      numpy_vector = output.reshape(-1).cpu().numpy()  # flatten(output)\n",
    "  return numpy_vector\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(ROOT_MEMES_DIR, 'embed.npy')):\n",
    "  embeds_matrix = np.load(os.path.join(ROOT_MEMES_DIR, 'embed.npy'))\n",
    "  with open(os.path.join(ROOT_MEMES_DIR, 'file_index.pkl'), 'rb') as f:\n",
    "    file_index = pickle.load(f)\n",
    "    print('files loaded from dump')\n",
    "else:\n",
    "  res = []  # тут основная информация о контенте\n",
    "  file_index = {}\n",
    "  TOP = 3092\n",
    "  error_files = []\n",
    "  print('Processing started')\n",
    "  dense_index = 0\n",
    "  for f_name in os.listdir(ROOT_MEMES_DIR)[:TOP]:\n",
    "    meme_filename = os.path.join(ROOT_MEMES_DIR, f_name)\n",
    "    img_embed = img2embedding(meme_filename)\n",
    "    if img_embed.sum() == 0:\n",
    "      error_files.append(meme_filename)\n",
    "    # сохраняяем эмбеддинг (их потом схлопнем в матрицу) и отдельно индекс файла в матрице\n",
    "    res.append(img_embed)\n",
    "    file_index[dense_index] = {'f_name': f_name}\n",
    "    dense_index += 1\n",
    "\n",
    "  if len(error_files) > 0:\n",
    "    print('num errors %d', len(error_files))\n",
    "    for i in error_files:\n",
    "      os.remove(i)\n",
    "\n",
    "  embeds_matrix = np.vstack(res)\n",
    "\n",
    "print(embeds_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOg4T8CSy6mE"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# np.save(os.path.join(ROOT_MEMES_DIR, 'embed.npy') , embeds_matrix)\n",
    "# with open(os.path.join(ROOT_MEMES_DIR, 'file_index.pkl'), 'wb') as f:\n",
    "#   pickle.dump(file_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1oNoJ7r4NrQ"
   },
   "source": [
    "Устанавливаем umap\n",
    "\n",
    "пример из [официальной документации](https://umap-learn.readthedocs.io/en/latest/basic_usage.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIB3Gio54bEH"
   },
   "outputs": [],
   "source": [
    "run_env = os.getenv('RUN_ENV', 'COLLAB')\n",
    "if run_env == 'COLLAB':\n",
    "    !pip install umap-learn==0.5.2\n",
    "    clear_output()\n",
    "print('UMAP was installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkKLwLXjV9pN"
   },
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "scaled_memes_data = StandardScaler().fit_transform(embeds_matrix)\n",
    "low_rank_matrix = reducer.fit_transform(scaled_memes_data)\n",
    "print('low rank matrix shape %s', low_rank_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IohdafZC4BGE"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(\n",
    "    low_rank_matrix[:, 0],\n",
    "    low_rank_matrix[:, 1],\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the memes dataset', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH_jWch79kwL"
   },
   "source": [
    "Получился один \"кластер\"\n",
    "\n",
    "Выполняем кластеризацию в низкоразмерном пространстве с помощью DBScan чтобы выделить метки кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jnd8NpVU82a5"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clstr = DBSCAN(eps=0.10, min_samples=4)\n",
    "classes = clstr.fit_predict(low_rank_matrix)\n",
    "print('num classes %s', np.unique(classes).size)\n",
    "\n",
    "plt.scatter(\n",
    "    low_rank_matrix[:, 0],\n",
    "    low_rank_matrix[:, 1],\n",
    "    c=classes,\n",
    "    cmap='rainbow',\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the memes dataset', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDMlsmsH95Wp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "clusters_filename = os.path.join(ROOT_MEMES_DIR, 'dbscan_clusters.csv')\n",
    "if os.path.exists(clusters_filename):\n",
    "  memes_df = pd.read_csv(clusters_filename)\n",
    "  print('loaded_from %s', clusters_filename)\n",
    "else:\n",
    "  df_rows = []\n",
    "  for meme_index in range(low_rank_matrix.shape[0]):\n",
    "    df_rows.append((file_index[meme_index]['f_name'], classes[meme_index]))\n",
    "  memes_df = pd.DataFrame(df_rows, columns=['f_name', 'dbscan_cluster'])\n",
    "print('%s', memes_df['dbscan_cluster'].value_counts().head(10).to_dict())\n",
    "memes_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQCktlEc_kDg"
   },
   "outputs": [],
   "source": [
    "memes_df.to_csv(os.path.join(ROOT_MEMES_DIR, 'dbscan_clusters.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgXRufB2wqcy"
   },
   "source": [
    "Видно, что есть кластер с индексом `0` где большая часть контента и меньшие по можности кластера. ДЛя сравнения визуализируем кластер c индексом `3` и кластер с индексом `4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FF2rdTNY-00U"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for f_name in os.listdir(ROOT_MEMES_DIR):\n",
    "#   if f_name not in ('file_index.pkl', 'embed.npy'):\n",
    "#     os.rename(os.path.join(ROOT_MEMES_DIR, f_name), os.path.join(ROOT_MEMES_DIR, f_name.split('.')[0]+'.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBYpBbhsnLyt"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as NotebookImage\n",
    "from IPython.display import display\n",
    "\n",
    "def visualise_cluster(cluster_id: int, top=10):\n",
    "  for _, row in memes_df.query(f'dbscan_cluster == {cluster_id}').head(top).iterrows():\n",
    "    tmp_file_path = os.path.join(ROOT_MEMES_DIR, row['f_name']+'.jpeg')\n",
    "    pil_img = NotebookImage(filename=tmp_file_path, width=200)\n",
    "    display(pil_img)\n",
    "\n",
    "visualise_cluster(cluster_id=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vo-c3xLGxuUB"
   },
   "outputs": [],
   "source": [
    "visualise_cluster(cluster_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihMWhvMCCaas"
   },
   "outputs": [],
   "source": [
    "visualise_cluster(cluster_id=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Y_DGvqiEvK_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
