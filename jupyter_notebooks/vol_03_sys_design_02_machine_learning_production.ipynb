{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ4vPv3dmmGL"
      },
      "source": [
        "# Machine learning в продакшне\n",
        "\n",
        "Поговорим, от том, как выводить модели в продакшн. Вы уже знакомы с понятием \"жизненный цикл ML проекта\" - сегодня мы увидим, как этот цикл выглядит в реальной жизни и попробуем вывести в продакшн модель классификации с помощью технологии виртуализации Docker (можно и без docker)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)  # гарантируем воспроизводимость\n",
        "\n",
        "run_env = os.getenv('RUN_ENV', 'COLLAB')\n",
        "if run_env == 'COLLAB':\n",
        "  from google.colab import drive\n",
        "  ROOT_DIR = '/content/drive'\n",
        "  drive.mount(ROOT_DIR)\n",
        "  print('Google drive connected')\n",
        "  DRIVE_DATA_DIR = 'ml_course_data'\n",
        "  root_data_dir = os.path.join(ROOT_DIR, 'MyDrive', DRIVE_DATA_DIR)\n",
        "else:\n",
        "  root_data_dir = os.getenv('DATA_DIR', '/srv/data')\n",
        "\n",
        "if not os.path.exists(root_data_dir):\n",
        "  raise RuntimeError('Отсутствует директория с данными')\n",
        "else:\n",
        "  print('Содержимое директории %s: %s', root_data_dir, os.listdir(root_data_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XffRMTGBmpqb",
        "outputId": "2eeee119-3b5d-4436-9480-d0ab051de90c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google drive connected\n",
            "Содержимое директории %s: %s /content/drive/MyDrive/ml_course_data ['nyt-ingredients-snapshot-2015.csv', 'insurance.csv', 'non_linear.csv', 'client_segmentation.csv', 'eigen.pkl', 'clustering.pkl', 'boosting_toy_dataset.csv', 'politic_meme.jpg', 'gray_goose.jpg', 'test_dataset.pkl', 'memes', 'optimal_push_time', 'sklearn_data', 'my_little_recsys', 'corpora', 'logs', 'nltk_data', 'recsys_data', 'MNIST', 'hymenoptera_data', 'pet_projects', 'ocr_dataset_sample.csv', 'geo_points.csv.gzip', 'scored_corpus.csv', 'labeled_data_corpus.csv', 'memes_stat_dataset.zip', 'als_model.pkl', 'raw_data.zip', 'json_views.tar.gz', 'test_data.csv', 'sales_timeseries_dataset.csv.gz', 'brand_tweets_valid.csv', 'brand_tweets.csv', 'Health_and_Personal_Care.jsonl.gz', 'models', 'corpus_embeds_0.npy', 'final_dataset.zip', 'ocr_dataset.zip', 'bidmachine_logs.zip', 'meta_Health_and_Personal_Care.jsonl.gz', 'messages.db', 'user_item_views.zip', 'content_catalog.zip', 'ground_truth_dataset.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybgmOHbDmmGM"
      },
      "source": [
        "В первом уроке мы поговорим о том, как обосновать перед бизнесом необходимость внедрения новой ML-системы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DImGce7TmmGN"
      },
      "source": [
        "## Оффлайн эксперимент. Proof concept\n",
        "\n",
        "В рамках курса вы\n",
        "* узнали про огромное количество моделей: классификация, регрессия\n",
        "* научились оценивать качество моделей\n",
        "* можете готовить данные для алгоритмов, включая генерацию фичей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOvQlgA4mmGN"
      },
      "source": [
        "Однако, бизнесу не интересны задачи классификации или регрессии - бизнесу интересно зарабатывать деньги. Чтобы заработать деньги с помощью ML нужно найти конкретную бизнес-проблему, поиском проблем в бизнесе должен заниматься владелец бизнеса (в методологии Agile его зовут Product Owner) и понять, как эту бизнес-проблему можно решить. После такого  начального этапа выявления проблемы бизнес-хотелка отдаётся ML-специалисту, который должен создать инженерное решение для проблемы и интергрировать его в продакшн - после выкатывания прототипа \"в прод\" бизнес начинает зарабатывать миллионы и все счастливы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LffIteNmmGO"
      },
      "source": [
        "Ниже я приведу полный путь от бизнес-идеи до прототипа - такой путь проходит любой проект ML, а называют такой пайплайн Proof of concept:\n",
        "\n",
        "1. Перейти от общих слов продукт оунера к конкретным бизнес-требованиям. Желательно, чтобы DS проводил её сам (возможно привлечь бизнес-аналитика).\n",
        "1. Описать дизайн (схему) эксперимента. Нужно понять, как повлиять на бизнес-метрики из первого пункта. На этом этапе нужно понять, какая информация доступна на входе, что ожидается на выходе и к какой задаче ML это можно свести  какие метрики покажут успешность задачи\n",
        "1. Разобраться с данными: где храняться достаточно ли их для проверки гипотезы. Неплохо бы сразу осознать, будут ли данные в продакшене отличаться от того, что доступно в трейне.\n",
        "1. Наинженерить фич и построить модель\n",
        "1. Оценить качество модели, посчитать технические и бизнесовые метрики (см. третий урок)\n",
        "1. Оценить ROI (Return on Investment) — ради этого всё и затевается.\n",
        "\n",
        "Фишка этих шагов в том, что ошибка на любом шаге сильно ухудшает весь проект - например, плохая постановка бизнес-требований приведёт к провальному эксперименту."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaAtOwDDmmGO"
      },
      "source": [
        "Расчёт ROI - самый важный, финальный этап. Без расчёта эффективности бизнес-заказчик не даст вам добра на выкатывание в продакшн.\n",
        "\n",
        "ROI  — это показатель доходности проекта, равный отношению доходов к затраченным инвестициям. ROI < 100% означает, что проект не окупится.\n",
        "\n",
        "`ROI` = (`LTP`)/(`CL` + `LTL`)\n",
        "\n",
        "1. LTP(Lifetime Profit)  - сколько доходов принесёт проект, пока его не свернут. Вычисляется как *операционные доходы* $\\times$ *срок жизни*\n",
        "1. CL (Capital Loss) - затраты на старт проекта\n",
        "1. LTL(Lifetime Loss)  - сколько расходов принесёт проект, пока его не свернут. Вычисляется как *операционные расходы проекта* $\\times$ *срок жизни проекта*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZLA8eJWmmGP"
      },
      "source": [
        "В капитальные затраты входит закупка железа и лицензий, разработку системы и ее внедрение. Операционные расходы - это то, что тратится на поддержание сервиса: зарплата программистов, devops-инженеров, аренда серверов.\n",
        "\n",
        "Из-за \"мгновенных\" капитальных расходов на старте проекта ROI будет зависеть от времени, на котором мы оцениваем доходность. Обычно для расчета ROI используется или год - нужно понять, окупится проект за год или нет.\n",
        "\n",
        "\n",
        "На далеком горизонте планирования можно окупить любую систему, поэтому важно понять величину *Lifetime* - сколько проработает система"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyn56i6-mmGP"
      },
      "source": [
        "В этом уроке мы узнали, что такое Proof of concept: какие действия нужно произвести чтобы понять, что модель будет полезна и принесёт выгоду. В следующем уроке мы поговорим о метриках сервиса - как понять, что модель действительно работает"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ7TtC6LmmGQ"
      },
      "source": [
        "## Метрики моделей ML\n",
        "\n",
        "Метрики ML-сервисов (как и любых других продакшн-систем) можено разделить на три основных группы\n",
        "\n",
        "* оффлайн-метрики модели\n",
        "* технические метрики сервиса\n",
        "* продуктовые (бизнес) метрики\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIgJMIdbmmGQ"
      },
      "source": [
        "### Оффлайн метрики\n",
        "\n",
        "Оффлайн-метрики показывают, насколько хорошо алгоритм \"выучил\" исторические данные. С этими метриками вы сталкивались в течение всего курса:\n",
        "\n",
        "* RMSE\n",
        "* MAE\n",
        "* precision\n",
        "* recall\n",
        "* accuracy\n",
        "* MAP\n",
        "* $\\ldots$\n",
        "\n",
        "Эти метрики не могут сказать, что модель будет достаточно хороша для бизнеса, но такая модель, как минимум, будет \"не совсем плоха\" чтобы отказываться от её выкатывания в прод. То есть выкатывают модель с хорошими оффлайн метриками и надеются, что она улучшит онлайн-метрики (см. дальше)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT9nRfnxmmGQ"
      },
      "source": [
        "В реальной жизни обучение модели запускается регулярно, поэтому оффлайн-метрики нуждаются в мониторинге.\n",
        "\n",
        "Пример из боевой системы обучения моделей: если ROC-AUC падает ниже 0.8, то модель в продакшн не выкатывается, а разработчику приходит уведомление в slack: дружище, с твоей моделью что-то не так, посмотри что случилось:\n",
        "\n",
        "```shell\n",
        "12:11:52,344 | INFO     | hydramatrices_data.py    :65   | Данные из HDFS загружены\n",
        "12:12:10,651 | INFO     | learn2rank_model.py      :168  | Разбили данные на train и test\n",
        "12:13:15,113 | INFO     | learn2rank_model.py      :248  | Кол-во объектов в train 1643676\n",
        "12:14:24,329 | INFO     | learn2rank_model.py      :265  | Новая модель Learning to Rank c2c готова\n",
        "12:14:49,295 | INFO     | learn2rank_model.py      :268  | Train Area under ROC = 0.8517\n",
        "12:15:11,057 | INFO     | learn2rank_model.py      :272  | Test Area under ROC = 0.8516\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9osfio6bmmGR"
      },
      "source": [
        "### Технические метрики\n",
        "\n",
        "Технические метрики сервиса - это некоторые показатели \"здоровья\", железа, которые никак не связаны с логикой\n",
        "\n",
        "* `RPS` (response per second) - сколько запросов в секунду прилетает на сервис\n",
        "* `response time` - время ответа сервиса\n",
        "* `CPU idle` - \"бездействие системы\", чем больше тем лучше. Если падает idle - значит, сильно загружен процессор\n",
        "* `available memory` - сколько памяти доступно на серверах\n",
        "* `500 errors` - количество 500-х ошибок на сервисе\n",
        "\n",
        "Дэшборды с техническими метриками могут выглядеть как-то так:\n",
        "\n",
        "![tech_metrics](img/tech_metrics.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cXze-LwmmGR"
      },
      "source": [
        "Для сбора и визуализации технических метрик используются следующие инструменты, которые должен знать каждый ML специалист:\n",
        "\n",
        "* statsd - хранение метрик\n",
        "* Grafana - визуализиция графиков\n",
        "* Zabbix - визуализация и отправка уведомлений (например, в slack)\n",
        "* Sentry - для анализа 500-х ошибок\n",
        "* Kibana - логи сервиса\n",
        "\n",
        "Прежде чем катить модель в прод нужно ознакомиться с каждым из этих инструментов и интегрировать с ними свою модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz8yzL33mmGR"
      },
      "source": [
        "### Продуктовые метрики\n",
        "\n",
        "Продуктовые метрики это то, что в первую очередь интересует бизнес. Когда выкатываете новую модель - она должна делать бизнесу лучше, а делать ML ради ML точно не стоит\n",
        "\n",
        "Какие метрики можно улучшить с помощью ML\n",
        "\n",
        "* средний чек\n",
        "* retention - возвращаемость клиентов на сервис\n",
        "* churn - отток клиентов с сервиса\n",
        "* bounce - % пользователей, которые зашли на сервис, но ничего не сделали  (показатель отказов)\n",
        "* конверсия в покупку\n",
        "\n",
        "Проверять, что ваша модель улучшает метрики следует с помощью АБ-теста\n",
        "\n",
        "![ab_testing](img/ab_testing.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cFFewQemmGR"
      },
      "source": [
        "В этом уроке мы узнали, как следить за моделями в продакшн. Вы познакомились с понятием \"технические метрики сервиса\" и теперь знаете, как сделать из \"чёрного ящика\" вашей модели прозрачный и управляемый сервис\n",
        "\n",
        "В следующем уроке мы перейдём к самому интересному - поговорим, как разворачивать модели на боевых серверах"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY_9TX7xmmGR"
      },
      "source": [
        "## Деплой модели: Docker\n",
        "\n",
        "Этапы разработки прод-сервиса:\n",
        "* разведочный анализ данных\n",
        "* прототип модели в Jupyter\n",
        "* продакшн-сервис\n",
        "\n",
        "Как же перейти от любимого Jupyter ноутбука к продакшин сервису? Современные архитектуры web-проектов предполагают т.н. микросервисную архитектуру, когда для решения конкретной бизнес задачи поднимается маленький веб-сервис, который умеет принимать http-запросы и делать predict, возвращая предсказания в виде json-объекта.\n",
        "\n",
        "JSON - это стадартный формат для общения микросервисов друг с другом, о нём говорили в самом начале курса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_HYPP9immGS"
      },
      "source": [
        "![microservices-logical.png](img/microservices-logical.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYQPnTQAmmGS"
      },
      "source": [
        "Как упаковать модель в микросервис? Для этого питоновский код нужно обернуть в http-сервер, который будет \"сёрвить\" (обслуживать) http-запросы. Вариантов http-сервера очень много\n",
        "\n",
        "* [Flask](https://palletsprojects.com/p/flask/)\n",
        "* [aiohttp](https://aiohttp.readthedocs.io/en/stable/)\n",
        "* [http.server](https://docs.python.org/3/library/http.server.html)\n",
        "\n",
        "Такой сервис обычно имеет url, на который можно отправлять запросы в заранее определённом формате, например `https://you.service/classify?uid=999` и возвращать ответ в JSON `{'uid': 999, 'class': 1}`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfwqw3xqmmGS"
      },
      "source": [
        "При чём тут **Docker**? Докер - это система виртуализации, которая позволяет унифицировать среду разработки и среду выполнения приложения: вы пишете код, который исполняется в виртуальной машине, тестируете его - а потом на боевые сервера отправляется та же самая виртуальная машина."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5dDVabmmGS"
      },
      "source": [
        "Получается, что вам не нужно волноваться о том, как будет жить питоновский код в продакшне - потому что будет исполняться в той же среде, в которой вы его разрабатывали (и тестировали). Докер является де-факто стандартом в мире современных архитектур для деплоя (т.е. вывода в продакшн-среду) моделей ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqspDg9lmmGS"
      },
      "source": [
        "### Простой докер-контейнер\n",
        "\n",
        "Вы уже пользовались докером для разворачивания Postgres базы данных, но не писали своих докерфайлов. Давайте исправим этот факт и напишем простой докер-сервис!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ_THc-ymmGS"
      },
      "source": [
        "Алгоритм упаковки сервиса в докер следующий\n",
        "\n",
        "1. Выбрать базовый образ. Я выбрал образ, в который включены такие библиотеки как sklearn, numpy и pandas https://hub.docker.com/r/morpheo/sklearn-base/\n",
        "1. Чтобы докер делал что-то полезное, нужно запустить внутри него программу. Программы внутри контейнера принято запускать через файл `docker-entrypoint.sh`. Для примера я создал файл [simple-entrypoint.sh](docker_example/simple-entrypoint.sh), внутри которого всего одна инструкция `echo \"Hello, MAI!\"`\n",
        "1. Чтобы собрать контейнер, нужно описать его структуру в Dockerfile. Загляните в файл [Dockerfile_simple](docker_example/Dockerfile), где описана структура нашего контейнера\n",
        "\n",
        "```dockerfile\n",
        "FROM morpheo/sklearn-base\n",
        "\n",
        "COPY simple_entrypoint.sh /usr/local/bin/docker-entrypoint.sh\n",
        "RUN chmod +x /usr/local/bin/docker-entrypoint.sh\n",
        "\n",
        "ENTRYPOINT [\"docker-entrypoint.sh\"]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdyTohyTmmGS"
      },
      "source": [
        "Находясь в директории `docker_example` надо запустить сборку контейнера командой\n",
        "```shell\n",
        "docker build . -f Dockerfile_simple -t mai:simple\n",
        "```\n",
        "\n",
        "После окончания процесса сборки запустить контейнер с помощью инструкции `docker run`:\n",
        "```shell\n",
        "docker run -it --rm  mai:simple\n",
        "```\n",
        "\n",
        "В результате должны увидеть в консоли `Hello, MAI!`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-V1c7x3mmGT"
      },
      "source": [
        "В этом уроке мы создали простой контейнер (для понимания), который только и умеет что выводить на печать простую фразу. В следующем уроке мы упакуем в докер пайплайн для тренировки и развёртывания модели машинного обучения в виде http-сервиса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otM0EiH6mmGT"
      },
      "source": [
        "# Упаковка модели в Docker: этап research\n",
        "\n",
        "Перед тем, как погружаться в мир докера, создадии пайплайн обучения на python.\n",
        "\n",
        "Начнём с загрузки данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "UnNdZA3XmmGT",
        "outputId": "6098d36a-5b17-4a22-8250-6054c07babe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   call_diff  sms_diff  traffic_diff  customes_class\n",
              "0  -0.666421  0.444911     -0.273538             0.0\n",
              "1  -0.889273 -0.537896     -1.959469             2.0\n",
              "2  -0.841503  0.846665      0.727606             0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9d9d797-1d75-4106-b285-5d958555f42c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>call_diff</th>\n",
              "      <th>sms_diff</th>\n",
              "      <th>traffic_diff</th>\n",
              "      <th>customes_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.666421</td>\n",
              "      <td>0.444911</td>\n",
              "      <td>-0.273538</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.889273</td>\n",
              "      <td>-0.537896</td>\n",
              "      <td>-1.959469</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.841503</td>\n",
              "      <td>0.846665</td>\n",
              "      <td>0.727606</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9d9d797-1d75-4106-b285-5d958555f42c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9d9d797-1d75-4106-b285-5d958555f42c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9d9d797-1d75-4106-b285-5d958555f42c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-751221ff-3c2f-4224-aaf5-bf5dc7ba4e8a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-751221ff-3c2f-4224-aaf5-bf5dc7ba4e8a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-751221ff-3c2f-4224-aaf5-bf5dc7ba4e8a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_source",
              "summary": "{\n  \"name\": \"df_source\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"call_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2301221210950464,\n        \"min\": -2.510954904296792,\n        \"max\": 2.3749883958483915,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          1.8559580614247788,\n          -0.4426608836163376,\n          0.0862618652041431\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sms_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2039820143974012,\n        \"min\": -2.6990820512161333,\n        \"max\": 3.788035770527541,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.608591929533526,\n          0.9277466586804728,\n          -0.2373283195285112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"traffic_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5804338411335284,\n        \"min\": -3.1292013016329183,\n        \"max\": 3.4345589737509976,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          2.501298133004629,\n          2.180293194669297,\n          0.9061825587343566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"customes_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8225975119502045,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          2.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_source = pd.read_csv(os.path.join(root_data_dir, 'client_segmentation.csv'))\n",
        "X = df_source[['call_diff','sms_diff','traffic_diff']].values\n",
        "y = df_source.customes_class.values\n",
        "\n",
        "df_source.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CqNq5ppmmGU"
      },
      "source": [
        "Это датасет, в котором три фичи `call_diff`, `sms_diff` и `traffic_diff` которые отражают относительное изменение в объёме звонков, смс и интернет-трафика соответственно по абонентам в базе телеком-оператора и несколько классов клиентов:\n",
        "\n",
        "* класс `0` - пользователь платит много\n",
        "* класс `1` - пользователь платит мало\n",
        "* класс `2` - пользователь ушёл в отток (не платит ничего)\n",
        "\n",
        "От нас требуется обучить модель классификации на три класса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWMB4-IPmmGU"
      },
      "source": [
        "Для визуализации данных выполним понижение размерности с помощью *t-sne*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "icr1mRlsmmGV",
        "outputId": "6a36249e-58a4-440a-833e-cc0d5677941a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "\n",
        "x_tsne = TSNE(n_components=2).fit_transform(X)\n",
        "colors = ['bo', 'gx', 'ro']; num_labels = len(colors)\n",
        "# И нарисуем получившиеся точки в нашем новом пространстве\n",
        "for name, label, color in [('class_%d' % i, i, colors[i]) for i in range(num_labels)]:\n",
        "    plt.plot(x_tsne[y == label, 0], x_tsne[y == label, 1], color, label=\"class %d\" % label)\n",
        "plt.legend(loc=0); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P53N1GVmmGV"
      },
      "source": [
        "Бизнесу требуется построить классификатор клиентов - давате обучим простенький классификатор, основанный на решающем дереве."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szY9iXMUmmGV",
        "outputId": "49e81170-3fa2-4a5a-c8ca-be6fc646232b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "У объекта под номером 1 класс 2.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# выбираем рандомный объект\n",
        "\n",
        "num_objects = X.shape[0]\n",
        "random_id = np.random.randint(num_objects)\n",
        "\n",
        "# преобразуем фичи, чтобы подошли на вход модели и делаем предсказания\n",
        "test_object = X[random_id,:].reshape(1, -1)\n",
        "pred = clf.predict(test_object)\n",
        "print(f\"У объекта под номером {random_id} класс {pred[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou0Hy_YkmmGV"
      },
      "source": [
        "Гототово, у нас есть модель, которая что-то обучает и что-то предсказывает. Можем сериализовать её для дальнейшего использования c помощью `pickle`. А теперь попробуем обернуть в докер наш пайплан обучения модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kDPrK3FmmGW"
      },
      "source": [
        "Базовый контейнер для сервиса я взял отсюда: https://hub.docker.com/r/frolvlad/alpine-python-machinelearning/ . Он включает python 3.5 и библиотеки numpy и sklearn - больше нам для обучения модели ниего не надо."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-KNjMM8mmGW"
      },
      "source": [
        "Запуск сборки\n",
        "```shell\n",
        " docker build . -f Dockerfile -t mai:advanced\n",
        "```\n",
        "Запуск обучения модели - см. файл `train.py`\n",
        "```shell\n",
        "docker run -it --rm  -v $(pwd)/data:/www/classifier/data mai:advanced train_model\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptUDHXN4mmGW"
      },
      "source": [
        "Вся полезная информация отправляется в файл с логами\n",
        "```shell\n",
        "tail -n1 data/service.log\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l_jPNsCmmGW"
      },
      "source": [
        "Пример логов модели\n",
        "```shell\n",
        "2020-04-24 06:55:54,070 | INFO     | service.py               :70   | Загружаем обученную модель\n",
        "2020-04-24 06:55:54,071 | INFO     | service.py               :73   | Модель загружена: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
        "            max_features=None, max_leaf_nodes=None,\n",
        "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
        "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "            presort=False, random_state=42, splitter='best')\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlH9vgCLmmGW"
      },
      "source": [
        "Запуск микросервиса - см. в файле `service.py`\n",
        "```shell\n",
        "docker run -it --rm  -v $(pwd)/data:/www/classifier/data -p 5000:5000 -d mai:advanced start_service\n",
        "```\n",
        "\n",
        "Увидеть запущенный контейнер можно через Docker ps\n",
        "```shell\n",
        "docker ps\n",
        "```\n",
        "\n",
        "Результат команды\n",
        "```shell\n",
        "CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
        "c9ba7303712c        mai:advanced   \"docker-entrypoint.s…\"   14 hours ago        Up 14 hours         0.0.0.0:5000->5000/tcp   infallible_easley\n",
        "```\n",
        "\n",
        "Чтобы проверить, что сервис \"жив\" и способен принимать запросы откройте в браузере спициальную страничку `http://0.0.0.0:5000/ping/` - это т.н. *healh check* нашего сервиса. В браузере должно появится\n",
        "```json\n",
        "{\"message\": \"pong\"}\n",
        "```\n",
        "\n",
        "Хороший туториал по [упаковке моделей в контейнеры](https://towardsdatascience.com/deploying-machine-learning-models-with-docker-5d22a4dacb5). Там можно почитать, как скейлить нагрузку помощью nginx+gunikorn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwXN3C3CmmGW"
      },
      "source": [
        "В нашем датасете три фичи - нам нужно передать их в наш микросервис. Передавать фичи можно через GET-запросы, например, так:\n",
        "```url\n",
        "http://0.0.0.0:5000/classifier/?x1=1&x2=-2.2&x3=1.05\n",
        "```\n",
        "\n",
        "Дальше нам нужно перехватить их на стороне сервиса, обработать фичи, загрузив в классификатор и выдать ответ:\n",
        "```json\n",
        "{\"x1\": 1.0, \"x2\": -2.2, \"x3\": 1.05, \"predicted_class\": 0}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c82gKn6ommGW"
      },
      "source": [
        "После окончания работ контейнер можно остановить\n",
        "```shell\n",
        "docker stop c9ba7303712c\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Syg55lmmGc"
      },
      "source": [
        "Мы упаковали модель в докер и можем использовать модель как микросервис - отправлять запросы и получать предсказания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvIQwiP5mmGc"
      },
      "source": [
        "Давайте обобщим все наши знания о микросервисах в одной картинке\n",
        "\n",
        "* у микросервиса должен быть определён формат ответа в виде JSON схемы\n",
        "* Consul - это сервис, который автоматически дёргает *health check* и рестартует контейнер, если он перестал отвечать\n",
        "* блок `logs` - это Elastic+Logstash+Kibana, связка используется для хранения логов\n",
        "* технические метрики отправляются в хранилище Prometheus и визуализируются  в Grafana. Нотификации в случае нештатных ситуаций отправляются в Slack\n",
        "* инциденты в виде 500-х ошибок отправляются в Sentry для дальнейшего анализа\n",
        "\n",
        "![microservice.png](img/microservice.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzMyJfsYmmGc"
      },
      "source": [
        "### Домашнее задание: применяем PCA-трансформацию\n",
        "\n",
        "[Домашка тут](https://github.com/aleksandr-dzhumurat/data_management/blob/master/jupyter_notebooks/VI_machine_learning_production_hw.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKCnCPHsmmGc"
      },
      "source": [
        "# ML в проде: рекомендательные системы\n",
        "\n",
        "Рекомендательные системы - это обобщённое название для сервисов, которые в ответ на запрос формируют из огромной коллекции доступных сущностей (мы будем называть их \"документами\", англ. item но в реальной жизни это фильмы в онлайн-кинотеатре или товары в интернет-магазине, а саму такую коллекцию документов для краткости будем называть каталогом) некоторый шорт-лист, который будет наиболее подходящим для данного запроса (такие документы называются \"релевантными\"). Рекомендательные системы используют для решения своих задач другие алгоритмы ML.\n",
        "О том, как на основе уже изученных ML-алгоритмов научиться решать задачу поиска релевантных объектов мы поговорим в этом  уроке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRJn9GtUmmGd"
      },
      "source": [
        "## Рекомендательные системы: цели и задачи\n",
        "\n",
        "Основная задача рекомендательной системы - нарезать шорт-лист из каталога, который будет максимально подходить к контексту, в котором запрашиваются рекомендации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zd_SLRymmGd"
      },
      "source": [
        "Под \"контекстом\" мы понимаем различные параметры мира, который окружает рекомендательную систему:\n",
        "\n",
        "* с какими документами из каталога уже взаимодействовал пользователь\n",
        "* какова \"сила\" взаимодействия - лайк или дизлайк? Если оценка - то какая? Если просмотр фильма - то как долго смотрел?\n",
        "* в какой стране находится пользователь - в Казахстане смотрят фильм \"Рэкетир\" а в России \"Бумер\".\n",
        "* утро или вечер в момент посмотрения рекомендаций\n",
        "* что по соцдему - какого пола и возраста пользователь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTDAruWPmmGd"
      },
      "source": [
        "Задача рекомендаций представляет собой задачу *ранжирования* - мы пытаемся расставить контент в таком порядке, чтобы в начале списка был самый релевантный контент"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhGV6L-0mmGd"
      },
      "source": [
        "Вот, например, как выглядит главная страница ivi - по сути, это персонализованная нарезка из доступного каталога контента\n",
        "\n",
        "![ivi_main](img/ivi_catalog.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbymL0cvmmGd"
      },
      "source": [
        "Различают два вида рекомендаций:\n",
        "\n",
        "* *content to user*  строятся на основе фидбэка, полученного от пользователя (например, лайкнутые фильмы)\n",
        "* *content to content* строятся на основе свойств контента найти максимально похожие на него элементы (например, блок \"С этим часто покупают\" на Ozon)\n",
        "\n",
        "Рекомендательная система решает задачу персонализации сервиса - это значит, что каждый пользователь  видит свой вариант сервиса - можно сказать, что у вас появляется столько вариантов наполнения страниц вашего сайта, сколько у вас пользователей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX6uXP0cmmGe"
      },
      "source": [
        "Рекомендательные системы нужны в ситуации, когда пользователь не может сделать выбор из огромного количества возможных вариантов каталога (например, каталога интернет-магазина) и ему нужно как-то помочь, ограничив выбор узким кругом объектов, которые больше всего подходят к текущему контексту - такие объекты и называются *релевантными*. Избавив пользователя от необходимости просматривать огромное число неподходящих объектов, рекомендательная система позволяет быстрее сконвертировать пользовательскую сессию в \"целевое действие\" - просмотр фильма или покупку гаджета."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH6jdUjNmmGe"
      },
      "source": [
        "Существует два основных метода для поиска релелевантных объектов\n",
        "\n",
        "* collaborative filtering\n",
        "* content filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGgDeYiWmmGe"
      },
      "source": [
        "Модели *коллаборативной фильтрации* используют интуитивное предположение о том, что если у двух пользователей сильно пересекаются два множества контента (с которым они взаимодействовали) то у этих двух пользователей схожие вкусы - на основе этого можно делать рекомендации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9liK6B6mmGe"
      },
      "source": [
        "Допустим, у нас есть информация о пользователях `X, Y, Z` и фильмах `A, B, C, D, E`. В таблице символ \"+\" означает, что пользователь $i$ смотрел фильм $j$:\n",
        "\n",
        "| - | A | B | C | D | E |\n",
        "| -- | -- | -- | -- | -- | -- |\n",
        "| X  | +  | -  | +  | +  | -  |\n",
        "| Y  | -  | +  | -  | -  | +  |\n",
        "| Z  | +  | +  | -  | +  | -  |\n",
        "\n",
        "Как видно, пользователи `X, Z` очень похожи друг на друга, т.к. им обоим нравится фильмы \"А\" и \"D\".\n",
        "\n",
        "В то же время пользователь `Y` не похож на них, он смотрит другие фильмы. Из картинки видно, что если бы нам нужно было бы построить персональные рекомендации для пользователя `X`, то мы бы порекомендовали  ему фильм `B` - такой фильм смотрел пользователь Z и значит, этот фильм понравится пользователю X, потому что данные говорят о том, чт вкусы этих двух пользователей похожи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeJb3ODhmmGe"
      },
      "source": [
        "*Content-based* фильтрация подбирает похожие элементы на основе свойств контента. Например, в случае фильма его свойства - это актёр, режиссёр, жанр, место действия и т.д. Например, если у нас естьфильм со Стэтхемом, то максимально похожим будет, скорее всего, другой фильм со Стэтхэмом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTxwt_n5mmGf"
      },
      "source": [
        "Также выделяют *гибридные* рекомендательные системы - в этом случае рекомендации из нескольких моделей (например, `content based` + `collaborative filterig`) используются для формирования итогового ранжирования."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9zoKF58mmGf"
      },
      "source": [
        "Колаборативные модели обучаются на триплетах (тройках) `(user, item, feedback)`, где для каждой пары `(user, item)` фидбэк может быть двух видов:\n",
        "\n",
        "* explicit (явный)\n",
        "* implicit (неявный)\n",
        "\n",
        "*Явный фидбэк* - это любое явное выражение пользователем своего отношения к контенту: лайк, оценка и т.д. *Неявный фидбэк* - это длительность просмотра фильма, количество заходов на карточку товара, время чтения статьи и т.д.: интуитивно понятно, что если пользователь смотрит фильм долго - то такой фильм, скорее всего, ему нравится, но явного сигнала (например, в виде лайка) мы не получаем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdmjtsNnmmGf"
      },
      "source": [
        "Задача построения рекомендации решается с помощью классических алгоритмов машинного обучения:\n",
        "\n",
        "* метод ближайших соседей (knn)\n",
        "* матричная факторизация\n",
        "* логистическая регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLsRvredmmGf"
      },
      "source": [
        "Рекомендатель отдаёт отранжированный список объектов. На этот список обычно накладываются разнообразные бизнес-правила, позволяющие оптимизировать метрики, важные для бизнеса: например, искуственное повышение новинок в выдаче.\n",
        "\n",
        "Грамотно построенная рекомендательная система позволяет нарастить продуктовые метрики. Например, в онлайн-кинотеатре:\n",
        "\n",
        "* растёт конверсия в просмотр т.к. пользователь получает на главной странице самый подходящий контент\n",
        "* увеличивается длительности смотрения на пользователя, удачно рекомендованный сериал генерирует десятки часов смотрения\n",
        "* уменьшается отток с сервиса - пользователь за одну сессию может выбрать несколько фильмов, которые будет смотреть несколько заходов подряд."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94QzOPBMmmGf"
      },
      "source": [
        "## KNN рекомендации\n",
        "\n",
        "Мы попробуем построить простейшую модель коллаборативной фильтрации, пользуясь только информацией о просмотрах контента в онлайн-кинотеатре ivi.\n",
        "\n",
        "Загрузим исходные данные - там примерно полмиллиона просмотров:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IN3a42oOmmGf",
        "outputId": "05600841-dfdb-4211-e5ad-0a4278f4e3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество просмотров 489565\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>view_duration</th>\n",
              "      <th>view_ts</th>\n",
              "      <th>dt</th>\n",
              "      <th>platform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4649</td>\n",
              "      <td>52867</td>\n",
              "      <td>735</td>\n",
              "      <td>2019-03-18 20:40:57+03:00</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>LG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>48800</td>\n",
              "      <td>361</td>\n",
              "      <td>2019-03-18 11:48:27+03:00</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>LG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5380</td>\n",
              "      <td>47146</td>\n",
              "      <td>268</td>\n",
              "      <td>2019-02-17 13:06:33+03:00</td>\n",
              "      <td>2019-02-17</td>\n",
              "      <td>LG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
              "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
              "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
              "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
              "\n",
              "  platform  \n",
              "0       LG  \n",
              "1       LG  \n",
              "2       LG  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "content_views = pd.read_csv(\n",
        "    'recsys_data/content_views.zip', delimiter=',', header=0, compression='zip',\n",
        "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
        "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
        "    parse_dates = [3, 4]\n",
        ")\n",
        "\n",
        "\n",
        "print('Количество просмотров %s' % content_views.user_id.count())\n",
        "\n",
        "content_views.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhFLCY5tmmGg"
      },
      "source": [
        "Загрузим дополнительную информацию о контенте: жанры, дату появления на сервисе, рейтинг кинопоиска и т.д."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JudCRat-mmGg",
        "outputId": "0e6b2615-a320-49a1-dfa5-b538eb88b8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество доступного контента 126182\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content_id</th>\n",
              "      <th>origin_country</th>\n",
              "      <th>release_date</th>\n",
              "      <th>kinopoisk_rating</th>\n",
              "      <th>compilation_id</th>\n",
              "      <th>genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1974</td>\n",
              "      <td>87.0</td>\n",
              "      <td>2009-12-15</td>\n",
              "      <td>7.27</td>\n",
              "      <td>153</td>\n",
              "      <td>Для детей</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2148</td>\n",
              "      <td>87.0</td>\n",
              "      <td>2009-12-21</td>\n",
              "      <td>7.27</td>\n",
              "      <td>153</td>\n",
              "      <td>Для детей</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2184</td>\n",
              "      <td>87.0</td>\n",
              "      <td>2009-12-22</td>\n",
              "      <td>7.27</td>\n",
              "      <td>153</td>\n",
              "      <td>Для детей</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
              "0        1974            87.0   2009-12-15              7.27             153   \n",
              "1        2148            87.0   2009-12-21              7.27             153   \n",
              "2        2184            87.0   2009-12-22              7.27             153   \n",
              "\n",
              "       genre  \n",
              "0  Для детей  \n",
              "1  Для детей  \n",
              "2  Для детей  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "content_description = pd.read_csv(\n",
        "    'recsys_data/content_description.zip', delimiter=',', header=0, compression='zip',\n",
        "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
        "    dtype = {'content_id': np.uint16},\n",
        "    parse_dates = [2]\n",
        ")\n",
        "\n",
        "print('Количество доступного контента %s' % content_description.content_id.count())\n",
        "\n",
        "content_description.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bzv14LUmmGg"
      },
      "source": [
        "Сформируем разреженную матрицу user-item такую, что\n",
        "\n",
        "* количество строк матрицы совпадает с числом пользователей\n",
        "* количество столбцов матрицы совпадает с количеством контента\n",
        "* на пересечении столбца $i$ и строки $j$ стоит единица, если пользователь $i$ смотрел контент $j$, иначе - ноль\n",
        "\n",
        "Для начала перейдём от индекса контента и индекса пользователя к индексам в разреженной матрице - воспользуемся `LabelEncoder`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4KL0sqVmmGg",
        "outputId": "80915be5-db01-4c69-fb65-8f524a77a17d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>view_duration</th>\n",
              "      <th>view_ts</th>\n",
              "      <th>dt</th>\n",
              "      <th>platform</th>\n",
              "      <th>user_index</th>\n",
              "      <th>item_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4649</td>\n",
              "      <td>52867</td>\n",
              "      <td>735</td>\n",
              "      <td>2019-03-18 20:40:57+03:00</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>LG</td>\n",
              "      <td>802</td>\n",
              "      <td>22812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>48800</td>\n",
              "      <td>361</td>\n",
              "      <td>2019-03-18 11:48:27+03:00</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>LG</td>\n",
              "      <td>2</td>\n",
              "      <td>20399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5380</td>\n",
              "      <td>47146</td>\n",
              "      <td>268</td>\n",
              "      <td>2019-02-17 13:06:33+03:00</td>\n",
              "      <td>2019-02-17</td>\n",
              "      <td>LG</td>\n",
              "      <td>911</td>\n",
              "      <td>19628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4498</td>\n",
              "      <td>30191</td>\n",
              "      <td>297</td>\n",
              "      <td>2019-03-18 15:27:18+03:00</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>LG</td>\n",
              "      <td>773</td>\n",
              "      <td>13517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4886</td>\n",
              "      <td>39349</td>\n",
              "      <td>302</td>\n",
              "      <td>2019-03-18 12:08:16+03:00</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>LG</td>\n",
              "      <td>836</td>\n",
              "      <td>16959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
              "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
              "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
              "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
              "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
              "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
              "\n",
              "  platform  user_index  item_index  \n",
              "0       LG         802       22812  \n",
              "1       LG           2       20399  \n",
              "2       LG         911       19628  \n",
              "3       LG         773       13517  \n",
              "4       LG         836       16959  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# кодируем индексы пользователей\n",
        "user_encoder = LabelEncoder()\n",
        "user_encoder.fit(content_views.user_id)\n",
        "\n",
        "# ереиндексация контента\n",
        "content_views = content_views.assign(\n",
        "    user_index = user_encoder.transform(content_views.user_id)\n",
        ")\n",
        "\n",
        "# кодируем индексы контента\n",
        "item_encoder = LabelEncoder()\n",
        "item_encoder.fit(content_views.content_id)\n",
        "\n",
        "# нова переиндексация\n",
        "content_views = content_views.assign(\n",
        "    item_index = item_encoder.transform(content_views.content_id)\n",
        ")\n",
        "\n",
        "\n",
        "content_views.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxUHB2vwmmGh"
      },
      "source": [
        "Теперь у нас есть колонки `user_index, item_index`, которые соответствуют номерам строки и столбца соответственно в матрице user-item. Передадим полученные колонки в конструктор `csr_matrix`, чтобы получить разреженную матрицу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97q0QN6OmmGh",
        "outputId": "d37fde94-6a4c-4733-a6a1-71e30cec4068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sparsity: 0.0091\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 259994 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "num_users = content_views.user_index.max() + 1\n",
        "num_items = content_views.item_index.max() + 1\n",
        "num_interactions = content_views.shape[0]\n",
        "\n",
        "user_item = csr_matrix(\n",
        "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
        "    shape=(num_users, num_items)\n",
        ")\n",
        "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
        "\n",
        "user_item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkHLLJo9mmGh"
      },
      "source": [
        "Разделяем выборку на валидацию и контроль"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj85a_12mmGh",
        "outputId": "02295f53-31dd-4db7-d2b9-bb2449e5808d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "        Размер обучающей выборки 1600 пользователей\n",
            "        Размер валидационной выборки 400 пользователей\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_ids, test_ids = train_test_split(\n",
        "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
        "    test_size=0.2\n",
        ")\n",
        "print(\n",
        "    \"\"\"\n",
        "        Размер обучающей выборки %d пользователей\n",
        "        Размер валидационной выборки %d пользователей\n",
        "    \"\"\"\n",
        "    % (train_ids.size, test_ids.size)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ1XJN7lmmGi"
      },
      "source": [
        "Мы видим, что в наше матрице 2000 пользователей и 27012 единиц контента, у матрицы высокая разреженность - менее 1% ненулевых элементов, остальное заполнено нулями.\n",
        "\n",
        "Чтобы строить рекомендации по колаборативной модели, нам нужен быстрый способ поиска пользователей, у которых схожая история просмотров- наше предположение в том, что похожие пользователи имеют похожую историю просмотров. Для поиска схожих пользователей воспользуемся поиском ближайших соседей по нашей матрице `user-item`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJBsAbwlmmGi",
        "outputId": "b6cf341a-9409-46a8-e8fe-b54db64abca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
              "                 metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
        "\n",
        "# обучаемся только на тренировочной части пользователей\n",
        "model_knn.fit(user_item[train_ids,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kErFDdTbmmGi"
      },
      "source": [
        "Создадим простейший класс, который умеет искать похожих по истории смотрения пользователей и выдавать рекомендации. Рекомендации - это контент, который смотрели ближашие соседи пользователя, а сам пользователь этот контент не видел"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idrROobvmmGi"
      },
      "outputs": [],
      "source": [
        "class ColaborativeFilteringKNNRecommender:\n",
        "    def __init__(self, knn_model, user_item_matrix, num_neighbors):\n",
        "        self.knn_model = knn_model\n",
        "        self.user_item_matrix = user_item_matrix\n",
        "        self.num_neighbors = num_neighbors\n",
        "        self.top_recs = 50\n",
        "\n",
        "    def make_recs(self, user_history: csr_matrix, top_recs: int):\n",
        "        neighbors = model_knn.kneighbors(\n",
        "            random_user_history,\n",
        "            self.num_neighbors,\n",
        "            return_distance=False\n",
        "        )[0]\n",
        "        full_recs = user_item[neighbors,:].max(axis=0)\n",
        "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
        "        user_history_ids = user_history.nonzero()[1]\n",
        "        # последовательность id того контента, который смотрели ближайшие соседи\n",
        "        full_recs_ids = full_recs.nonzero()[1][:self.top_recs]\n",
        "        # исключаем из рекомендаций то, что уже было у упользователя в историии\n",
        "        success_recs = np.array([i for i in full_recs_ids if i in user_history_ids])\n",
        "        print(\"Число успешных рекомендаций %d из %d\" % (success_recs.size, top_recs))\n",
        "\n",
        "        return np.array([i for i in full_recs_ids if i not in user_history_ids])[:10]\n",
        "\n",
        "\n",
        "# объект рекомендателя\n",
        "recommender = ColaborativeFilteringKNNRecommender(\n",
        "    knn_model=model_knn,\n",
        "    user_item_matrix=user_item,\n",
        "    num_neighbors=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THzLHwmtmmGj"
      },
      "source": [
        "Применяем рекомендатель для случайного пользователя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0txJBxrmmGj",
        "outputId": "462ba892-5f29-4fbd-d39a-eae8c531e916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Число успешных рекомендаций 6 из 10\n",
            "user_index 954, history: [   9   76  939  940  983 1086 1087 1088 1089 1090]\n",
            "recommendations: [ 687  988 1250 1254 1295 1300 1303 1307 1416 1500]\n"
          ]
        }
      ],
      "source": [
        "# пример рекомендаций для случайного пользователя\n",
        "random_user_index = np.random.choice(test_ids)\n",
        "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
        "\n",
        "recs = recommender.make_recs(random_user_history, top_recs=10)\n",
        "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
        "print('recommendations: %s' % recs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsV2ma81mmGj"
      },
      "source": [
        "## Домашняя работа: строим KNN\n",
        "\n",
        "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAbTVpprmmGk"
      },
      "source": [
        "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76gkmk3vmmGk"
      },
      "outputs": [],
      "source": [
        "# -- ВАШ КОД ТУТ --\n",
        "\n",
        "\n",
        "\n",
        "# ------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drkzgiPdmmGk"
      },
      "source": [
        "### Домашнее задание: Item to Item\n",
        "\n",
        "Решите задачу c2c рекомендаций - вызовите метод [similar_items](https://implicit.readthedocs.io/en/latest/models.html?highlight=similar_items#implicit.recommender_base.RecommenderBase.similar_items) для  *item_id=1*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTdb1AXQmmGk"
      },
      "outputs": [],
      "source": [
        "# -- ВАШ КОД ТУТ --\n",
        "\n",
        "\n",
        "\n",
        "# ------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C20a581vmmGk"
      },
      "source": [
        "Мы обучили простейшую рекомендательную систему, основанную на колаборативной фильтрации и поиске ближайших соседей. В следующем уроке мы узнаем, как перейти от рекомендаций основанных на knn к более сложной концепции эмбеддингов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKfVo_b6mmGk"
      },
      "source": [
        "# Урок 3. Эмбеддинги пользователей и контента (скрытые факторы)\n",
        "\n",
        "Рекомендации, которые строятся на основе KNN, имеют следующий недостаток: фактическим мы запоминаем матрицу `user-item` на этапе тренировки модели - такие модели называются *memory-based*. Это привобдит к большому расходу памяти на этапе получения предсказаний, т.к. по каждому пользователю мы вынуждены хранить разреженный вектор большой размерности. При росте количества пользователей модель начинает критически быстро расти по памяти."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62UyV4cSmmGl"
      },
      "source": [
        "Другой подход заключается в применении матричного разложения - когда мы пытаемся приблизить нашу большую разреженную матрицу user-item размерности $m\\times n$ двумя плотными матрицами, которые называются матрицей латентных (скрытых) факторов пользователей размерности $m\\times f$ и матрицей скрытых факторов контента размерности $n \\times f$. О таких методах мы уже говорили в уроке по теме \"Снижение размерности\" курса \"Машинное обучение. Начальный уровень\". Такой подход, при котором мы запоминаем не матрицу user-item, а только некий полезный сигнал из этой матрицы, называется *model-based*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HyR8N5cmmGl"
      },
      "source": [
        "Фокус в том, что $m,n$ - это числа порядка десятков тысяч, а $f$ имеет небольшую размерность (обычно 30-50). Кажому пользователю и каждой единице понтента при таком подходе ставится в соответствие вектор размерности $f$, а произведение вектора пользователя $p_u$ на вектор контента $q_i$ даёт единственное число $r_{ui}$ - меру \"релевантности\", насколько данный контент понравится данному пользователю"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IskGLC82mmGl"
      },
      "source": [
        "![svd_decomp](img/svd_decomp.png)\n",
        "\n",
        "$$\n",
        "r_{ui} = q_i^Tp_u\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4tDoCOammGl"
      },
      "source": [
        "Для матричного разложения используются различные алгоритмы:\n",
        "\n",
        "* Singular Vector Decomposition (SVD)\n",
        "* Alternative Least Squares (ALS)\n",
        "* Bayesian personalized ranking (BPR)\n",
        "\n",
        "При решении реальных задач советую начать с BPR - он даёт отличные результаты, но у него есть и недостаток - вычислительная сложность, которая увеличивает время обучения.\n",
        "\n",
        "Выбирая между SVD и ALS я рекомендую выбирать ALS, т.к. он более новый и более быстрый."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me7_02USmmGl"
      },
      "source": [
        "Мы продемонстрируем работу рекомендательной системы на примере SVD-разложения - для этотго даже не нужно устанавливать дополнительные пакеты, нужная функция есть прямо в пакете `numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJLJaBSjmmGl",
        "outputId": "d90cfc59-0de6-4c16-9d56-e1d1bf49c12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2000, 27012) (2000, 50) (27012, 50)\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "latent_factors_num = 50\n",
        "# раскладываем Useк-Item матрицу\n",
        "user_factors, scale, item_factors = svds(\n",
        "    user_item.asfptype(),\n",
        "    k=latent_factors_num,\n",
        "    return_singular_vectors=True\n",
        ")\n",
        "scale = np.diag(np.sqrt(scale))\n",
        "# эмбеддинги пользователей\n",
        "user_factors = np.dot(user_factors, scale).astype(np.float32)\n",
        "# эмбеддинги контента\n",
        "item_factors = np.dot(scale, item_factors).astype(np.float32)\n",
        "\n",
        "print(user_item.shape, user_factors.shape, item_factors.T.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCJO9WmPmmGm"
      },
      "source": [
        "Спроектируем класс, который будет формировать рекомендации на основе матриц `user_factors` и `item_factors`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X4-ZbpPmmGm",
        "outputId": "ec81bae4-7a63-45de-deab-d93bc39dfaff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([16421,  8459, 15912, 17787, 23459, 26717,  2484, 13301, 13309,\n",
              "       23456, 13344,   603])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class ColaborativeFilteringFactorizationRecommender:\n",
        "    def __init__(self, user_factors, item_factors, user_item_matrix):\n",
        "        self.user_factors = user_factors\n",
        "        self.item_factors = item_factors\n",
        "        self.user_item_matrix = user_item_matrix\n",
        "\n",
        "    def make_recs(self, user_index):\n",
        "        user_factors = self.user_factors[user_index,:]\n",
        "        user_history_ids = self.user_item_matrix.getrow(user_index).nonzero()[1]\n",
        "        # рекомендации - это произведение вектора на матрицу\n",
        "        personal_scores = user_factors.reshape(1, -1).dot(self.item_factors).flatten()\n",
        "        personal_recs = np.argsort(-personal_scores)[:20]\n",
        "\n",
        "        return np.array([i for i in personal_recs if i not in user_history_ids])\n",
        "\n",
        "factorization_recommender = ColaborativeFilteringFactorizationRecommender(\n",
        "    user_factors=user_factors,\n",
        "    item_factors=item_factors,\n",
        "    user_item_matrix=user_item\n",
        ")\n",
        "\n",
        "random_user_index = np.random.choice(test_ids)\n",
        "factorization_recommender.make_recs(random_user_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4p7AyMimmGm"
      },
      "source": [
        "Колаборативная модель на основе скрытых факторов пользователя/контента позволяет быстро получить список релевантного контента для каждого пользователя"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bisQ99d2mmGm"
      },
      "source": [
        "### Домашнее задание: обучаем Implicit\n",
        "\n",
        "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScirbjNDmmGn"
      },
      "outputs": [],
      "source": [
        "# -- ВАШ КОД ТУТ --\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMLkJt0fmmGn"
      },
      "source": [
        "В этому уроке мы поговорили о том, как перейти от memory-based рекомендателям к model-based. В следующем уроке обсудим, а как измеряют эффективность рекомендательных систем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAVsQyPrmmGn"
      },
      "source": [
        "## Метрики рекомендательных систем\n",
        "\n",
        "Мы научились делать персональные рекомендации единиц каталога. В этом уроке поговорим о том, как отделить \"хорошие\" модели от \"плохих\"\n",
        "\n",
        "Метрики рекомендательной системы (как и любых других продакшн-систем) можено разделить на три основных группы\n",
        "\n",
        "* оффлайн-метрики модели\n",
        "* продуктовые (бизнес) метрики"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTPmUY-WmmGn"
      },
      "source": [
        "Продуктовые метрики - это то, как пользователи реагируют на рекомендации. К пользовательским метрикам можно отнести:\n",
        "\n",
        "* конверсию (в просмотр, в покупку и т.д.) - чем выше конверсия, тем лучше модель\n",
        "* длительность нахождения на сервисе (чем дольше, тем лучше)\n",
        "* поизицию, до которой были просмотрены рекомендации - чем меньше позиций пролистали, тем лучше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eicPIFxommGn"
      },
      "source": [
        "**Продуктовые метрики** (иногда их называют онлайн-метриками) можно измерить, только проведя АБ-тест, эксперимент на реальных пользователях сервиса. Механика проведения эксперимента следующая мы делим пользователей на две группы: группа А видит старый вариант алгоритма, группа Б - новый вариант. После окончания теста сравнивается значение в тестовой группе и контрольной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf7-EZgbmmGn"
      },
      "source": [
        "**Оффлайн-метрики** рекомендательных систем позволяют проверить, насколько качественные прогнозы выполняет модель, пользуясь историческими данными.\n",
        "\n",
        "Для этой задачи можно приспособить известную Вам метрику **RMSE**, которая определяет, насколько точно мы приблизили матрицу *user-item*\n",
        "$$\n",
        "\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(a_{ij}-\\hat{a}_{ij})^2}\n",
        "$$\n",
        "\n",
        "Где $a_{ij}$ - истинное значение фидбека пользователя $i$ для контента $j$, а $\\hat{a}_{ij}$ - значение фидбэка, которое предсказала наша модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22T5COlWmmGn"
      },
      "source": [
        "Это неплохая метрика, например, для задачи регрессии, но для рекомендаций она немного странная - в принципе, нам не важно, насколько хорошо предсказываются оценки 2,3,4 - мы хотим уверенном предсказывать высокие оценки: 8,9,10.\n",
        "\n",
        "Другой пример метрик - это метрики из задач классификации (precision + reccall).\n",
        "\n",
        "Допустим, у нас есть список рекомендаций из $n=5$ элементов и список фактических просмотров из $k=3$ элементов. В красную рамку обведены те рекомендации, которые были фактически просмотрены - количество таких фильмов $m = 2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jEtK-rBmmGo"
      },
      "source": [
        "![eval](img/eval.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbblL6HqmmGo"
      },
      "source": [
        "**Recall**  показывает отношение товаров, купленных из рекомендаций к общему числу фактических просмотров\n",
        "\n",
        "$$\n",
        "\\text{recall} = \\frac{m}{k} = \\frac{2}{3}\n",
        "$$\n",
        "\n",
        "**Precision**  показывает, насколько много из рекомендованного нами попало в итоге в просмотренное\n",
        "\n",
        "$$\n",
        "\\text{precision} = \\frac{m}{n} = \\frac{2}{5}\n",
        "$$\n",
        "\n",
        "У precision заметен один недостаток - игнорируется порядок, в котором пользователя заинтересовали рекомендованные объекты. Эту задачу решает метрика *average precision at K*. В числителе дисконтируем каждую \"единичку\", на ту позицию, где она стоит:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDJ3HARpmmGo"
      },
      "source": [
        "$$\n",
        "\\text{ap} = \\frac{1}{5}\\left( 0 + \\frac{1}{2} + \\frac{1}{3}\\right) = \\frac{1}{5}\\cdot \\frac{5}{6} = \\frac{1}{6}\n",
        "$$\n",
        "\n",
        "при такой модификации мы заставляем модель не просто угадывать релевантные объекты, но и \"поднимать\" их выше к началу списка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFxTzjPGmmGo"
      },
      "source": [
        "Кроме перечисленных выше метрик, которые измеряют точность \"угадывания\", можно мерять и другие показатели\n",
        "\n",
        "* diversity (разннообразие выдачи) - как сильно в выдаче представлены разные жанры, авторы и т.д.\n",
        "* coverage (покарытие каталога) - какая часть каталога покрывается рекомендациями (следует избегать случаев, когда всем пользователям рекомендуюется одно и то же подмножество)\n",
        "* serendipity (индивидуальность) -  берем разницу между вероятностью рекомендации айтема юзеру и всем юзерам (т.е. насколько рекомендация индивидуальна) и суммируем по всем релевантным рекомендованым айтемам. Позволяет определить, насколько выдача \"заточена\" под польователя\n",
        "* novelty (новизна) - как часто попадают в выдачу новые (холодные) элементы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cfPGoyQmmGo"
      },
      "source": [
        "### Домашнее задание на метрики\n",
        "\n",
        "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
        "\n",
        "Вычислите\n",
        "\n",
        "* precision\n",
        "* recall\n",
        "* precision@5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFx9N2QZmmGo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
        "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
        "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
        "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
        "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
        "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
        "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
        "    41368, 53414,  2681, 30201]\n",
        "\n",
        "user_recs = [\n",
        "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
        "    21267, 50126, 58560, 7764, 49781\n",
        "]\n",
        "\n",
        "# --- ВАШ КОД ТУТ ---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJc0WyAOmmGp"
      },
      "source": [
        "В этом уроке познакомились с метриками. Теперь вы можете отличать хорошие модели рекомендаций от плохих."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeFuWv8XmmGp"
      },
      "source": [
        "В этом модуле мы мознакомились с темой рекомендательных систем. Это область знаний, которую \"просто выучить, сложно понять\" - потому что с помощью простых алгоритмов ML можно сильно увеличить эффективность вашего бизнеса, но правильное применение этих методов к задаче построения рекомендательной системы - особое искусство, требующее хорошего понимания бизнес-области и знания специфических метрик систем ранжирования"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URHZSbO_mmGp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGKBnaDPmmGp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}